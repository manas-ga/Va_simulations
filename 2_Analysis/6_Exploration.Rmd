---
title: "Exploration"
output: 
  bookdown::html_document2:
    toc: true
    css: custom.css
bibliography: /Users/jhadfiel/Work/Tex/library/JarLib.bib
---
  
  <script src="hideOutput.js"></script>
  
  <script type="text/javascript">
  // When the document is fully rendered...
$(document).ready(function() {
  // ...select all header elements...
  $('h1, h2, h3, h4, h5').each(function() {
    // ...and add an id to them corresponding to their 'titles'
    $(this).attr('id', $(this).html());
  });
});
</script>

```{r setup_exploration, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

run_get_data<-FALSE
run_analyse_data<-FALSE
run_model<-TRUE
run_alpha<-FALSE
run_bc<-FALSE

#rmarkdown::render("/Users/jhadfiel/Work/Va_simulations/2_ANalysis/6_Exploration.Rmd")

```

The following script is best ran in a conda environment with dependencies python=3.11.5 and numpy=1.26.0 (conda activate Va_anal). 

# Patterns

First we assess how well we can estimate $V_a$ from simulated data where there is no burn-in phase. In these simulations, average effects are simply assigned to alleles at random with respect to their frequency. The main experimental set-up consists of 10 replicate populations each of 1000 individuals that evolve over 3 generations with the recombination rate during the experiment being $1.4\times10^{-6}$. Simulations were also ran where one of the parameter was changed: either 3 or 5 replicates, 100 or 500 individuals, 1 or 5 generations and a recombination rate of $1.4\times10^{-7}$ or $1.4\times10^{-8}$. We plot the estimates against the true values on the log-log scale, with the best linear fit for each set of simulation parameters plotted as a dashed line (the solid black line is the 1:1 line). In the legend we give the average proportional difference between the estimate and true value (a value of 1 would be unbiased, a value under one indicates downwardly bias) with a star indicating significant bias at a 5\% significance threshold. The degree of bias may not be constant with respect to the true value of $V_a$. The deviation of the slope from one, on the log-log scale, we call the trend. When the trend is zero the proportional bias, if any, is constant with respect to $V_a$ (i.e. $\widehat{V_a}/V_a$ is constant). If the trend is positive it indicates that as $V_a$ increases $\widehat{V_a}/V_a$ becomes larger and if trend is negative it indicates that as $V_a$ increases $\widehat{V_a}/V_a$ gets smaller. A star indicates that the trend is significantly different from zero at a 5\% significance threshold.


<div class="fold s">
```{r }
dat<-read.csv("/Volumes/hadfield/Va_simulations/RESULTS_and_ANALYSES/No_burnin/Scale_0.033/Data_no_burnin.csv")


plot_res<-function(predictor=NULL){

  pred_names<-c("ngen_expt", "n_ind_exp", "n_cages", "r")
  real_names<-c("number of generations", "number of individuals", "number of replicates", "recombination rate")

  if(!predictor%in%pred_names){stop("predictor should be one of ngen_expt, n_ind_exp, n_cages or r")}

  delete<-rep(1, nrow(dat))

  if(predictor!="ngen_expt"){
    delete[dat$ngen_expt!=3]<-0
  }  
  if(predictor!="n_ind_exp"){
    delete[dat$n_ind_exp!=1000]<-0
  }  
  if(predictor!="n_cages"){
    delete[dat$n_cages!=10]<-0
  }  
  if(predictor!="r"){
    delete[dat$r!=1.4e-06]<-0
  }  
  delete[dat$vA_est>0.5]<-0


  dat.sub<-subset(dat, delete==1)
  colnames(dat.sub)[which(colnames(dat.sub)==predictor)]<-"p"
  model.sub1<-lm(log(vA_est)~as.factor(p)-1+offset(log(vA_true)), dat.sub)

  model.sub2<-lm(log(vA_est)~as.factor(p)-1+log(vA_true):as.factor(p)+offset(log(vA_true)), dat.sub)

 nlevels<-nlevels(as.factor(dat.sub$p))


 legend.names<-paste0(levels(as.factor(dat.sub$p)), ": average=", round(exp(coef(model.sub1)),2), c("", "*")[1+(coef(summary(model.sub1))[,4]<0.05)], ", trend=", round(coef(model.sub2)[nlevels+1:nlevels],2), c("", "*")[1+(coef(summary(model.sub2))[nlevels+1:nlevels,4]<0.05)])


  plot(log(vA_est)~log(vA_true), col=as.factor(p), data=dat.sub)
  abline(0,1)
  abline(coef(model.sub2)[1],1+coef(model.sub2)[4], lty=2, col=1)                   
  abline(coef(model.sub2)[2],1+coef(model.sub2)[5], lty=2, col=2)        
  abline(coef(model.sub2)[3],1+coef(model.sub2)[6], lty=2, col=3)

  legend("bottomright", fill=1:3, legend=legend.names, title=real_names[match(predictor, pred_names)])

}

plot_res("ngen_expt")
plot_res("n_ind_exp")
plot_res("n_cages")
plot_res("r")
```
</div>

The general pattern seems to be that there is downward bias as the amount of information decreases, either because the within-replicate variance increases because there is more drift (number of individuals per replicate is low) or the between replicate variance decreases because allele-frequencies change over a shorter amount of time (number of generations is low) or because the number of replicates is low. The proportional bias seems relatively constant, although there does seem to be some evidence that the downward bias is reduced as $V_a$ becomes larger (if bias is measured on the log (i.e. proportional) scale. 


# File Paths

Paths to various scripts that are used for running the simulations and extracting information from SLiM outputs. `base_path` specifies the path to all the scripts used for running simulations using SLiM and msprime - typically the "1_Simulations" folder in "Va_simulations". `analysis_path` specifies the path to the directory containing all scripts useful for analysing SLiM outputs: "Vw.Rmd", "Vw_sim_functions.Rmd", "2_Extract_mutations.py", and "3_Extract_genomes.py". `file_storage_path` is where the ?XXX files are stored? `slim_path` specifies the path to the folder of SLiM output.

<div class="fold s">
```{r }
if(Sys.info()["nodename"]!="SCE-BIO-C06645"){message("WARNING: Command line arguments required!!!")}

### On AC3 ###

if(Sys.info()["nodename"]%in%c("bigfoot", "bigshot", "bigbird", "bigyin", "biggar", "bigwig", "c1", "c2", "c3", "c4", "c5", "c6")){
  
  base_path = "/ceph/users/marun/Va_simulations/1_Simulations" 
  analysis_path = "/ceph/users/marun/Va_simulations/2_Analysis"
  file_storage_path = "/data/obbard/Va_simulations/analyses" # File storage path is the designated storage space on AC3 instead of the /home directory on qm
  
}

### On Vera ###

if(Sys.info()["nodename"]=="vera.bio.ed.ac.uk"){
  
  base_path = "/data/home/msamant/Manas/Va_simulations/Github/Va_simulations/1_Simulations" 
  analysis_path = "/data/home/msamant/Manas/Va_simulations/Github/Va_simulations/2_Analysis"  
  file_storage_path = base_path
  
}

### On Eddie ###

if(grepl("ecdf.ed.ac.uk", Sys.info()["nodename"])){
  base_path = "/home/msamant/Va_simulations/1_Simulations"
  analysis_path = "/home/msamant/Va_simulations/2_Analysis"
  file_storage_path = "/exports/eddie/scratch/msamant"
}

### On Manas's PC

if(Sys.info()["nodename"]=="SCE-BIO-C06645"){
  
  if(Sys.info()["sysname"]=="Linux"){   ## Local Wsl
    
    base_path = "/mnt/c/Users/msamant/Documents/GitHub/Va_simulations/1_Simulations"
    analysis_path = "/mnt/c/Users/msamant/Documents/GitHub/Va_simulations/2_Analysis" 
    file_storage_path = base_path
    
  }else{                                ## Local windows
    
    base_path = "C:/Users/msamant/Documents/GitHub/Va_simulations/1_Simulations" 
    analysis_path = "C:/Users/msamant/Documents/GitHub/Va_simulations/2_Analysis" 
    file_storage_path = base_path
  }
  
}

### On Jarrod's PC ###

if(Sys.info()["nodename"]=="sce-bio-c04553"){  
  base_path="~/Work/Va_simulations/1_Simulations"
  analysis_path = "~/Work/Va_simulations/2_Analysis"
  file_storage_path = base_path
  slim_path = "/Volumes/hadfield/Va_simulations/sim_files"
}else{
  slim_path = "/mnt/u/Datastore/CSCE/biology/groups/hadfield/Va_simulations/sim_files"
}


extract_genomes_path = file.path(analysis_path, "3_Extract_genomes.py")                                           ## Python script extracting mutations and genomes from the SLiM output file 
extract_mut_path = file.path(analysis_path, "2_Extract_mutations.py")                                             ## Python script extracting mutations from the SliM output file

slim_output_path = file.path(slim_path, "SLiM_outputs")
# Path to SLiM output              
slim_param_path = file.path(slim_path, "sim_params") 
# Path to SLiM simulation parameters

temp_files_path = file.path(file_storage_path, "temp_files")  
```
</div>

# Load packages and functions

```{r packages}
if(Sys.info()["nodename"]=="bigyin"){stop("Bigyin cannot run asreml-r. Use a different code.")}

library(MCMCglmm)
library(asreml)
library(Matrix)
#library(rmutil)
library(pryr) ## For tracking memory usage using mem_used()
library(bigalgebra)
library(RhpcBLASctl)

  
#################################
#### Load Jarrod's functions ####
#################################

functions_only=TRUE ## Read only the functions

#rmarkdown::render(file.path(analysis_path, "Vw.Rmd"), quiet=TRUE)

rmarkdown::render("~/Desktop/tmp/Vw.Rmd", quiet=TRUE)

##############################
### Load Manas's functions ###
##############################

rmarkdown::render(file.path(analysis_path, "Vw_sim_functions.Rmd"), quiet=TRUE)

set.seed(1)
```

# Get data

First enter the Set_ID of the simulations to be analysed

```{r }
Set_ID = "zero_test_bigyin_2024-10-09_16_53_28.860706_1.8969696969697e-07_1.4_1.4_1000_10_1_0_1"
```

and then extract data

```{r get_data, eval=run_get_data}

sim_data = extract_slim_data(Set_ID = Set_ID,
                             sim = 1,
                             slim_output_path = slim_output_path, 
                             sim_param_path = slim_param_path,
                             extract_genomes_path = extract_genomes_path, 
                             extract_mut_path = extract_mut_path,
                             mutations_path = temp_files_path, 
                             c_matrix_path = temp_files_path, 
                             randomise = TRUE,
                             verbose=FALSE)
```

# Analyse data



```{r analyse_data, eval=run_analyse_data}
parents_info = analyse_parents(c0 = sim_data$c0,  
                               list_alpha = sim_data$list_alpha,             
                               LDdelta=FALSE,         
                               SNPs = sim_data$SNPs,                   
                               RecombRate = sim_data$sim_params$r_expt,             
                               HapLength = sim_data$sim_params$sequence_length,              
                               AtleastOneRecomb=FALSE,
                               calc_nR=TRUE,
                               verbose=FALSE)
```

```{r plot_alpha}
plot_alpha_distribution(alpha = sim_data$list_alpha, p = colMeans(sim_data$c0), parameters=parents_info$parameters, pch=16, cex=0.3)
```

```{r plot_logit_alpha}

 parameters.logit<-alpha_distribution(alpha=sim_data$list_alpha, p=colMeans(sim_data$c0), logit=TRUE)

 plot_alpha_distribution(alpha = sim_data$list_alpha, p=colMeans(sim_data$c0), parameters=parameters.logit, pch=16, cex=0.3)
```
# Model parameters

```{r model_parameters}
# Analysis parameters
proj="BLoM" # projection type for allele frequencies: "LoM", "BLoM", "L" or "N"
LDdelta = FALSE
pa = 1
Vs = "LoNL" # "L" or "LoNL"
method="REML" # Can be "REML" or "MCMC"
randomise = TRUE # Should the reference allele be randomised for analysis?

# How is pdelta to be estimated? 
# Can be "optim" (using the function optim()), or "fixed" or "manual"(estimated by manually scanning a range of pdelta values)

pdelta_method = "optim" # "optim" or "manual" or "fixed" or "no_analysis". If this is "no_analysis", the estimate of Vw is not calculated, but the rest of the code still runs.

if(pdelta_method=="fixed"){
  pdelta = 0 # Can be specified to any value
}

if(pdelta_method=="optim"){
  pdelta = NA # This triggers the use of optim() inside the function Vw_model()
}

if(pdelta_method=="manual"){
  
  nseq<-20 # The number of times pdelta is to be varied 
  pdelta_l = -1 # Lower limit of pdelta
  pdelta_u = 1 # Upper limit of pdelta
  pdelta<-seq(pdelta_l, pdelta_u, length=nseq)
  
}

# How should bdelta[1] (intercept) and bdelta[2] (slope of (p-q)) be estimated

bdelta_method = "estimate"  # Can be "fixed" or "estimate"

if(bdelta_method=="estimate"){
  bdelta = c(NA, NA)
}else{
  bdelta = c(0, 0) # This only estimates the intercept while keeping the slope fixed at 0
}
```
Fit model

```{r fit_model, eval=run_model}

m1<-Vw_model(C0 = sim_data$c0,          # parental genotypes (rows individuals, columns loci, coded as 0, 1/2 or 1) 
             nR = parents_info$nR,         # matrix of non-recombinant probabilities between loci
             pbar1 = sim_data$pbar1,       # vector of allele frequencies at time-point 1
             ngen1= sim_data$ngen1,    # number of generations between parents and time-point 1
             pbar2 = sim_data$pbar2,       # vector of allele frequencies at time-point 2
             ngen2 = sim_data$ngen2,       # number of generations between parents and time-point 2
             nind = sim_data$sim_params$n_ind_exp,        # population size in each replicate
             proj=proj, # projection type for allele frequencies: "LoM", "BLoM", "L" or "N"
             LDdelta = LDdelta,
             pa = pa,
             pdelta = pdelta,
             bdelta = bdelta,
             Vs = Vs,
             method = method,
             L = parents_info$L,    # list with elements UL and DL
             svdL = parents_info$svdL,    # list with elements UL and DL
             tol = sqrt(.Machine$double.eps),
             save_tprojp=TRUE,
             verbose=FALSE)
```

# Extract estimates

```{r extract_estimates, eval=run_model}
vA_est = m1$Vw_est # Store the estimate from the model with the highest log likelihood
pdelta_est = m1$pdelta # The sample() functions ensures that only one value is selected in case there are multiple points with the highest LL
pdelta_var_est = m1$pdelta_var
bdelta_intercept_est = m1$bdelta[1]
bdelta_slope_est = m1$bdelta[2]
bdelta_var_est = paste(m1$bdelta_var[1,1], m1$bdelta_var[2,2], m1$bdelta_var[1,2], sep = "_")
sigma2delta_est = summary(m1$model)$varcomp[1,1]
```

Look at alpha-estimates under projected allele frequencies

```{r alpha_distribution)fits, eval=run_alpha}
 parameters.linear<-alpha_distribution(alpha=sim_data$list_alpha, p=colMeans(sim_data$c0), tprojp=m1$tprojp, save_model=TRUE)
 parameters.logit<-alpha_distribution(alpha=sim_data$list_alpha, p=colMeans(sim_data$c0), tprojp=m1$tprojp, logit=TRUE, save_model=TRUE)
```

```{r projected_plots}
plot_alpha_distribution(alpha = sim_data$list_alpha, p=colMeans(sim_data$c0), tprojp=m1$tproj, parameters=parameters.linear, pch=16, cex=0.3)

plot_alpha_distribution(alpha = sim_data$list_alpha, p=colMeans(sim_data$c0), tprojp=m1$tproj, parameters=parameters.logit, pch=16, cex=0.3)
```

Compare to Buffalo and Coop's method

```{r eval=run_bc}
est_Va_bc(sim_data$pbar1, sim_data$pbar2, parents_info$L, parents_info$nR, nrep=10)
```

