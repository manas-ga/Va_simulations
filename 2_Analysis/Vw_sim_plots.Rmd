---
title: "Vw_sim_plots"
author: "Manas GA"
date: "2024-12-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(ggplot2)
library(cowplot)
library(latex2exp)
```

The following code loads outputs of simulation analyses and makes figures for the manuscript. Simulation data is classified into sets, with the sets that are useful for the manuscript being  as follows (the number of simulations within each set are indicated inside brackets):

- Set_5 (900 simulations): All simplified simulations 
- Set_9 (100 simulations, each analysed in three different ways): The standard set for full simulations 
- Set_11 (100): Full simulations with 0.02 % beneficial mutations
- Set_14 (100): Full simulations with 2 % beneficial mutations
- Set_12 (200): Full simulations varying map length in th experiment
- Set_13 (176): Full simulations varying map length in history
- Set_15 (200): Full simulations varying the scale
- Set_N1 (396): Full simulations varying the map length in history (for simulations in which scale = 0.045)
- sanity_check (80): Simplified simulations with nearly free recombination in the experiment
- Set_16 (100): Testing B&C - simplified simulations with 50 replicate populations and map length in history = c(0.5, 5, 50, 100)
- Set_17 (69): Testing B&C - full simulations with 50 replicate populations and map length in history = c(0.5, 5, 50, 100)

Total = 2421



## Set paths

```{r paths}

### On Manas's PC ###

# EdiUni Datastore needs to be mounted via a vpn 
# Or works only on the University's network

if(Sys.info()["nodename"]=="SCE-BIO-C06645"){

  if(Sys.info()["sysname"]=="Linux"){
    
    data_path = "/mnt/u/Datastore/CSCE/biology/groups/hadfield/Va_simulations/4_analysed_data" ## Local Wsl
    output_path = "/mnt/c/Users/msamant/Documents/GitHub/Va_simulations/5_Manuscript_files/Manuscript_figures"
    
  }else{
    
    data_path = "U:/Datastore/CSCE/biology/groups/hadfield/Va_simulations/4_analysed_data" ## Local windows
    output_path = "C:/Users/msamant/Documents/GitHub/Va_simulations/5_Manuscript_files/Manuscript_figures"
  }
}


### On Jarrod's PC ###

# EdiUni Datastore needs to be mounted via a vpn 
# Or works only on the University's network

if(Sys.info()["nodename"]=="sce-bio-c04553"){  
  data_path = "/Volumes/hadfield/Va_simulations/4_analysed_data"
  output_path = "~/Work/Va_simulations/5_Manuscript_files/Manuscript_figures"
}

```

## Function to remove duplication

Some simulations were erroneously analysed twice. The following function takes a data frame for a set of simulations as input, and if there are any simulations analysed twice, retains the analysis performed earlier in time.

```{r function_deduplicate_sim_analyses}

deduplicate_sim_analyses = function(data_frame){

  for (set_id in unique(data_frame$Set_ID)){
    
    count = sum(data_frame$Set_ID == set_id)
    
    if(count>1){
      data_sim = data_frame[data_frame$Set_ID==set_id,]
      
      # Remove the nodename and the year from the analysis stamp and then identify the analysis which was performed later 
      
      max_time = max(sub(".*_2025-", "",  data_sim$analysis_stamp))
      analysis_to_be_deleted = data_sim$analysis_stamp[grep(max_time, data_sim$analysis_stamp)]
      
      # Delete this analysis
      
      data_frame = data_frame[data_frame$analysis_stamp!=analysis_to_be_deleted,]
      
    }
    
  }
  
  return(data_frame)
  
}
```

## Function to add recalculated true V_A (V_A_true_new), lost_va to a dataframe

These calculations were performed at a later stage and are stored in a separate file ("<data_path>/combined_data/new_va_calculation_combined.csv"). For every simulation in the input dataframe this functions looks up the row with the appropriate Set_ID in "new_va_calculation_combined.csv" and adds the V_A_true_new and other data pertaining to lost_va to the input dataframe.

```{r function_add_new_va_data}
add_new_va_data = function(new_va_data,    # Data frame storing the calculations of vA_true_new, lost_va, etc
                           target_data,    # Target dataframe to which this information is to be added
                           verbose = FALSE){   
  
  # Create empty columns in the target data
  
  target_data$vA_true_new = NA
  target_data$va_true_new = NA
  target_data$va_left = NA
  target_data$va_left_new = NA
  
  for(set_id in target_data$Set_ID){
    
    # Check if the set_id exists in new_va_data
  
   if(!set_id%in%new_va_data$Set_ID){
     if(verbose){warning(paste("Simulation ", set_id, " is missing from new_va_calculation_combined.csv", sep = ""))}
   }else{
     
      # Add data to target_data
      target_data[target_data$Set_ID == set_id,]$vA_true_new = new_va_data[new_va_data$Set_ID == set_id,]$vA_true_new
      target_data[target_data$Set_ID == set_id,]$va_true_new = new_va_data[new_va_data$Set_ID == set_id,]$va_true_new
      target_data[target_data$Set_ID == set_id,]$va_left = new_va_data[new_va_data$Set_ID == set_id,]$va_left
      target_data[target_data$Set_ID == set_id,]$va_left_new = new_va_data[new_va_data$Set_ID == set_id,]$va_left_new
       
     }
    
    
    
  }
  return(target_data)
}
```


## Function to make "standard" plot

Creates plots with four panels:
A. Estimate of V_A vs True V_A
B. Hisotgram of the estimates pf p_{\alpha}
C. Histogram of the estimates of (\beta)_{\alpha}^{(0)}
D. Histogram of the estimates of (\beta)_{\alpha}^{(1)}

```{r function_make_std_plots}
make_std_plots = function(data, 
                          alpha = FALSE, # If alpha = TRUE, alpha = eta + (1 - 2p)eta is used to calculate vA_true, i.e. vA_true_new is used in the plots. Otherwise, vA_true is used in the plots
                          font_size = 15, 
                          end_gen = 25000, 
                          data_in_title = FALSE){
  
  # vA_est ~ vA_true

p_main = ggplot(data, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true})) + 
  theme_bw() + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)")) + 
  theme(text = element_text(size = font_size)) 
  
# palpha_est histogram

p_palpha = ggplot(data, aes(x = palpha_est)) + 
  theme_bw() + 
  geom_histogram(color = "black", fill = "white") + 
  labs(x = TeX(r"(Estimate of $p_{\alpha} $)"), y = "Frequency") + 
  geom_vline(xintercept = 0, color = "red") +  
  geom_vline(xintercept = mean(data$palpha_est), linetype = "dashed") +
  theme(text = element_text(size = font_size)) 

# Residual variance

p_res_var = ggplot(data, aes(x = Residual_var)) + 
  theme_bw() + 
  geom_histogram(color = "black", fill = "white") + 
  labs(x = "Estimate of the residual variance", y = "Frequency") + 
  geom_vline(xintercept = 1, color = "red") + 
  geom_vline(xintercept = mean(data$Residual_var), linetype = "dashed") +
  theme(text = element_text(size = font_size)) 

# balpha_slope_est histogram

p_balpha_slope = ggplot(data, aes(x = balpha_slope_est)) + 
  theme_bw() + 
  geom_histogram(color = "black", fill = "white") + 
  labs(x = TeX(r"(Estimate of $\beta^{(1)}_{\bar{\alpha}}$)"), y = "Frequency") + 
  geom_vline(xintercept = 0, color = "red") + 
  geom_vline(xintercept = mean(data$balpha_slope_est), linetype = "dashed") +
  theme(text = element_text(size = font_size))

# Combine the four plots

p_combined = plot_grid(p_main, p_palpha, p_res_var, p_balpha_slope, labels = "AUTO")

if(data_in_title){

  # Title
  
  ml = unique(data$sequence_length*data$r)
  if(length(ml)>1){stop("The data set does not have the same map length in the burnin phase in every simulation.")}
  
  ml_expt = unique(data$sequence_length*data$r_expt)
  if(length(ml_expt)>1){stop("The data set does not have the same map length in the experiment in every simulation.")}
  
  end_gen = unique(data$end_gen)
  if(length(end_gen)>1){stop("The data doe not have have the same end_gen for every simulations")}
  
  if(end_gen==2){
    ml = unique(data$sequence_length*data$r_msp)
    if(length(ml)>1){stop("The data set does not have the same map length in the burnin phase in every simulation.")}
  }else{
    ml = unique(data$sequence_length*data$r)
    if(length(ml)>1){stop("The data set does not have the same map length in the burnin phase in every simulation.")}
  }
  
  mu_alpha = (data$shape)*(data$shape)
  
  title = ggdraw() + draw_label(paste("Map length in burnin = ", ml, " M, Map length in experiment = ", ml_expt, " M, scale = ", data$scale, sep = ""), hjust = 0.5, size = font_size)
  
  # Add title
  p_combined = plot_grid(title, p_combined, ncol = 1, rel_heights = c(0.1,1))
    
}

return(list(main = p_main, palpha = p_palpha, res_var = p_res_var, balpha_slope = p_balpha_slope,
            combined = p_combined))

  
}
```

Load the dataframe storing information on calculations of vA_true_new, va_true_new, va_lost, va_lost_new

```{r load_new_va_data}
d_new_va = read.csv(file.path(data_path, "combined_data/new_va_calculation_combined.csv"))
alpha = TRUE # If alpha = TRUE, alpha = eta + (1 - 2p)eta is used to calculate vA_true, i.e. vA_true_new is used in the plots. Otherwise, vA_true is used in the plots
corrected = TRUE
```


## Simplified simulations (simulations without burnin) (Set_5/Set_18) (Figure 1, Figure 2)

Selection coefficients were drawn from a gamma distribution (shape = 0.3, scale = 0.033) and assigned to mutations randomly. The recombination rate in the msprime simulation was 5.32e-07. Map length in the history phase of just 1 generation (eng_gen = 2) was 5.


Standard parameters:

Map length in the experiment phase (ml_exp) = 2 M
Number of individuals in the experiment (n_ind_exp) = 1000
Number of cages (n_cages) = 10
ngen2 = 4


```{r simplified_standard}
if(corrected){
  d_5 = read.csv(file.path(data_path, "combined_data/Set_18_corrected_output.csv"))
}else{
  d_5 = read.csv(file.path(data_path, "combined_data/Set_5_output.csv"))
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_5 = add_new_va_data(new_va_data=d_new_va, target_data=d_5, verbose=TRUE)

# Filter out the data where allele frequencies are sampled using simulate_pool_seq()

d_5 = d_5[grep("pool_seq", d_5$analysis_stamp, invert = TRUE, value = FALSE),]
d_5 = deduplicate_sim_analyses(d_5)

# Select data for the standard plot for simplified simulations
d_5_std = d_5[d_5$r_expt*d_5$sequence_length==2&d_5$n_ind_exp==1000&d_5$n_cages==10&d_5$ngen2==4,] # Data for the standard set

##################################################################################################
####### Standard plots (Set_5: ml_expt = 2, n_indxpt = 1000, n_cages = 10, ngen2 = 4) ############
##################################################################################################

################
### Figure 1 ###
################

p_nb_2_std = make_std_plots(d_5_std, alpha = alpha)$combined

title = ggdraw() + draw_label("Simplified simulations", hjust = 0.5, size = 30)
p_nb_2_std = plot_grid(title, p_nb_2_std, ncol = 1, rel_heights = c(0.1,1))


ggsave(p_nb_2_std, width = 8, height = 8, file = file.path(output_path, if(corrected){"Fig1_corrected.jpg"}else{"Fig1.jpg"}))
p_nb_2_std



```

We then vary map length in the experiment (ml_exp), population size in the experiment (n_ind_exp), the number of replicate populations (n_cages), and the generation when the experiment ends (ngen2) (ngen1 is set to 1 in the simulations) one at a time while keeping the other parameters fixed at their standard values.
```{r simplified_varying_parameters}

################
### Figure 2 ###
################

# The legends and plot windows are combined using plot_grid() in cowplot to ensure that all plot windows and legends have the same sizes for all plots irrespective of the length of the legend label

### ml_exp ###

d_5_ml_exp = d_5[d_5$n_ind_exp==1000&d_5$n_cages==10&d_5$ngen2==4,]
p_nb_2_ml_exp = ggplot(d_5_ml_exp, aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(sequence_length*r_expt))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length in\nmorgans \n(experiment)") + 
  scale_color_manual(values = c("#0072B2", "#999999", "#009E73")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)

legend_nb_2_ml_exp = get_legend(p_nb_2_ml_exp)
p_nb_2_ml_exp = plot_grid(p_nb_2_ml_exp + theme(legend.position = "none"),
                      legend_nb_2_ml_exp,
                      ncol = 2,
                      rel_widths = c(1.0, 0.3))
p_nb_2_ml_exp

### n_ind_exp ###
d_5_nind = d_5[d_5$r_exp==2e-6&d_5$n_cages==10&d_5$ngen2==4,]
p_nb_2_nind = ggplot(d_5_nind , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(n_ind_exp))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Population \nsize \n(experiment)") + 
  scale_color_manual(values = c("#0072B2", "#999999", "#009E73")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) 

legend_nb_2_nind = get_legend(p_nb_2_nind)
p_nb_2_nind = plot_grid(p_nb_2_nind + theme(legend.position = "none"),
                        legend_nb_2_nind,
                        ncol = 2,
                        rel_widths = c(1.0, 0.3))
p_nb_2_nind

### n_cages ###

d_5_ncages = d_5[d_5$r_exp==2e-6&d_5$n_ind_exp==1000&d_5$ngen2==4,]
p_nb_2_ncages = ggplot(d_5_ncages , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(n_cages))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Replicate \npopulations") + 
  scale_color_manual(values = c("#0072B2", "#999999", "#009E73")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) 

legend_nb_2_ncages = get_legend(p_nb_2_ncages)
p_nb_2_ncages = plot_grid(p_nb_2_ncages + theme(legend.position = "none"),
                          legend_nb_2_ncages,
                          ncol = 2,
                          rel_widths = c(1.0, 0.3))
p_nb_2_ncages

### ngen_expt ###

d_5_ngen2 = d_5[d_5$r_exp==2e-6&d_5$n_ind_exp==1000&d_5$n_cages==10,]
p_nb_2_ngen2 = ggplot(d_5_ngen2 , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(ngen2-ngen1))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = TeX(r"($\tau - t$)")) + 
  scale_color_manual(values = c("#0072B2", "#009E73", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) 

legend_nb_2_ngen2 = get_legend(p_nb_2_ngen2)
p_nb_2_ngen2 = plot_grid(p_nb_2_ngen2 + theme(legend.position = "none"),
                         legend_nb_2_ngen2,
                         ncol = 2,
                         rel_widths = c(1.0, 0.3))
p_nb_2_ngen2

### Combine the plots ###

p_nb_2_combined = plot_grid(p_nb_2_ml_exp, p_nb_2_nind, p_nb_2_ncages, p_nb_2_ngen2, labels = "AUTO")

title = ggdraw() + draw_label("Simplified simulations", hjust = 0.5, size = 30)

# Add title
p_nb_2_combined = plot_grid(title, p_nb_2_combined, ncol = 1, rel_heights = c(0.1,1))

p_nb_2_combined
ggsave(p_nb_2_combined, width = 12, height = 10, file = file.path(output_path, if(corrected){"Fig2_corrected.jpg"}else{"Fig2.jpg"}))
```

### Simplified simulations with dominance

```{r dimplified_dominance}

d_23 = read.csv(file.path(data_path, "combined_data/Set_23_corrected_output.csv"))
d_23 = add_new_va_data(new_va_data=d_new_va, target_data=d_23, verbose=TRUE)
d_23$k = gsub(".*=", x=d_23$sim, "")

p_nb_dom_main = ggplot(d_23, aes(y = vA_est, x = vA_true_new, color = k)) +
  theme_bw() + geom_point() + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Dominance (|k|)") +
  theme(text = element_text(size = 15))+ 
  scale_color_manual(values = c("#009E73","#0072B2", "#999999")) +
  geom_abline(slope = 1, intercept = 0) +
 theme(legend.position = "bottom")

p_nb_dom_palpha = ggplot(d_23, aes(y = palpha_est, x = k, fill = k)) +
  theme_bw() + geom_boxplot() + 
  labs(x = "Dominance (|k|)", y = TeX(r"(Estimate of $p_{\alpha} $)"), fill = "Dominance (|k|)") +
  theme(text = element_text(size = 15))+ 
  scale_fill_manual(values = c("#009E73", "#0072B2",  "#999999")) +
  geom_abline(slope = 0, intercept = 0, linetype = "dotdash") +
 theme(legend.position = "bottom")

p_nb_dom_balpha_slope = ggplot(d_23, aes(y = balpha_slope_est, x = k, fill = k)) +
  theme_bw() + geom_boxplot() + 
  labs(x = "Dominance (|k|)", y = TeX(r"(Estimate of $\beta^{(1)}_{\bar{\alpha}}$)"), fill = "Dominance (|k|)") +
  theme(text = element_text(size = 15))+ 
  scale_fill_manual(values = c("#009E73", "#0072B2",  "#999999")) +
  geom_abline(slope = 0, intercept = 0, linetype = "dotdash") +
 theme(legend.position = "bottom")

p_nb_dom_res_var = ggplot(d_23, aes(y = Residual_var, x = k, fill = k)) +
  theme_bw() + geom_boxplot() + 
  labs(x = "Dominance (|k|)", y = "Estimate of the residual variance", fill = "Dominance (|k|)") +
  theme(text = element_text(size = 15))+ 
  scale_fill_manual(values = c("#009E73", "#0072B2",  "#999999")) +
  geom_abline(slope = 0, intercept = 1, linetype = "dotdash") +
 theme(legend.position = "bottom")

legend_nb_dominance = get_plot_component(p_nb_dom_main + guides(color = guide_legend(nrow = 1)) + theme(legend.position = "bottom"), "guide-box-bottom") 

p_nb_dominance_combined = plot_grid(p_nb_dom_main + theme(legend.position = "none"),
                                    p_nb_dom_palpha + theme(legend.position = "none"),
                                    p_nb_dom_res_var + theme(legend.position = "none"),
                                    p_nb_dom_balpha_slope + theme(legend.position = "none"),
                                    labels = "AUTO", nrow = 2)
title_nb_dominance = ggdraw() + draw_label("Simplified simulations", hjust = 0.5, size = 30)

p_nb_dominance_combined = plot_grid(title_nb_dominance,
                                    p_nb_dominance_combined,
                                    legend_nb_dominance,
                                    nrow = 3, rel_heights = c(0.1, 1, 0.05))

ggsave(p_nb_dominance_combined, width = 10, height = 10, file = file.path(output_path, "Fig_S4A.jpg"))
```


## Full simulations with a burnin phase of 25000 generations 


### Set 9 (larger simulations (scale = 0.033): ml = 0.5, ml_exp = 2) (Figure 3)

The standard set for full simulations. 

Selection coefficients were drawn from a gamma distribution (shape = 0.3, scale = -0.033) and assigned to mutations randomly. No beneficial mutations. The forward simulation in the history phase was run for 25000 generations. The recombination rate in the msprime simulation was 5.32e-07. Map length in the history phase was 0.5 M, and the map length in the experiment was 2 M.

Number of individuals in the experiment (n_ind_exp) = 1000
Number of cages (n_cages) = 10
ngen2 = 4

The analyses for this set were performed using all.gp = FALSE and using the true N_E (i.e. using predict_Ne = TRUE)

```{r full_standard}

################
### Figure 3 ###
################

if(corrected){
  d_9 = read.csv(file.path(data_path, "combined_data/Set_9_corrected_output.csv")) # Data for the standard set
}else{
  d_9 = read.csv(file.path(data_path, "combined_data/Set_9_output.csv")) # Data for the standard set
}


# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_9 = add_new_va_data(new_va_data=d_new_va, target_data=d_9, verbose=TRUE)
# Remove the pool_seq data
d_9 = d_9[grep("pool_seq", d_9$analysis_stamp, invert = TRUE, value = FALSE),]

# Set 9 simulations were also renanalysed setting Ne_exp to c(1000, 1000) and setting all.gp = FALSE. Removing those rows.
d_9_std = d_9[d_9$all.gp==FALSE&d_9$Ne_exp!="1000_1000",]

p_b_std = make_std_plots(d_9_std, alpha = alpha)$combined
title = ggdraw() + draw_label("Full simulations", hjust = 0.5, size = 30)

p_b_std = plot_grid(title, p_b_std, ncol = 1, rel_heights = c(0.1,1))

ggsave(plot = p_b_std, width = 8, height = 8, file = file.path(output_path, if(corrected){"Fig3_corrected.jpg"}else{"Fig3.jpg"}))
p_b_std


```
### Simplified & Full simulations analysed after simulated_pool_seq sampling of allele frequencies (Figure S4)

```{r full_poolseq}
##################
### Simplified ###
##################

d_nb_poolseq = read.csv(file.path(data_path, "combined_data/Set_18_corrected_output.csv"))

# retain only the dataset with pool_seq
d_nb_poolseq = d_nb_poolseq[grep("pool_seq", d_nb_poolseq$analysis_stamp, invert = FALSE, value = FALSE),]

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_nb_poolseq = add_new_va_data(new_va_data=d_new_va, target_data=d_nb_poolseq, verbose=TRUE)

# Add the standard dataset
d_nb_poolseq = rbind(d_5_std, d_nb_poolseq)

d_nb_poolseq$Type = ifelse(grepl("poo", d_nb_poolseq$analysis_stamp),
                sapply(strsplit(d_nb_poolseq$analysis_stamp, "_"), function(x) paste(x[1:11], collapse = "_")),
                "Exact")

labels_nb_poolseq = c("Exact" = "Exact",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0" = expression(R[75]*C[1000]*V[0]),
                     "pool_seq_TRUE_read_length_75_coverage_100_V_logmean_0" = expression(R[75]*C[100]*V[0]),
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0.693147180559945" = expression(R[75]*C[1000]*V[log(2)]),
                     "pool_seq_TRUE_read_length_1_coverage_1000_V_logmean_0" = expression(R[1]*C[1000]*V[0]))

values_nb_poolseq = c("Exact" = "#009E73",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0" = "#0072B2",
                     "pool_seq_TRUE_read_length_75_coverage_100_V_logmean_0" ="#999999",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0.693147180559945" = "#E59866",
                     "pool_seq_TRUE_read_length_1_coverage_1000_V_logmean_0" = "#D01C8B")

p_nb_poolseq = ggplot(d_nb_poolseq, aes(y = vA_est, x = vA_true_new, color = Type)) +
  theme_bw() + geom_point() + geom_abline(slope = 1, intercept = 0) + 
  scale_color_manual(values = values_nb_poolseq, labels = labels_nb_poolseq) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Pool-seq") +
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(legend.position = "bottom") + ggtitle("Simplified simulations") + theme(plot.title = element_text(hjust = 0.5))


############
### Full ###
############

d_b_poolseq = read.csv(file.path(data_path, "combined_data/Set_9_corrected_output.csv"))

# retain only the dataset with pool_seq
d_b_poolseq = d_b_poolseq[grep("pool_seq", d_b_poolseq$analysis_stamp, invert = FALSE, value = FALSE),]

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_b_poolseq = add_new_va_data(new_va_data=d_new_va, target_data=d_b_poolseq, verbose=TRUE)

# Analyses with a pool_seq coverage of 100 were accidentally analysed twice
# Removing the analyses run on ac3

d_b_poolseq = d_b_poolseq[grep(".ecdf.ed.ac.uk", d_b_poolseq$analysis_stamp),]

# Add the standard dataset
d_b_poolseq = rbind(d_9_std, d_b_poolseq)

d_b_poolseq$Type = ifelse(grepl("poo", d_b_poolseq$analysis_stamp),
                sapply(strsplit(d_b_poolseq$analysis_stamp, "_"), function(x) paste(x[1:11], collapse = "_")),
                "Exact")
labels_b_poolseq = c("Exact" = "Exact",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0" = expression(R[75]*C[1000]*V[0]),
                     "pool_seq_TRUE_read_length_75_coverage_100_V_logmean_0" = expression(R[75]*C[100]*V[0]),
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0.693147180559945" = expression(R[75]*C[1000]*V[log(2)]),
                     "pool_seq_TRUE_read_length_1_coverage_1000_V_logmean_0" = expression(R[1]*C[1000]*V[0]))

values_b_poolseq = c("Exact" = "#009E73",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0" = "#0072B2",
                     "pool_seq_TRUE_read_length_75_coverage_100_V_logmean_0" ="#999999",
                     "pool_seq_TRUE_read_length_75_coverage_1000_V_logmean_0.693147180559945" = "#E59866",
                     "pool_seq_TRUE_read_length_1_coverage_1000_V_logmean_0" = "#D01C8B")


p_b_poolseq = ggplot(d_b_poolseq, aes(y = vA_est, x = vA_true_new, color = Type)) +
  theme_bw() + geom_point() + geom_abline(slope = 1, intercept = 0) + 
  scale_color_manual(values = values_b_poolseq, labels = labels_b_poolseq) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Pool-seq") +
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
 theme(legend.position = "bottom") + ggtitle("Full simulations") + theme(plot.title = element_text(hjust = 0.5))

################
### Combined ###
################

# Extract legend

legend_poolseq = get_plot_component(p_b_poolseq + guides(color = guide_legend(nrow = 1)) + theme(legend.position = "bottom"), "guide-box-bottom") 

# Combine without labels

p_pool_seq_combined = plot_grid(p_nb_poolseq + theme(legend.position = "none"),
                                p_b_poolseq + theme(legend.position = "none"),
                                labels = "AUTO")

# Add the legend

p_pool_seq_combined = plot_grid(p_pool_seq_combined,
                                legend_poolseq,
                                nrow = 2, rel_heights = c(1, 0.1))

# Save file

ggsave(plot = p_pool_seq_combined, width = 8, height = 5, file = file.path(output_path, "FigS5.jpg"))
p_pool_seq_combined


```


We then vary various parameters one at a time while keeping the others fixed to their values for the previous set.

### Varying the ratio of beneficial:deleterious mutations (scale = 0.033) (Figure 4C)

```{r full_varying_mut_ratio}
if(corrected){
  d_11 = read.csv(file.path(data_path, "combined_data/Set_11_corrected_output.csv")) # Data for the set with mut_ratio = 0.0002
  d_14 = read.csv(file.path(data_path, "combined_data/Set_14_corrected_output.csv")) # Data for the set with mut_ratio = 0.02
  
}else{
  d_11 = read.csv(file.path(data_path, "combined_data/Set_11_output.csv")) # Data for the set with mut_ratio = 0.0002
  d_14 = read.csv(file.path(data_path, "combined_data/Set_14_output.csv")) # Data for the set with mut_ratio = 0.02
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_11 = add_new_va_data(new_va_data=d_new_va, target_data=d_11, verbose=TRUE)

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_14 = add_new_va_data(new_va_data=d_new_va, target_data=d_14, verbose=TRUE)

# Combined plot for proportion of beneficial mutations

p_ben_0.033 = ggplot(rbind(d_9_std, d_11, d_14), aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(format(mut_ratio, scientific = FALSE)))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = TeX(r"($\mu_{ben} : \mu_{del}$)")) + 
  scale_color_manual(values = c("#009E73", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5))

legend_ben = get_legend(p_ben_0.033)

p_ben_0.033 = plot_grid(p_ben_0.033 + theme(legend.position = "none"),
                        legend_ben,
                        ncol = 2,
                        rel_widths = c(1, 0.3))
p_ben_0.033
```

### Varying the map length in the experiment phase (scale = 0.033): ml_exp = c(0.01, 0.2, 2), mut_ratio = 0 (Figure 4A)

```{r full_varying_ml_exp}
if(corrected){
  d_12 = read.csv(file.path(data_path, "combined_data/Set_12_corrected_output.csv")) # Data when ml_exp was varied for scale = 0.033
}else{
  d_12 = read.csv(file.path(data_path, "combined_data/Set_12_output.csv")) # Data when ml_exp was varied for scale = 0.033
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_12 = add_new_va_data(new_va_data=d_new_va, target_data=d_12, verbose=TRUE)

d_ml_exp = rbind(d_9_std, d_12)

p_ml_exp_0.033 = ggplot(d_ml_exp , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(sequence_length*r_expt))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(experiment)") + 
  scale_color_manual(values = c("#0072B2", "#999999", "#009E73")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5)) 


# When combining such plots, varying legend sizes can result in misaligned plots
# Standardising the size of the plot and the space allocated to the legend by extracting the legend and then combining the legend-less plot and the legend in a standardised way

legend_ml_exp_0.033 = get_legend(p_ml_exp_0.033)
p_ml_exp_0.033 = plot_grid(p_ml_exp_0.033 + theme(legend.position = "none"),
                           legend_ml_exp_0.033,
                           ncol = 2,
                           rel_widths = c(1, 0.3))
p_ml_exp_0.033

```

### Varying the scale of the gamma distribution from which mutations are drawn in the simulation (deleterious mutations only) (scale = c(0.033, 0.045, 0.1)) (Figure 4D)

```{r full_varying_scale}
if(corrected){
  # Load the data for Set_15 in which mut_ratio was 0.0002 and 0.02
  d_15 = read.csv(file.path(data_path, "combined_data/Set_15_corrected_output.csv"))
}else{
  # Load the data for Set_15 in which mut_ratio was 0.0002 and 0.02
  d_15 = read.csv(file.path(data_path, "combined_data/Set_15_output.csv"))  
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_15 = add_new_va_data(new_va_data=d_new_va, target_data=d_15, verbose=TRUE)
# Combine with the data of the standard set i.e. mut_ratio = 0
d_scale = rbind(d_9_std, d_15)
# Some simulations were erroneously analysed twice, in such case retain only the first analysis
d_scale = deduplicate_sim_analyses(d_scale)

p_scale = ggplot(d_scale , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(scale))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = TeX(r"($\eta_{scale}$)")) + 
  scale_color_manual(values = c("#009E73", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5)) 

# When combining such plots, varying legend sizes can result in mesaligned plots
# Standardising the size of the plot and the space allocated to the legend by extractig the legend and then combining the legend-less plot and the legend in a standardised way

legend_scale = get_legend(p_scale)

p_scale = plot_grid(p_scale + theme(legend.position = "none"),
                    legend_scale,
                    ncol = 2,
                    rel_widths = c(1, 0.3))

p_scale

```

### Varying the map length in the history phase (ml = c(0.5, 5, 50, 250)) (Figure 4B)

```{r full_varying_ml_history}

if(corrected){
  d_13 = read.csv(file.path(data_path, "combined_data/Set_13_corrected_output.csv"))
}else{
  d_13 = read.csv(file.path(data_path, "combined_data/Set_13_output.csv"))
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_13 = add_new_va_data(new_va_data=d_new_va, target_data=d_13, verbose=TRUE)

# Combine with the standard data set

d_ml_history = rbind(d_9_std, d_13)

p_b_0.033_ml = ggplot(d_ml_history , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(sequence_length*r))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5))

# When combining such plots, varying legend sizes can result in mesaligned plots
# Standardising the size of the plot and the space allocated to the legend by extractig the legend and then combining the legend-less plot and the legend in a standardised way

legend_b_0.033_ml = get_legend(p_b_0.033_ml)
p_b_0.033_ml = plot_grid(p_b_0.033_ml + theme(legend.position = "none"),
                           legend_b_0.033_ml,
                           ncol = 2,
                           rel_widths = c(1, 0.3))

p_b_0.033_ml

```

## The standard set of full simulations (with burnin) (scale = 0.033) analysed with all.gp = FALSE (standard) or all.gp = TRUE (gametic phase LD not used) (Figure 4E)

```{r full_varying_all.gp}

d_9_nstd = d_9[d_9$all.gp==TRUE&d_9$Ne_exp!="1000_1000",]

# In d_9_nstd there are some simulations that were analysed twiced
# Retaining only the analysis performed first

d_9_nstd = deduplicate_sim_analyses(d_9_nstd)

# Combine with the standard data set (i.e. analyses in which all.gp=FALSE)
d_all.gp = rbind(d_9_std, d_9_nstd)

all.gp_labs = c(TeX(r"(${\bf L}^{'}_{0} + \frac{ r_{ij} \times{\bf L}^{''}_{0}}{1-r_{ij}}$)"), TeX(r"($\bf L_0$)"))
names(all.gp_labs) = c(FALSE, TRUE)

p_all.gp = ggplot(d_all.gp, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = all.gp)) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = TeX(r"($\tilde{\bf L}_0$)")) + 
  scale_color_manual(values = c("#009E73", "#0072B2"), labels = all.gp_labs) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5))

# When combining such plots, varying legend sizes can result in mesaligned plots
# Standardising the size of the plot and the space allocated to the legend by extractig the legend and then combining the legend-less plot and the legend in a standardised way

legend_all.gp = get_legend(p_all.gp)

p_all.gp = plot_grid(p_all.gp + theme(legend.position = "none"),
                     legend_all.gp,
                     ncol = 2,
                     rel_widths = c(1, 0.3))

p_all.gp



```

## The standard set of full simulations (with burnin) (scale = 0.033) analysed with Ne = nind = 1000 (Figure 4F)

```{r full_varying_NE}

d_9_fixed_Ne = d_9[d_9$all.gp==FALSE&d_9$Ne_exp=="1000_1000",]

d_9_Ne = rbind(d_9_std, d_9_fixed_Ne)

# The Ne_exp contains the Ne in as a vector of length two separated by "_". The first element is the Ne in the first generation after the parents generation when there is no selection. The second element is the Ne in between ngen1 to ngen2 when selection operates. Here we select only the element 2.

# Create labels for Ne_type
Ne_type = unique(d_9_Ne$Ne_exp)
Ne_type_labs = rep(NA, length(Ne_type))

for(i in 1:length(Ne_type)){
  Ne_type_labs[i] = round(as.numeric(unlist(strsplit(Ne_type[i], "_"))[2]), 2)
  nind_exp = unique(d_9_Ne[d_9_Ne$Ne_exp==Ne_type[i],]$n_ind_exp)
  
  if(Ne_type_labs[i]==nind_exp){
    Ne_type_labs[i] = paste("N:", Ne_type_labs[i])
  }else{
      Ne_type_labs[i] = paste("True:", Ne_type_labs[i])
      }
}

names(Ne_type_labs) = Ne_type

p_Ne = ggplot(d_9_Ne, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = Ne_exp)) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = TeX(r"($N_E$)")) + 
  scale_color_manual(values = c("#0072B2", "#009E73"), labels = Ne_type_labs) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5))

legend_Ne = get_legend(p_Ne)

p_Ne = plot_grid(p_Ne + theme(legend.position = "none"),
                 legend_Ne,
                 ncol = 2,
                 rel_widths = c(1, 0.3))

#################
### Figure S3 ###
#################

# plot residual variance

p_Ne_res = ggplot(d_9_Ne, aes(y = Residual_var, x = Ne_exp)) +
  theme_bw() + 
  geom_boxplot() +
  labs(y = "Residual variance", x = TeX(r"($N_E$)")) +
  scale_x_discrete(labels = Ne_type_labs) +
  theme(text = element_text(size = 15))
  
ggsave(p_Ne_res, width = 5, height = 5, file = file.path(output_path, if(corrected){"FigS3_corrected.jpg"}else{"FigS3.jpg"}))

p_Ne
p_Ne_res


```


### Combine plots for large (scale = 0.033) full simulations (with burnin) (Figure 4)

```{r full_combine_plots}
################
### Figure 4 ###
################

p_b_0.033_combined = plot_grid(p_ml_exp_0.033, p_b_0.033_ml, p_ben_0.033, p_scale, p_all.gp, p_Ne, ncol = 2, labels = "AUTO")

title = ggdraw() + draw_label("Full simulations", hjust = 0.5, size = 30)

# Add title
p_b_0.033_combined = plot_grid(title, p_b_0.033_combined, ncol = 1, rel_heights = c(0.1,1))
p_b_0.033_combined

ggsave(p_b_0.033_combined, width = 12, height = 12, file = file.path(output_path, if(corrected){"Fig4_corrected.jpg"}else{"Fig4.jpg"}))


```

### Set_N1 (scale = 0.045): ml = c (5, 50, 250), ml_exp = 2, mut_ratio = 0 (Figure S1)

Varying map length in history, but for \eta_{scale} = 0.045

```{r full_varying_ml_scale_0.045}
#################
### Figure S1 ###
#################
if(corrected){
  d_N1 = read.csv(file.path(data_path, "combined_data/Set_N1_corrected_output.csv"))
}else{
  d_N1 = read.csv(file.path(data_path, "combined_data/Set_N1_output.csv"))
}

# Add calculations of vA_true_new, va_true_new, va_lost, va_lost_new
d_N1 = add_new_va_data(new_va_data=d_new_va, target_data=d_N1, verbose=TRUE)

### ml ###

p_b_0.045_ml = ggplot(d_N1 , aes(y=vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = factor(sequence_length*r))) +
  theme_bw() + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans\n(history)", title = TeX(r"($\eta_{scale}$ = 0.045)")) + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) +
  theme(plot.title = element_text(hjust = 0.5))

p_b_0.045_ml

ggsave(p_b_0.045_ml, width = 6, height = 5, file = file.path(output_path, if(corrected){"FigS1_corrected.jpg"}else{"FigS1.jpg"}))

```

## Additive genic variance lost during the experiment (Figure S2)

Plot the fraction of the initial additive genic variance lost by the end of the experiment as a function of non-neutral \eta_{scale}. Plot the error in our estimates of V_A as a function of the V_a lost in the simulations, colour-coded by \eta_{scale}. Then, identify the simulations with the greatest and smallest losses and plot locuswise V_a lost vs abs(\alpha) for these simulations. Finally, divide \alpha into intervals of 0.01, for each interval calculate the cumulative loss in V_a for the simulations with the minimum and maximum losses.

```{r va_lost}

##############
# Figure S2A #
##############

plot_lost_va = ggplot(d_scale, aes(y = if(alpha){((va_true_new - va_left_new)/va_true_new)}else{((va_true - va_left)/va_true)}, x = factor(round(scale, digits = 4)), fill = factor(round(scale, digits = 4)))) +
  theme_bw() +
  geom_boxplot() +
  labs(y = TeX(r"(Fraction of the total $V_a(0)$ lost)"), x = TeX(r"($\eta_{scale}$)"), fill  = TeX(r"($\eta_{scale}$)")) +
  theme(text = element_text(size = 15)) +
  scale_fill_manual(values = c("#009E73", "#0072B2", "#999999"))  +
  theme(legend.position = "bottom")

##############
# Figure S2B #
##############

# Does abs_va_lost explain the bias in our estimates?

plot_lost_va_bias = ggplot(d_scale, aes(y = if(alpha){vA_est - vA_true_new}else{vA_est - vA_true},
                                        x = if(alpha){va_true_new - va_left_new}else{va_true - va_left}, 
                                        color = factor(round(scale, digits = 4)))) +
  theme_bw() +
  geom_point() +
  labs(y = TeX(r"(Estimate of $V_A$ - True $V_A$)"),x = TeX(r"(Total $V_a$ lost)"), color = TeX(r"($\eta_{scale}$)")) +
  theme(text = element_text(size = 15)) +
  geom_abline(slope = -1, intercept = 0) + 
  scale_color_manual(values = c("#009E73", "#0072B2", "#999999"))  +
  theme(legend.position = "bottom")

##############
# Figure S2C #
##############

# Identify the simulation with the greatest absolute loss in V_a

if(alpha){
  max_loss_sim = d_scale[which((d_scale$va_true_new - d_scale$va_left_new) == max(d_scale$va_true_new - d_scale$va_left_new)),]$Set_ID}else{
  max_loss_sim = d_scale[which((d_scale$va_true - d_scale$va_left) == max(d_scale$va_true - d_scale$va_left)),]$Set_ID  
  }

message("Simulation with the geratest absolute loss in initial additive genic variance:")
max_loss_sim
max_loss_sim_vA_true = if(alpha){d_scale[d_scale$Set_ID==max_loss_sim,]$vA_true_new}else{d_scale[d_scale$Set_ID==max_loss_sim,]$vA_true}
message(paste("True V_A =", max_loss_sim_vA_true))

message(paste("Lost V_a =", if(alpha){d_scale[d_scale$Set_ID==max_loss_sim,]$va_true_new - d_scale[d_scale$Set_ID==max_loss_sim,]$va_left_new}else{d_scale[d_scale$Set_ID==max_loss_sim,]$va_true - d_scale[d_scale$Set_ID==max_loss_sim,]$va_left}))

# Identify the simulation with the smallest absolute loss in V_a
# However, limit only to simulations for which vA_true (or vA_true_new) is close to max_loss_sim_vA_true

d_scale1 = d_scale[if(alpha){which((max_loss_sim_vA_true - 0.001) <= d_scale$vA_true_new & d_scale$vA_true_new<= (max_loss_sim_vA_true + 0.001))}else{which((max_loss_sim_vA_true - 0.001) <= d_scale$vA_true & d_scale$vA_true_new <= (max_loss_sim_vA_true + 0.001))},]

if(alpha){
  min_loss_sim = d_scale1[which((d_scale1$va_true_new - d_scale1$va_left_new) == min(d_scale1$va_true_new - d_scale1$va_left_new)),]$Set_ID}else{
  min_loss_sim = d_scale1[which((d_scale1$va_true - d_scale1$va_left) == min(d_scale1$va_true - d_scale1$va_left)),]$Set_ID  
  }
message("Simulation with the smallest absolute loss in initial additive genic variance:")
min_loss_sim
message(paste("True V_A =", if(alpha){d_scale[d_scale$Set_ID==min_loss_sim,]$vA_true_new}else{d_scale[d_scale$Set_ID==min_loss_sim,]$vA_true}))
message(paste("Lost V_a =", if(alpha){d_scale[d_scale$Set_ID==min_loss_sim,]$va_true_new - d_scale[d_scale$Set_ID==min_loss_sim,]$va_left_new}else{d_scale[d_scale$Set_ID==min_loss_sim,]$va_true - d_scale[d_scale$Set_ID==min_loss_sim,]$va_left}))

# Load finescale data for these two simulations

# List names of files containing finescale data for all sims

finescale_file_list = list.files(pattern = ".*finescale.*.csv$", full.names = TRUE, path = data_path)

d_finescale_max <- read.csv(finescale_file_list[grepl(max_loss_sim, finescale_file_list)][1])
d_finescale_min <- read.csv(finescale_file_list[grepl(min_loss_sim, finescale_file_list)][1])

# Calculate locuswise_va_lost

d_finescale = rbind(d_finescale_max, d_finescale_min)

d_finescale$locuswise_va_lost = d_finescale$locuswise_va_true - d_finescale$locuswise_va_left
d_finescale$locuswise_va_lost_new = d_finescale$locuswise_va_true_new - d_finescale$locuswise_va_left_new

d_finescale$lost_va_type = ifelse(d_finescale$Set_ID==min_loss_sim, "Min.", "Max.")


# Restricting to selected loci only
d_finescale_sel = d_finescale[d_finescale$list_alpha!=0,]

plot_finescale_va_lost = ggplot(d_finescale_sel, aes(y = if(alpha){locuswise_va_lost_new}else{locuswise_va_lost},                                                      x = if(alpha){abs(list_alpha_new)}else{abs(list_alpha)}, 
                                                     color = lost_va_type)) +
  theme_bw() +
  geom_point() +
  labs(y = TeX(r"($V_a$ lost at a locus$)"), x = if(alpha){TeX(r"($|\alpha|$)")}else{TeX(r"($|\eta|$)")}, color = "Simulation type") +
  theme(text = element_text(size = 15)) +   
  theme(legend.position = "bottom") +
  scale_color_manual(values = c("Min." = "#009E73", "Max." = "#999999"),
    labels = c("Min." = TeX(r"(Min. $V_a$ lost)"), "Max." = TeX(r"(Max. $V_a$ lost)"))  # Custom legend labels
  ) +
  geom_line(aes(x = seq(0, 1.2, length = nrow(d_finescale_sel)), y = 0.5*(1/2000)*(1999/2000)*seq(0, 1.2, length = nrow(d_finescale_sel))^2), linewidth = 0.1, color = "black")

plot_finescale_va_lost  

##############
# Figure S2D #
##############

d_finescale_sel$list_alpha_cat = abs(round(d_finescale_sel$list_alpha, 2))
d_finescale_sel$list_alpha_new_cat = abs(round(d_finescale_sel$list_alpha_new, 2))

if(alpha){
  d_summed_lost_va = aggregate(cbind(locuswise_va_true_new, locuswise_va_lost_new) ~ list_alpha_new_cat*lost_va_type, data = d_finescale_sel, FUN = "sum")
  
  d_summed_lost_va$fract_va_lost = d_summed_lost_va$locuswise_va_lost_new/d_summed_lost_va$locuswise_va_true_new
  
}else{
  d_summed_lost_va = aggregate(cbind(locuswise_va, locuswise_va_lost) ~ list_alpha_cat*lost_va_type, data = d_finescale_sel, FUN = "sum")
}


plot_categoriwise_va_lost = ggplot(d_summed_lost_va, aes(y = locuswise_va_lost_new,                                                      x = if(alpha){list_alpha_new_cat}else{list_alpha_cat}, 
                                                       fill = lost_va_type)) +
    theme_bw() +
    geom_bar(stat = "Identity", position = position_dodge(preserve = "single")) +
    labs(y = TeX(r"(Total $V_a$ lost at groups of loci)"), x = if(alpha){TeX(r"($|\alpha|$)")}else{TeX(r"($|\eta|$)")}, fill = "Simulation type") +
    theme(text = element_text(size = 15)) +   
    theme(legend.position = "bottom") +
    scale_fill_manual(values = c("Min." = "#009E73", "Max." = "#999999"),
      labels = c("Min." = TeX(r"(Min. $V_a$ lost)"), "Max." = TeX(r"(Max. $V_a$ lost)"))  # Custom legend labels
    ) 
  plot_categoriwise_va_lost
  
##############
# Figure S2E # (not included)
##############
  
  plot_categoriwise_fract_va_lost = ggplot(d_summed_lost_va, aes(y = fract_va_lost,                                                      x = if(alpha){list_alpha_new_cat}else{list_alpha_cat}, 
                                                       fill = lost_va_type)) +
    theme_bw() +
    geom_bar(stat = "Identity", position = position_dodge(preserve = "single")) +
    labs(y = TeX(r"(Fraction $V_a$ lost at groups of loci)"), x = if(alpha){TeX(r"($|\alpha|$)")}else{TeX(r"($|\eta|$)")}, fill = "Simulation type") +
    theme(text = element_text(size = 15)) +   
    theme(legend.position = "bottom") +
    scale_fill_manual(values = c("Min." = "#009E73", "Max." = "#999999"),
      labels = c("Min." = TeX(r"(Min. $V_a$ lost)"), "Max." = TeX(r"(Max. $V_a$ lost)"))  # Custom legend labels
    ) 
  plot_categoriwise_fract_va_lost
  
#################  
### Figure S2 ###
#################

### Combine the four plots ###

va_lost_combined_plot = plot_grid(plot_lost_va, plot_lost_va_bias, plot_finescale_va_lost, plot_categoriwise_va_lost, ncol = 2, nrow = 2, labels = "AUTO")
va_lost_combined_plot
ggsave(va_lost_combined_plot, width = 10, height = 10, file = file.path(output_path, if(corrected){"FigS2_corrected.jpg"}else{"FigS2.jpg"}))

### Calculate the the fraction of total amount of V_a lost at loci for alpha > 0.3 in the "Max." (V_a lost) simulation

message("The fraction of V_a lost in the 'Max.' simulation at loci with alphas larger than 0.3 = ")

if(alpha){
  sum(d_summed_lost_va[d_summed_lost_va$lost_va_type=="Max."&d_summed_lost_va$list_alpha_new_cat>0.3,]$locuswise_va_lost_new)/sum(d_summed_lost_va[d_summed_lost_va$lost_va_type=="Max.",]$locuswise_va_lost_new)
}else{
  sum(d_summed_lost_va[d_summed_lost_va$lost_va_type=="Max."&d_summed_lost_va$list_alpha_cat>0.3,]$locuswise_va_lost)/sum(d_summed_lost_va[d_summed_lost_va$lost_va_type=="Max.",]$locuswise_va_lost)
}

message("The fraction of non-neutral loci in the 'Max.' simulation with alphas larger than 0.3 = ")

if(alpha){
  nrow(d_finescale_sel[d_finescale_sel$lost_va_type=="Max."&d_finescale_sel$list_alpha_new>0.3,])/nrow(d_finescale_sel[d_finescale_sel$lost_va_type=="Max.",])
}else{
   nrow(d_finescale_sel[d_finescale_sel$lost_va_type=="Max."&d_finescale_sel$list_alpha>0.3,])/nrow(d_finescale_sel[d_finescale_sel$lost_va_type=="Max.",]) 
  }

message("Mean |alpha| for non neutral loci in the 'Max.' simulation = ")

if(alpha){
    mean(abs(d_finescale_sel[d_finescale_sel$lost_va_type=="Max.",]$list_alpha_new))
}else{
    mean(abs(d_finescale_sel[d_finescale_sel$lost_va_type=="Max.",]$list_alpha))
  }


```

## Comparison to B&C

### Simplified simulations (Figure 5)

```{r simplified_comparison_BC}
if(corrected){
  d_16 = read.csv(file.path(data_path, "combined_data/Set_16_corrected_output.csv"))
}else{
  d_16 = read.csv(file.path(data_path, "combined_data/Set_16_output.csv"))
}

d_16 = add_new_va_data(new_va_data=d_new_va, target_data=d_16, verbose=TRUE)
d_16$vA_BC_est_ia = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[2])}))
d_16$vA_BC_est_iia = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[3])}))
d_16$vA_BC_est_iiia = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[4])}))

d_16$vA_BC_est_ib = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[6])}))
d_16$vA_BC_est_iib = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[7])}))
d_16$vA_BC_est_iiib = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[8])}))

d_16$assumption_G_test = unlist(lapply(d_16$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[12])}))

###############################
### vA_est using our method ###
###############################

p_bc_simplified_us = ggplot(d_16, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle("Our method") + theme(plot.title = element_text(hjust = 0.5)) 

#####################################
### vA_est using B&C Approach i-a ### (B+Ib+N+)
#####################################

p_bc_simplified_bc_ia = ggplot(d_16, aes(y = vA_BC_est_ia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^+Ib^+N^+$)")) + theme(plot.title = element_text(hjust = 0.5)) 

######################################
### vA_est using B&C Approach ii-a ### (B0Ib+N+)
######################################

p_bc_simplified_bc_iia = ggplot(d_16, aes(y = vA_BC_est_iia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^+N^+$)")) + theme(plot.title = element_text(hjust = 0.5))

#######################################
### vA_est using B&C Approach iii-a ###  (B0Ib0N+)
#######################################

p_bc_simplified_bc_iiia = ggplot(d_16, aes(y = vA_BC_est_iiia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^0N^+$)")) + theme(plot.title = element_text(hjust = 0.5))


#####################################
### vA_est using B&C Approach i-b ### (B+Ib+N0)
#####################################

p_bc_simplified_bc_ib = ggplot(d_16, aes(y = vA_BC_est_ib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^+Ib^+N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

######################################
### vA_est using B&C Approach ii-b ### (B0Ib+N0)
######################################

p_bc_simplified_bc_iib = ggplot(d_16, aes(y = vA_BC_est_iib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^+N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

#######################################
### vA_est using B&C Approach iii-b ### (B0Ib0N0)
#######################################

p_bc_simplified_bc_iiib = ggplot(d_16, aes(y = vA_BC_est_iiib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^0N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

###################################
### Departure from Assumption G ###
###################################

p_bc_simplified_assumption_G_test = ggplot(d_16, aes(y = assumption_G_test, x = as.factor(sequence_length*r_msp), fill = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_boxplot() + 
  labs(y = "Deviation from Assumption G", x = "Map length in morgans (history)") + 
  scale_fill_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 12)) + ggtitle(" ")


### Capture the legend and combine the plots

legend_16 = get_legend(p_bc_simplified_us)

p_bc_simplified_combined = plot_grid(p_bc_simplified_bc_ia + theme(legend.position = "none"), 
                                     p_bc_simplified_bc_iia + theme(legend.position = "none"),
                                     p_bc_simplified_bc_iiia + theme(legend.position = "none"), 
                                     p_bc_simplified_us + theme(legend.position = "none"),
                                     p_bc_simplified_bc_ib + theme(legend.position = "none"), 
                                     p_bc_simplified_bc_iib + theme(legend.position = "none"),
                                     p_bc_simplified_bc_iiib + theme(legend.position = "none"),
                                     p_bc_simplified_assumption_G_test + theme(legend.position = "none"), nrow = 2, labels = c("A", "C", "E", "G", "B", "D", "F", "H"))
p_bc_simplified_combined = plot_grid(p_bc_simplified_combined, legend_16, ncol = 2, rel_widths = c(1, 0.08))

title = ggdraw() + draw_label("Simplified simulations", hjust = 0.5, size = 30)

# Add title
p_bc_simplified_combined = plot_grid(title, p_bc_simplified_combined, ncol = 1, rel_heights = c(0.05,1))

ggsave(p_bc_simplified_combined, file = file.path(output_path, if(corrected){"Fig5_corrected.jpg"}else{"Fig5.jpg"}), w = 15, h = 9)


```

### Full simulations (Figure 6)

```{r full_comparison_BC}
if(corrected){
  d_17 = read.csv(file.path(data_path, "combined_data/Set_17_corrected_output.csv"))
}else{
  d_17 = read.csv(file.path(data_path, "combined_data/Set_17_output.csv"))
}

d_17 = add_new_va_data(new_va_data=d_new_va, target_data=d_17, verbose=FALSE)
d_17$vA_BC_est_ia = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[2])}))
d_17$vA_BC_est_iia = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[3])}))
d_17$vA_BC_est_iiia = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[4])}))

d_17$vA_BC_est_ib = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[6])}))
d_17$vA_BC_est_iib = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[7])}))
d_17$vA_BC_est_iiib = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[8])}))

d_17$assumption_G_test = unlist(lapply(d_17$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[12])}))

###############################
### vA_est using our method ###
###############################

p_bc_full_us = ggplot(d_17, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle("Our method") + theme(plot.title = element_text(hjust = 0.5))

#####################################
### vA_est using B&C Approach i-a ### (B+Ib_N+)
#####################################

p_bc_full_bc_ia = ggplot(d_17, aes(y = vA_BC_est_ia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^+Ib^+N^+$)")) + theme(plot.title = element_text(hjust = 0.5)) 

######################################
### vA_est using B&C Approach ii-a ### (B0Ib+N+)
######################################

p_bc_full_bc_iia = ggplot(d_17, aes(y = vA_BC_est_iia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^+N^+$)")) + theme(plot.title = element_text(hjust = 0.5))

#######################################
### vA_est using B&C Approach iii-a ### (B0Ib0N+)
#######################################

p_bc_full_bc_iiia = ggplot(d_17, aes(y = vA_BC_est_iiia, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^0N^+$)")) + theme(plot.title = element_text(hjust = 0.5))


#####################################
### vA_est using B&C Approach i-b ### (B+Ib+N0)
#####################################

p_bc_full_bc_ib = ggplot(d_17, aes(y = vA_BC_est_ib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^+Ib^+N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

######################################
### vA_est using B&C Approach ii-b ### (B0Ib+N0)
######################################

p_bc_full_bc_iib = ggplot(d_17, aes(y = vA_BC_est_iib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^+N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

#######################################
### vA_est using B&C Approach iii-b ### (B0Ib0N0)
#######################################

p_bc_full_bc_iiib = ggplot(d_17, aes(y = vA_BC_est_iiib, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$)"), color = "Map length \nin morgans \n(history)") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13) +
  ggtitle(TeX(r"(B&C Approach $B^0Ib^0N^0$)")) + theme(plot.title = element_text(hjust = 0.5))

###################################
### Departure from Assumption G ###
###################################

p_bc_full_assumption_G_test = ggplot(d_17, aes(y = assumption_G_test, x = as.factor(sequence_length*r), fill = as.factor(sequence_length*r))) +
  theme_bw() +
  geom_boxplot() + 
  labs(y = "Deviation from Assumption G", x = "Map length in morgans (history)") + 
  scale_fill_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 12)) + ggtitle(" ")


### Capture the legend and combine the plots

legend_17 = get_legend(p_bc_full_us)

p_bc_full_combined = plot_grid(p_bc_full_bc_ia + theme(legend.position = "none"), 
                               p_bc_full_bc_iia + theme(legend.position = "none"),
                               p_bc_full_bc_iiia + theme(legend.position = "none"), 
                               p_bc_full_us + theme(legend.position = "none"), 
                               p_bc_full_bc_ib + theme(legend.position = "none"), 
                               p_bc_full_bc_iib + theme(legend.position = "none"),
                               p_bc_full_bc_iiib + theme(legend.position = "none"),
                               p_bc_full_assumption_G_test + theme(legend.position = "none"), nrow = 2, labels = c("A", "C", "E", "G", "B", "D", "F", "H"))
p_bc_full_combined = plot_grid(p_bc_full_combined, legend_17, ncol = 2, rel_widths = c(1, 0.08))

title = ggdraw() + draw_label("Full simulations", hjust = 0.5, size = 30)

# Add title
p_bc_full_combined = plot_grid(title, p_bc_full_combined, ncol = 1, rel_heights = c(0.05,1))

ggsave(p_bc_full_combined, file = file.path(output_path, if(corrected){"Fig6_corrected.jpg"}else{"Fig6.jpg"}), w = 15, h = 9)


```

## Sanity check

To perform sanity checks on our method, and our implementation of BC's method, we ran (simplified, i.e. no burnin) simulations with nearly-free recombination in the experiment (ml_exp = 5000). The map length in the history (including msprime) was either 0.5, 10, 50, or 100 morgans.

```{r sanity_check}
d_sanity = read.csv(file.path(data_path, "combined_data/sanity_check_output.csv"))
d_sanity = add_new_va_data(new_va_data=d_new_va, target_data=d_sanity, verbose=TRUE)
d_sanity$vA_BC_est_actual = unlist(lapply(d_sanity$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[3])}))
d_sanity$vA_BC_est_exact = unlist(lapply(d_sanity$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[7])}))
d_sanity$assumption_G_test = unlist(lapply(d_sanity$vA_BC, function(x){as.numeric(unlist(strsplit(x, "_"))[12])}))

p_sanity_us = ggplot(d_sanity, aes(y = vA_est, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$ using our method)"), color = "Map length \nin history") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) + ylim(0, 0.35) + xlim(0, 0.13)

p_sanity_bc_actual = ggplot(d_sanity, aes(y = vA_BC_est_actual, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$ using B&C (actual))"), color = "Map length \nin history") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE)  + ylim(0, 0.35) + xlim(0, 0.13)

p_sanity_bc_exact = ggplot(d_sanity, aes(y = vA_BC_est_exact, x = if(alpha){vA_true_new}else{vA_true}, color = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) + 
  labs(x = TeX(r"(True $V_A$)"), y = TeX(r"(Estimate of $V_A$ using B&C (improved))"), color = "Map length \nin history") + 
  scale_color_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) +
  geom_smooth(method = "lm", se=FALSE) + ylim(0, 0.35) + xlim(0, 0.13)

p_sanity_assumption_G_test = ggplot(d_sanity, aes(y = assumption_G_test, x = as.factor(sequence_length*r_msp), fill = as.factor(sequence_length*r_msp))) +
  theme_bw() +
  geom_boxplot() + 
  labs(y = "Deviation from Assumption G in B&C", x = "Map length in history") + 
  scale_fill_manual(values = c("#009E73", "#D01C8B", "#0072B2", "#999999")) + 
  theme(text = element_text(size = 15)) 

legend_sanity = get_legend(p_sanity_us)

p_sanity_combined = plot_grid(p_sanity_bc_actual + theme(legend.position = "none"), 
                              p_sanity_bc_exact + theme(legend.position = "none"), 
                              p_sanity_us + theme(legend.position = "none"), 
                              p_sanity_assumption_G_test + theme(legend.position = "none"), ncol = 2, labels = "AUTO")
p_sanity_combined = plot_grid(p_sanity_combined, legend_sanity, ncol = 2, rel_widths = c(1, 0.15))

ggsave(p_sanity_combined, file = file.path(output_path, "sanity.jpg"), w = 9, h = 9)
  
```

