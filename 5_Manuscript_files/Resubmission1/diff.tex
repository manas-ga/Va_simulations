\documentclass[12pt]{article}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL main.tex    Wed Aug 27 18:51:35 2025
%DIF ADD main2.tex   Wed Aug 27 18:51:35 2025
\usepackage{authblk}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage[sectionbib]{bibunits}
\defaultbibliographystyle{genetics} 
\defaultbibliography{Vw} 
\usepackage[round]{natbib}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{nameref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{lineno}
\usepackage{caption}
\usepackage{lscape}
\usepackage{geometry}
\usepackage{longtable}
\usepackage{float}  % for captionof
\linenumbers
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    pdfpagemode=FullScreen,
}
\hypersetup{linktocpage}
\renewcommand\contentsname{}


\title{\textbf{Estimating the additive genetic variance for relative fitness from changes in allele frequency}}
%\author{Manas Geeta Arun, Aidan Angus-Henry, Darren J. Obbard\\ \& Jarrod D. Hadfield}

\author[1]{Manas Geeta Arun\thanks{Corresponding author: manas.geetaarun@ed.ac.uk}}
\author[1,2]{Aidan Angus-Henry}
\author[1]{Darren J. Obbard}
\author[1]{Jarrod D. Hadfield}

\affil[1]{Institute of Ecology and Evolution, The University of Edinburgh, Ashworth Laboratories Charlotte Auerbach Road, Edinburgh, EH9 3FL, United Kingdom.}

\affil[2]{Charité - Universitätsmedizin Berlin, Charitéplatz 1, 10117 Berlin, Germany.}

\date{}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}} %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF AMSMATHULEM PREAMBLE %DIF PREAMBLE
\makeatletter %DIF PREAMBLE
\let\sout@orig\sout %DIF PREAMBLE
\renewcommand{\sout}[1]{\ifmmode\text{\sout@orig{\ensuremath{#1}}}\else\sout@orig{#1}\fi} %DIF PREAMBLE
\makeatother %DIF PREAMBLE
%DIF COLORLISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
\lstset{extendedchars=\true,inputencoding=utf8}

%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \renewcommand{\figurename}{}
\renewcommand{\thefigure}{Figure \arabic{figure}}
\DIFaddend \begin{bibunit}
\maketitle
%\tableofcontents
\section*{Running head}
Estimating heritable variance in fitness
\section*{Keywords}
Fisher’s Fundamental Theorem of Natural Selection, rate of adaptation, quantitative genetics, evolve and resequence.

\clearpage

\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

The rate of adaptation is equal to the additive genetic variance for relative fitness ($V_A$) in the population. Estimating $V_A$ typically involves \DIFdelbegin \DIFdel{measuring fitness proxies }\DIFdelend \DIFaddbegin \DIFadd{obtaining suitable measures of fitness }\DIFaddend on a large number of individuals \DIFdelbegin \DIFdel{from a known pedigree}\DIFdelend \DIFaddbegin \DIFadd{with known pairwise relatedness}\DIFaddend . Such data are hard to collect and the results are often sensitive to the definition of fitness used. Here, we present a new method for estimating $V_A$ that does not involve making measurements of fitness \DIFdelbegin \DIFdel{proxies }\DIFdelend on individuals, but instead tracks changes in the genetic composition of the population. First, we show that $V_A$ can readily be expressed as a function of the genome-wide diversity/linkage disequilibrium matrix and genome-wide expected change in allele frequency due to selection. We then show how independent experimental replicates can be used to infer the expected change in allele frequency due to selection and then estimate $V_A$ via a linear mixed model. Finally, using individual-based simulations, we demonstrate that our approach yields precise and \DIFdelbegin \DIFdel{unbiased }\DIFdelend \DIFaddbegin \DIFadd{accurate }\DIFaddend estimates over a range of biologically plausible \DIFdelbegin \DIFdel{levels of }\DIFdelend \DIFaddbegin \DIFadd{scenarios. 
}

\section*{\DIFadd{Article summary}}
\addcontentsline{toc}{section}{\DIFadd{Article summary}}

\DIFadd{Conventional approaches for estimating the heritable component of fitness variation (}\DIFaddend $V_A$\DIFdelbegin \DIFdel{. 
}\DIFdelend \DIFaddbegin \DIFadd{) have steep methodological, statistical, and even definitional challenges. Here, the authors present a new method that overcomes many of these issue by modelling $V_A$ using selection-induced changes to a population's genetic composition. The authors develop novel mathematical theory and an inference approach that uses independent experimental populations derived from the same ancestral population. Individual based simulations show that this method provides unbiased and precise estimates of $V_A$. This opens the door for future studies investigating the genomic distribution of $V_A$, a key factor driving Darwinian evolution.
}\DIFaddend 

\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

Despite its simplicity, the fundamental theorem of natural selection (FTNS) \citep{fisher1930genetical,fisher1958genetical} is arguably one of the most central results in evolutionary biology, providing a concise mathematical statement of how quickly a population is expected to adapt. It describes the per generation gain in the mean fitness of a population as a result of natural selection, assuming the `environment' (including variables intrinsic to the population, such as density or allele frequencies) are held constant \citep{ewens1989interpretation, Frank.1992}. The crucial insight the FTNS provides is that the rate of this increase in mean fitness is exactly equal to the additive genetic variance for relative fitness ($V_A$) in the population \citep{burt1995evolution, grafen2015biological}. Consequently, estimating $V_A$ is one of the `\emph{holy grails}' of evolutionary genetics  \citep{walsh2022full}, despite the FTNS being criticised for its inability to predict the actual gain in mean fitness \citep{price1972fisher, ewens1989interpretation, ewens2024fundamental} \DIFaddbegin \DIFadd{(also see \mbox{%DIFAUXCMD
\citet{edwards1994fundamental} }\hskip0pt%DIFAUXCMD
for an historical review of the debate around FTNS)}\DIFaddend . 

A number of attempts have been made to measure $V_A$ in wild populations. Typically, these have involved long term studies on natural populations in which the lifetime reproductive success of a large number of individuals has been measured. Combining these fitness data with information on the relatedness among individuals in a (generalised) linear mixed model approach yields estimates of $V_A$ \citep{kruuk2004estimating}. This is far from straightforward in natural populations, as it can be notoriously difficult to tease apart additive genetic effects from common environmental effects, such as parental effects \citep{kruuk2007separate, shaw2014quantitative}. In addition, wild study systems are rarely closed, meaning emigration can be misinterpreted as mortality and offspring sired outside the study area can be overlooked. Furthermore, many studies on wild populations lack genetic pedigrees, and as a consequence may miss substantial fitness variation acquired through undetected polygamy \citep{vedder2011polygyny, charmantier2006testing}. In addition to these biases, estimates from wild populations also tend to come with considerable uncertainty. \citet{burt1995evolution} reviewed studies estimating $V_A$ in \DIFdelbegin \DIFdel{3 }\DIFdelend \DIFaddbegin \DIFadd{three }\DIFaddend species of plants and \DIFdelbegin \DIFdel{3 }\DIFdelend \DIFaddbegin \DIFadd{three }\DIFaddend species of animals, and found that most estimates of $V_A$ were not significantly different from \DIFdelbegin \DIFdel{0. }\DIFdelend \DIFaddbegin \DIFadd{zero. }\DIFaddend They argued that the upper bound for estimates of $V_A$ could be as high as 0.3, but most likely less than 0.1. Consistent with this, and using a larger data set, \citet{hendry2018contemporary} reported that estimates of $V_A$ varied between \DIFdelbegin \DIFdel{0 }\DIFdelend \DIFaddbegin \DIFadd{zero }\DIFaddend and 0.85, with the vast majority of estimates (73\%) being less than 0.2. Overall, the mean $\widehat{V_A}$ across studies was 0.08. In a recent meta-analysis, \citet{bonnet2022genetic} applied Bayesian quantitative genetic methods to data obtained from 19 long term studies on wild vertebrate populations. They reported a meta-analytic mean $V_A$ of 0.185 across studies, considerably higher than those obtained by \citet{burt1995evolution} and \citet{hendry2018contemporary}. Surprisingly, estimates of $V_A$ in populations of Spotted Hyenas (\emph{Crocuta crocuta}), as well as two of the three populations of Blue Tits (\emph{Cyanistes caeruleus}) were higher than 0.4. This is a remarkable finding, since it suggests that growth rates in these populations should increase nearly 1.5 fold every generation due to selection, provided the environment remains constant. All three meta-analyses investigating $V_A$ \citep{burt1995evolution,hendry2018contemporary,bonnet2022genetic} have detected substantial variability between study systems in their estimates of $V_A$. Although most of this variability will be sampling error, the best estimate suggests the variability in actual $V_A$ across populations is also large with a standard deviation of 0.11, although there is substantial uncertainty about its exact value (95\% credible intervals: 0.01--0.26) \citep{bonnet2022genetic}.  

Measuring $V_A$ in the laboratory is considerably more straightforward, and involves either quantitative genetic breeding designs such as \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{diallel crosses and }\DIFaddend full-sib half-sib \DIFdelbegin \DIFdel{design }\DIFdelend \DIFaddbegin \DIFadd{experiments }\DIFaddend \citep{falconer1996,lynch1998}, or experimental techniques such as hemiclonal analysis \citep{abbott2011obtaining}. While the controlled environment of the laboratory can, to a large extent, help overcome some of the challenges faced by field studies, laboratory environments often lack important features that are likely to generate fitness variation, such as parasites, predators and competitors. Therefore, it is not entirely clear if laboratory estimates of $V_A$ are particularly relevant. Furthermore, many laboratory studies standardise their fitness measurements in a way that makes it hard to infer estimates of $V_A$ (eg. \citet{ruzicka2019genome})  or work with absolute fitness but then fail to report $V_A$ (eg. \citet{singh2023investigation}). However, these studies do suggest that genetic variance for fitness is likely highly dependent on the specific environment in which fitness is assayed (eg. \citet{punzalan2014comparing}). In one of the few laboratory studies that estimated the genetic variance for \emph{relative} fitness,  \citet{martinossi2018consequences} reported estimates from isofemale lines of the bean beetle, \emph{Acanthoscelides obtectus}, that were highly sensitive to evolutionary history, assay environment, and sex, being higher in males (0.13-0.42) than in females (0.013-0.056).  \DIFaddbegin \DIFadd{A compromise between the precision of the laboratory environment and the biotic and abiotic complexity encountered by wild populations can be achieved by working with experimental populations established in the field, an approach especially tractable in annual plants. Working with field populations of the annual legume }\textit{\DIFadd{Chamaecrista fasciculata}}\DIFadd{, \mbox{%DIFAUXCMD
\citet{kulbaba2019additive} }\hskip0pt%DIFAUXCMD
found estimates of $V_A$ that varied considerably among populations and years. Interestingly, many of their estimates were appreciably larger, with the largest estimate (calculated from Table 1 in the correction) being 3.05.  
}\DIFaddend 

A common difficulty for current field and laboratory approaches is that, while Darwinian fitness is a deceptively intuitive concept, there is little consensus on its precise definition. In fact, it has been argued that the appropriate definition of fitness can vary depending on the context \citep{hendry2018contemporary}. In the absence of a universal definition, empiricists can only \DIFdelbegin \DIFdel{measure proxies of fitness }\DIFdelend \DIFaddbegin \DIFadd{use a measure of fitness deemed most appropriate for their study system}\DIFaddend , and it is reasonable to assume that estimates of $V_A$ are likely to be sensitive to the \DIFdelbegin \DIFdel{fitness proxy }\DIFdelend \DIFaddbegin \DIFadd{definition of fitness }\DIFaddend used. A useful illustration of this point is provided by two studies that estimated $V_A$ in a wild population of Red Deer (\emph{Cervus elaphus}), using largely overlapping datasets, but markedly different definitions of fitness \citep{kruuk2000heritability, foerster2007sexually}. \citet{kruuk2000heritability} defined fitness as the total number of progeny produced by an individual in its lifetime and estimated $V_A$ to be 0.1, whereas \cite{foerster2007sexually} employed an alternative definition of fitness that measured an individual’s contribution to population growth \citep{coulson2006estimating} and obtained the appreciably higher estimate of 0.64. 

Some of the definitional difficulties of measuring $V_A$ can be overcome by measuring $V_A$ as the rate of adaptation, rather than comparing \DIFdelbegin \DIFdel{the fitness proxies of }\DIFdelend \DIFaddbegin \DIFadd{measures of fitness among }\DIFaddend relatives. One of the earliest attempts to explore this idea was made by \citet{fowler1997genetic} (also see \citet{gardner2005genetic}) in laboratory populations of \emph{Drosophila melanogaster}. Using balancer chromosomes  that allow recombination to be suppressed on the third chromosome, \citet{fowler1997genetic} could track the frequency trajectories of newly introduced wild-type third chromosomes over the course of 43 weeks. By \DIFdelbegin \DIFdel{modeling }\DIFdelend \DIFaddbegin \DIFadd{modelling }\DIFaddend fitness using genotype frequency data for a number of different wild-type third chromosomes  \citep{barton2000measuring}, they demonstrated the presence of substantial $V_A$ on the third chromosome. More recently, in a landmark study, \citet{buffalo2019linked} developed a method to estimate the amount of genome-wide allele frequency change that can be attributed to selection. The linchpin of their theory is the idea that linked selection induces across-generation covariances in allele frequency change at neutral loci, since associations between these neutral loci and their respective non-neutral backgrounds persist across generations. This new theoretical framework has the potential to pave the way for a powerful empirical tool to detect genomic signatures of linked selection \citep{Buffalo.2020, simon2024contribution}. Of particular relevance here, \citet{buffalo2019linked} also show that their method can be used to obtain estimates of $V_A$, albeit under some potentially restrictive assumptions.

In this study, we present an alternative theoretical framework that relates $V_A$ to genome-wide changes in \DIFdelbegin \DIFdel{allele-frequency}\DIFdelend \DIFaddbegin \DIFadd{allele frequency}\DIFaddend . Using mathematical identities only, we show how $V_A$ can be obtained from an initial linkage disequilibrium (LD) matrix and expected changes in allele frequency due to selection, without making any assumptions about patterns of gene action or the relationships between genotype fitnesses and genotype frequencies. Our approach, like that of \citet{buffalo2019linked}, relies on temporal genomic data and does not necessitate measuring fitness in individuals. However, in contrast to the `bottom-up' population genetic approach of \citet{buffalo2019linked}, we use a `top-down' quantitative genetic approach which simplifies and generalises some aspects of the problem.

Our aim here is three-fold. First, we derive our central theoretical result from first principles. Second, we develop the statistical machinery required to apply our result to real biological data, and validate it with individual based simulations \DIFaddbegin \DIFadd{that permit dominance effects, but assume random mating and an absence of epistasis}\DIFaddend . Third, we make a detailed comparison of our method with that of \citet{buffalo2019linked}.

\section*{Materials and \DIFdelbegin \DIFdel{Method}\DIFdelend \DIFaddbegin \DIFadd{methods}\DIFaddend }
\addcontentsline{toc}{section}{Materials and \DIFdelbegin \DIFdel{Method}\DIFdelend \DIFaddbegin \DIFadd{methods}\DIFaddend }

\subsection*{Outline of the theory}
\addcontentsline{toc}{subsection}{Outline of the theory}

Table \ref{tab:notation} summarises the notation used in the following text. We consider a population consisting of $N$ diploid individuals. We assume that there are $n_L$ segregating biallelic loci in the population. Let $c_{k,i}$ and $\alpha_i$ represent the proportion of copies of an arbitrarily chosen reference allele at locus $i$ in individual $k$ and Fisher's average effect \citep{Fisher.1941} for \DIFaddbegin \DIFadd{relative }\DIFaddend fitness at locus $i$, respectively. The widely accepted mathematical definition of the $\alpha$'s are the regression coefficients obtained from a multiple regression of the $c$'s on relative fitness, $w$ \citep{Fisher.1941, Lee.2013}. The vector $\boldsymbol{{\alpha}}$ can be expressed as

\begin{equation} \label{eq1}
\begin{array}{rl} 
\boldsymbol{{\alpha}} &= \textbf{L}^{-1}Cov(\textbf{c}, w) 
\end{array}
\end{equation}
where $\textbf{c}$ is the vector of predictors representing the $c$'s at all loci for an individual and $\textbf{L}$ is a symmetric ${n_L} \times {n_L}$ matrix whose $i^{th}$ (diagonal) element is the variance in the $c$'s at locus \DIFdelbegin \DIFdel{i }\DIFdelend \DIFaddbegin \DIFadd{$i$ }\DIFaddend computed over individuals, while the  $ij^{th}$ (off-diagonal) element describes the covariance between the $c$'s at locus $i$ and locus $j$ computed over individuals. 

The breeding value for the relative fitness of individual $k$ is then

$$u_k = {\bf c}^{\top}_{k}\boldsymbol{{\alpha}}$$


and the additive genetic variance for relative fitness is the variance of this quantity across individuals:

\begin{equation} \label{eq2}
\begin{array}{rl} 
{V_A} &= Var({\bf c}^{\top}\boldsymbol{{\alpha}}) \\ 
&= \boldsymbol{{\alpha}}^{\top}Var({\bf c}, {\bf c}^{\top})\boldsymbol{{\alpha}}\\ 
&= \boldsymbol{\alpha}^{\top}\textbf{L}\boldsymbol{\alpha}\\
\end{array}
\end{equation}
This follows from the fact that at any given point in time, $\alpha$'s are constant across individuals. In the absence of mutation and meiotic drive, the allele frequency in parents is transmitted to offspring without bias, such that the vector of expected change in allele frequencies due to selection can be expressed as Robertson's covariance \citep{robertson1966mathematical, price1970selection, queller2017fundamental}:

\begin{equation} \label{eq3}
\begin{array}{rl}
E[\Delta{\textbf{p}}] &= E[\Delta\bar{{\textbf{c}}}]\\
&= Cov(\textbf{c}, w)
\end{array}
\end{equation}

Substituting Equation \ref{eq1} into Equation \ref{eq3} gives $E[\Delta{\textbf{p}}] = {\bf L}\boldsymbol{\alpha}$, which is the multivariate analogue of Equation 10 in \citet{Kirkpatrick.2002}. Combining this with Equation \ref{eq2} yields,

\begin{equation} \label{eq4}
\begin{array}{rl}
{V_A} &= \left({\textbf{L}^{-1}E[\Delta{\textbf{p}}]}\right)^{\top}{\textbf{L}}\left({\textbf{L}^{-1}E[\Delta{\textbf{p}}]}\right)\\
&= E[\Delta{\textbf{p}}]^{\top}{\textbf{L}^{-1}}E[\Delta{\textbf{p}}]
\end{array}
\end{equation}

Equation \ref{eq4} is a general result and involves no assumptions about the patterns of dominance or epistasis for fitness, or about patterns of mating. An intuitive explanation of why $V_A$ can be calculated this way is to note Fisher's Fundamental Theorem states that ${V_A}$ is equal to the (partial) increase in mean fitness caused by evolutionary change through natural selection. Equation \ref{eq2} can be expressed as a sum of $\alpha_i E[\Delta p_i]$ over all loci, $i$:

\begin{equation} \label{eq2b}
\begin{array}{rl}
{V_A} &= \boldsymbol{\alpha}^{\top}E[\Delta{\textbf{p}}]
\end{array}
\end{equation}

In this,  $\alpha$ represents the proportional change in the population mean fitness that is caused by a unit change in allele frequency at a locus \citep{Fisher.1941, Kojima.1959, Lee.2013}. Therefore, multiplying $\alpha$ by the actual change caused by natural selection, $E[\Delta p]$, we get the proportional change in mean fitness caused by evolutionary change by natural selection at that locus \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\citep[see Eq 51.4][also]{price1972fisher}}\hskip0pt%DIFAUXCMD
}\DIFaddend . If we then add these changes at every locus in the genome, we obtain the total proportional change in mean fitness due to evolutionary change by natural selection, and hence $V_A$.  

\subsection*{Extending our approach to practical situations}
\addcontentsline{toc}{subsection}{Extending our approach}


Our theoretical approach assumes $\boldsymbol{\alpha}$ or $E[\Delta {\bf p}]$ are known. In reality, neither can be directly observed and must be inferred from data on observed allele frequency change, $\Delta {\bf p}$. Since $\Delta {\bf p}$ will vary around $E[\Delta {\bf p}]$ due to genetic drift, $E[\Delta {\bf p}]$ must be inferred using replicate observations of $\Delta {\bf p}$. Since time cannot be replayed, we infer $E[\Delta {\bf p}]$ through experimental replicates (see \citet{Buffalo.2020} also). Our theoretical model also assumes ${\bf L}$ is known, but since it is hard to generate experimental replicates without at least one round of reproduction, we condition on ${\bf L}_{0}$ (${\bf L}$ in a generation prior to the first generation over which allele frequency change is measured). In what follows we will refer to the population at time zero (generation 0) as the `base population'. Our aim is then to \DIFdelbegin \DIFdel{estimate an }\DIFdelend \DIFaddbegin \DIFadd{approximate the }\DIFaddend additive genetic variance for fitness in the base population \DIFdelbegin \DIFdel{, $V_A(0)=\bar{\boldsymbol{\alpha}}^{\top}{\bf L}_0\bar{\boldsymbol{\alpha}}$, }\DIFdelend \DIFaddbegin \DIFadd{$V_A(0)$ as $V_{\bar A}(0)=\bar{\boldsymbol{\alpha}}^{\top}{\bf L}_0\bar{\boldsymbol{\alpha}}$, }\DIFaddend where $\bar{\boldsymbol{\alpha}}$ is the \DIFdelbegin \DIFdel{vector of mean average effects across }\DIFdelend \DIFaddbegin \DIFadd{mean vector of average effects averaged over }\DIFaddend time and replicates. \DIFaddbegin \DIFadd{Note that if average effects are constant then $V_{\bar A}(0)=V_A(0)$, but if the average effects vary then $V_A(0)$ will in general exceed $V_{\bar A}(0)$ which can be interpreted as the additive genetic }\emph{\DIFadd{covariance}} \DIFadd{in fitness between replicates/time points for a population with genotypic structure equal to that in the base population (see Supplementary information \ref{App:dist}).}\DIFaddend \\

We also allow allele frequency changes to be measured over multiple generations, rather than a single generation. Thus, $\Delta {\bf p}_m = \Delta {\bf p}_{t_m,m}+\Delta {\bf p}_{t_m+1,m}\dots\Delta {\bf p}_{\tau_m-1,m}$ is the observed change in allele frequency from generation $t_m$ to $\tau_m$ in replicate $m$, with $\Delta {\bf p}_{t,m}$ being the change from time $t$ to $t+1$. Note that $t_m$ (i.e. the generation in which we start recording allele frequency changes \DIFaddbegin \DIFadd{in replicate $m$}\DIFaddend ) can be any positive integer. If replicate populations are derived from the base population with exactly one round of reproduction, $t_m$ would be \DIFdelbegin \DIFdel{1. }\DIFdelend \DIFaddbegin \DIFadd{1 for all $m$. }\DIFaddend $\tau_m$ can be any integer greater than $t_m$. We first note that the total change in allele frequency in replicate $m$ between times $t_m$ and $\tau_m$ is

\begin{equation}
\Delta {\bf p}_{m} = \sum^{\tau_m-1}_{t=t_m}\left({\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t,m}\right)
\end{equation}

where ${\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}=E[\Delta{\bf p}_{t,m}]$ is the expected change in allele frequency due to selection in replicate $m$ between generation $t$ and $t+1$ and $\underset{D}\Delta {\bf p}_{t,m}$ is the change due to drift. It is important to note that ${\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}$ captures responses to both direct and indirect selection. ${\bf L}$ will vary over time and we decompose ${\bf L}$ at a particular time\DIFaddbegin \DIFadd{/replicate }\DIFaddend into a part that can be predicted by ${\bf L}_0$ and the action of drift and recombination, and a part that cannot be predicted. To do this we decompose  ${\bf L}$ into ${\bf L}^{'}$ and ${\bf L}^{''}$, following the notation of \citet{buffalo2019linked}. ${\bf L}^{'}$ represents the (co)variances in the $c$'s computed over the haploid genomes of all $2N$ \DIFdelbegin \DIFdel{gametes }\DIFdelend \DIFaddbegin \DIFadd{gametic contributions }\DIFaddend that constitute the base population. Thus, the diagonal elements of ${\bf L}^{'}$ are proportional to gametic (gene) diversity and the off-diagonals are proportional to gametic-phase disequilibrium. On the other hand, ${\bf L}^{''}$  represents the (co)variances that arise due to alleles within the different gametic contributions of a genotype, and thus the diagonal elements are proportional to the additive coefficients of Hardy-Weinberg disequilibrium (\citet{bulmer1980mathematical} and Chapter 12 in \citet{Weir.1989}), and the off-diagonal elements are proportional to the nongametic-phase disequilibrium. Given this decomposition\DIFdelbegin \DIFdel{(See Appendix }\DIFdelend \DIFaddbegin \DIFadd{, the dynamics of ${\bf L}$ under drift and recombination are (See Supplementary information }\DIFaddend \ref{Appendix:LD} for details \DIFaddbegin \DIFadd{and \mbox{%DIFAUXCMD
\citet{Hill.1968} }\hskip0pt%DIFAUXCMD
and \mbox{%DIFAUXCMD
\citet{Santiago.1998}}\hskip0pt%DIFAUXCMD
}\DIFaddend ):

\begin{equation}
{\bf L}_{t,m}= {\bf N}_{t,m}\circ\tilde{\bf L}_{0}+\DIFdelbegin \DIFdel{\Delta }%DIFDELCMD < {\bf %%%
\DIFdel{L}%DIFDELCMD < }%%%
\DIFdelend \DIFaddbegin \DIFadd{\Delta{\bf L}}\DIFaddend ^{'}_{t,m}+{\bf L}^{''}_{t,m}
\label{Eq:LD_dynamics}
\end{equation}
where $\circ$ is the Hadamard \DIFaddbegin \DIFadd{(i.e. element-wise) }\DIFaddend product, $\tilde{\bf L}_{0}$ is the weighted sum of ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$ , with the $ij^{th}$ element of ${\bf L}^{''}_{0}$ weighted by \DIFdelbegin \DIFdel{$r_{i,j}/(1-r_{i,j})$ }\DIFdelend \DIFaddbegin \DIFadd{$r_{ij}/(1-r_{ij})$ }\DIFaddend and ${\bf N}_{t,m}$ is a matrix with the $ij^{th}$ element being \DIFdelbegin \DIFdel{$(1-r_{i,j})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$. $r_{i,j}$ }\DIFdelend \DIFaddbegin \DIFadd{$(1-r_{ij})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$. $r_{ij}$ }\DIFaddend is the recombination rate between the two loci and  $N_{e_{k,m}}$ is the effective population size in generation $k$ in replicate $m$. $\Delta {\bf L}^{'}_{t,m}$ is a stochastic term \DIFdelbegin \DIFdel{with zero expectation }\DIFdelend that represents the accumulated change in ${\bf L}^{'}$ between generations 0 and $t$ in replicate $m$ that cannot be predicted. ${\bf L}^{''}_{t,m}$ is the matrix of nongametic-phase disequilbria that arises in generation $t$ in replicate $m$. In the \DIFaddbegin \DIFadd{absence of selection, $\Delta {\bf L}^{'}_{t,m}$ and ${\bf L}^{''}_{t,m}$ have zero expectation. In the }\DIFaddend following, it will be useful to designate $\boldsymbol{\mathcal{L}}_{t,m} = {\bf N}_{t,m}\circ\tilde{\bf L}_0$ as the \DIFdelbegin \DIFdel{expected }\DIFdelend \DIFaddbegin \DIFadd{predicted }\DIFaddend ${\bf L}_{t,m}$, for $t>0$, conditional on ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$. Also, we represent the deviation of ${\bf L}_{t,m}$ from this \DIFdelbegin \DIFdel{expectation }\DIFdelend \DIFaddbegin \DIFadd{prediction }\DIFaddend as $\Delta {\bf L}_{t,m}=\Delta {\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}$. It will also be useful to denote $\boldsymbol{\alpha}_{t,m}=\bar{\boldsymbol{\alpha}}+\Delta\boldsymbol{\alpha}_{t,m}$ where $\Delta\boldsymbol{\alpha}_{t,m}$ is the deviation of the average effects (in generation $t$ in replicate $m$) from the mean of the average effects across time and replicates.  We can then decompose the change due to selection into two terms:

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \Delta {\bf p}_m
%DIFDELCMD < =& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
%DIFDELCMD < =& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t, m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\Delta {\bf p}_m
=& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
=& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t, m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
=&\boldsymbol{\mathcal{L}}_{m}\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{m}+\underset{D}\Delta {\bf p}_{m}\\
\end{array}\DIFaddend 
\label{Eq:dp}
\end{equation}

\DIFdelbegin \DIFdel{where the }\DIFdelend \DIFaddbegin \DIFadd{Here quantities subscripted with just $m$ are the sums of the relevant quantity over $t$ (for example, $\boldsymbol{\mathcal{L}}_m=\sum_{t=t_m}^{\tau_m-1}\boldsymbol{\mathcal{L}}_{t,m}$). The }\DIFaddend predictable change due to selection is \DIFdelbegin \DIFdel{$\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}$ }\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mathcal{L}}_{m}\bar{\boldsymbol{\alpha}}$ }\DIFaddend and is similar to that derived for a single locus in \citet{Santiago.1998}\DIFdelbegin \DIFdel{, and the }\DIFdelend \DIFaddbegin \DIFadd{. The }\DIFaddend unpredictable change due to selection caused by stochastic changes in  ${\bf L}$ and/or $\boldsymbol{\alpha}$ is \DIFdelbegin \DIFdel{$\underset{U}\Delta {\bf p}_{t,m}=\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}$. Note that $\underset{D}\Delta {\bf p}$ and $\underset{U}\Delta {\bf p}$ have expectation zero and that the $\underset{D}\Delta {\bf p}$ terms }\DIFdelend \DIFaddbegin \DIFadd{$\underset{U}\Delta {\bf p}_{m}=\sum_{t=t_m}^{\tau_m-1}\left(\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}\right)$. The total change due to drift is $\underset{D}\Delta {\bf p}_m$. The $\underset{D}\Delta {\bf p}_m$ have zero expectation and }\DIFaddend are independent across replicates \DIFdelbegin \DIFdel{, generations, and generations within replicates \mbox{%DIFAUXCMD
\citep{buffalo2019linked}}\hskip0pt%DIFAUXCMD
. The $\underset{U}\Delta {\bf p}$ are never independent across generations within replicates since the $\Delta {\bf L}^{'}$ are sums of changes over all previous generations after generation 0. They may, however, be independent across replicates if each replicate is initiated from individuals independently generated from Generation $0$ individuals (e.g. $t_m=1$ for all $m$) }\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\citep{buffalo2019linked}}\hskip0pt%DIFAUXCMD
}\DIFaddend . \DIFdelbegin \DIFdel{If replicates are derived from a single population that was derived from generation 0 $t_m-1$ generations before, then the $\Delta {\bf L}$ will be dependent due to the shared }\DIFdelend \DIFaddbegin \DIFadd{In what follows we also assume the $\underset{U}\Delta {\bf p}_m$ have zero expectation, although we believe there are two primary mechanisms by which this assumption can fail. First, the model for the predicted changes in ${\bf L}$ (i.e. $\boldsymbol{\mathcal{L}}_m$) may be inaccurate such that the $\Delta{\bf L}_{t,m}$ have non-zero expectation. Since $\boldsymbol{\mathcal{L}}_m$ is derived under the assumptions of drift and recombination only, directional }\DIFaddend changes in ${\bf L}$ \DIFdelbegin \DIFdel{from generation $0$ to $t_m-1$.  However, even when replicates are independently generated from generation $0$, there may be cases where the $\underset{U}\Delta {\bf p}$ are non-independent between replicates, because of some structure to either the $\Delta {\bf L}^{'}$'s or the $\Delta\boldsymbol{\alpha}$'s. The $\Delta\boldsymbol{\alpha}$'s may be non-independent across replicates, if a selection regime is unique to a time point but experienced by all replicates. The $\Delta {\bf L}$'s may also be non-independent if selection induces correlated }\DIFdelend \DIFaddbegin \DIFadd{induced by selection is an obvious mechanism.  Second, the product $\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}$ may have non-zero expectation if changes in the average effects are correlated with changes in patterns of diversity/LD. Again, selection-induced changes in $\Delta{\bf L}_{t,m}$ is a possible mechanism. Additionally, unless all gene action is additive, }\DIFaddend changes in ${\bf L}$ \DIFdelbegin \DIFdel{across replicates, although here we follow the assumption of the }\DIFdelend \DIFaddbegin \DIFadd{also induce changes in $\boldsymbol{\alpha}$ since then average effects depend on allele frequencies (Supplementary information \ref{App:loglinear}). 
}

\DIFadd{Since these mechanisms all involve selection-induced changes we appeal to the }\DIFaddend infinitesimal model where such changes are negligible \citep{Barton.2017}, at least for the diagonal elements \citep{Bulmer.1971}. \DIFdelbegin \DIFdel{Making $t_m$ as small as possible so that changes in ${\bf L}$ from ${\bf L}_0$ are minimised (i.e. the replicates are initiated using the offspring of the base population such that $t_m=1$) and }\DIFdelend \DIFaddbegin \DIFadd{However, }\DIFaddend calculating change in allele frequency over a single generation (i.e. $\tau_m-t_m=1$) \DIFdelbegin \DIFdel{will result in the least }\DIFdelend \DIFaddbegin \DIFadd{would minimise any }\DIFaddend bias since any change in ${\bf L}$ due to selection should be minimised and the approximations that follow \DIFdelbegin \DIFdel{should hold well.  However, although }\DIFdelend \DIFaddbegin \DIFadd{will be more accurate.  Although }\DIFaddend the approximations will hold better when $\tau_m-t_m=1$, increasing  $\tau_m-t_m$ (i.e. calculating change in allele frequency over multiple generations) will increase power since the changes in allele frequency due to selection will be larger. 

Assuming \DIFdelbegin \DIFdel{the $\Delta {\bf L}$'s and the $\Delta\boldsymbol{\alpha}$'s are independent across replicates we can then }\DIFdelend \DIFaddbegin \DIFadd{both $\underset{U}\Delta {\bf p}_{m}$ and $\underset{D}\Delta {\bf p}_{m}$ have zero expectation we can }\DIFaddend derive the mean and covariance structure of allele frequency change \DIFdelbegin \DIFdel{across replicates in terms of the mean ($\boldsymbol{\mu}_{\bar{\alpha}}$) and covariance structure (${\bf V}_{\bar{\alpha}}$) of the mean average effects (Appendix \ref{App:dist}). Note that here we treat the average effects as random variables rather than fixed quantities (See Appendix \ref{App:alpha_random} and \mbox{%DIFAUXCMD
\citet{gianola2009additive} }\hskip0pt%DIFAUXCMD
for a discussion on what this implies)}\DIFdelend \DIFaddbegin \DIFadd{in a replicate as}\DIFaddend :

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < E\left[\Delta {\bf p}_m\right]
%DIFDELCMD < =& \boldsymbol{\mathcal{L}}_m\boldsymbol{\mu}_{\bar{\alpha}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
E\left[\Delta {\bf p}_m\right]
=& \boldsymbol{\mathcal{L}}_m\bar{\boldsymbol{\alpha}}\\
\end{array}\DIFaddend 
\label{eq:Edelta}
\end{equation}


\DIFdelbegin \DIFdel{where $\boldsymbol{\mathcal{L}}_m=\sum_{t=t_m}^{\tau_m-1}\boldsymbol{\mathcal{L}}_{t,m}$. 
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The conditional among-replicate covariance is also straightforward
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})
%DIFDELCMD < =&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_n\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
VAR\left(\Delta {\bf p}_m\right) =&\boldsymbol{\mathcal{D}}_m+\boldsymbol{\mathcal{U}}_m\\
\end{array}\DIFaddend 
\DIFdelbegin %DIFDELCMD < \label{eq:covdelta}
%DIFDELCMD < %%%
\DIFdelend \end{equation}

where \DIFdelbegin \DIFdel{$m$ and $n$ are a pair of replicates. The within-replicate (co)variances are more challenging to derive,  as not only do they include the predictable response to selection, but also the cumulative effects }\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mathcal{D}}_m$ and $\boldsymbol{\mathcal{U}}_m$ are the covariances due to the cumulative action }\DIFaddend of drift and the unpredictable response to selection\DIFdelbegin \DIFdel{. There is no easy form for the within-replicate }\DIFdelend \DIFaddbegin \DIFadd{, respectively. The drift }\DIFaddend (co)variances \DIFdelbegin \DIFdel{in the allele frequency change caused by the total impact of the unpredictable response to selection. Here, we simply write the covariance due to the cumulative unpredictable response to selection as $\boldsymbol{\mathcal{U}}_m$, which gives
}%DIFDELCMD < 

%DIFDELCMD < %%%
\begin{displaymath}
\DIFdel{\begin{array}{rl}
VAR\left(\Delta {\bf p}_m\right) =&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_m+\boldsymbol{\mathcal{D}}_m+\boldsymbol{\mathcal{U}}_m\\
\end{array}
}\end{displaymath}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{where $\boldsymbol{\mathcal{D}}_m$ is the covariance due to the cumulative action of drift and is }\DIFdelend \DIFaddbegin \DIFadd{have expectation }\DIFaddend equal to $\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ where ${\bf M}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}$ and the $ij^{th}$ element of ${\bf M}_{t,m}$ is \DIFdelbegin \DIFdel{$(1-r_{i,j})/N_{E_{t,m}}$ (Appendix }\DIFdelend \DIFaddbegin \DIFadd{$(1-r_{ij})/N_{E_{t,m}}$ (Supplementary information }\DIFaddend \ref{App:dist}). Note that since the predictable response to selection includes both direct and indirect selection, the relevant effective population size for the drift covariance in allele frequency does not include the effects of linked selection and for this reason we denote it as $N_E$ rather than $N_e$. Using this notation, $N_E=4N/(2+V_o)$ where $N$ is the census population size and $V_o$ is the variance in offspring number in the absence of \DIFaddbegin \DIFadd{additive }\DIFaddend genetic fitness variation \citep{Wright.1938}. Although the dynamics of ${\bf L}$ (Equation \ref{Eq:LD_dynamics}, also see \DIFdelbegin \DIFdel{Appendix }\DIFdelend \DIFaddbegin \DIFadd{Supplementary information }\DIFaddend \ref{Appendix:LD}) were derived under drift and recombination in the absence of selection, and hence $N_e=N_E$, the dynamical equations for ${\bf L}$ will better approximate reality when an effective population size that incorporates all excess variation in fitness is used. Consequently, we use $N_e$ and $N_E$ to distinguish the effective population sizes that are relevant for stochastic changes in ${\bf L}$ and allele frequency, respectively.
\DIFdelbegin \DIFdel{It should also be noted that if $VAR(\Delta {\boldsymbol \alpha})$, and hence $\boldsymbol{\mathcal{U}}$, is non-zero then the additive genetic variance exhibited in replicate }\DIFdelend \DIFaddbegin 

\DIFadd{There is no easy form for the covariance due to the cumulative unpredictable response to selection and we simply denote it as $\boldsymbol{\mathcal{U}}_m$ (Supplementary information \ref{App:dist}). While the drift terms will be independent across replicates, we also need to assume that $\underset{U}\Delta {\bf p}_{m}$ are independent across replicates for the covariance between replicates to be zero. An obvious source of non-independence would be if replicates are not initiated from individuals independently generated from Generation $0$ individuals (i.e. $t_m\neq1$ for at least one }\DIFaddend $m$\DIFdelbegin \DIFdel{at generation $t$ will in general exceed $V_A(0)$. When $VAR(\Delta {\boldsymbol \alpha})$ is non-zero, we should more generally think of $V_A(0)$ not as }\DIFdelend \DIFaddbegin \DIFadd{). If this were the case, }\DIFaddend the \DIFdelbegin \DIFdel{additive genetic variance for fitness }\DIFdelend \DIFaddbegin \DIFadd{$\Delta {\bf L}$ will be dependent across replicates due to the shared changes in ${\bf L}$ from generation $0$ to the generation from which the replicates are derived. This could be minimised by initialising replicates as early as possible (ideally at $t_m=1$).}\\   

\subsection*{\DIFadd{Inference outline}}
\addcontentsline{toc}{subsection}{\DIFadd{Inference outline}}

\DIFadd{In the previous section, the mean average effects,  $\bar{\boldsymbol{\alpha}}$, are treated as fixed and expectations and variances are taken over the evolutionary process, including variation in the average effects over time and replicates. When making inferences, we treat the mean average effects as random variables rather than fixed quantities (See Supplementary information \ref{App:alpha_random} and \mbox{%DIFAUXCMD
\citet{gianola2009additive} }\hskip0pt%DIFAUXCMD
for a discussion on what this implies) and derive expectations and (co)variances taken over both the evolutionary process and the distribution of $\bar{\boldsymbol{\alpha}}$. Using the laws of total expectation and (co)variance we obtain:
}

\begin{equation}
\DIFadd{\begin{array}{rl}
E\left[\Delta {\bf p}_m\right]
=& \boldsymbol{\mathcal{L}}_m\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}
\label{eq:Edelta}
}\end{equation}

\DIFadd{and 
}

\begin{equation}
\DIFadd{\begin{array}{rl}
VAR\left(\Delta {\bf p}_m\right) =&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_m+\boldsymbol{\mathcal{D}}_m+\boldsymbol{\mathcal{U}}_m\\
\end{array}
}\end{equation}

\DIFadd{where $\boldsymbol{\mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}}$ and are the mean and covariance  structure of the mean average effects respectively. Critically, when deconditioning on $\bar{\boldsymbol{\alpha}}$ the cross-replicate covariances become non-zero:
}

\begin{equation}
\DIFadd{\begin{array}{rl}
COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})
=&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_n\\
\end{array}
\label{eq:covdelta}
}\end{equation}

\DIFadd{where $m$ and $n$ are a pair of replicates.}\\ 

\DIFadd{In Supplementary information \ref{App:alpha_random} we determine permissible models for $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}$ and ${\bf V}_{\bar{\alpha}}$.  Of those, we identify the sensible biological model for the mean average effect:
}

\begin{equation} 
\DIFadd{\begin{array}{rl}
\boldsymbol{\mu}_{\bar{\alpha}} = & \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})
\end{array}
}\end{equation}

\DIFadd{where ${\bf p}_{0}$ is the frequency of the reference alleles at each locus }\DIFaddend in the base population \DIFdelbegin \DIFdel{, but the additive genetic covariance in fitness between replicates.
}\DIFdelend \DIFaddbegin \DIFadd{and ${\bf q}_{0}=\bf{1}-{\bf p}_{0}$. For the variance of the average effects, we identify the model 
}\DIFaddend 

\DIFdelbegin \subsection*{\DIFdel{Inference outline}}
%DIFAUXCMD
\addcontentsline{toc}{subsection}{\DIFdel{Inference outline}}
%DIFAUXCMD
\DIFdelend \DIFaddbegin \begin{equation} 
\DIFadd{\begin{array}{rl}
{\bf V}_{\bar{\alpha}}=& \sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}
\end{array}
}\end{equation}
\DIFaddend 

\DIFdelbegin \DIFdel{By applying sum of squares theory \mbox{%DIFAUXCMD
\citep[page 355]{searle2006} }\hskip0pt%DIFAUXCMD
to Equation \ref{eq2} we can obtain the expected $V_A(0)$ after averaging over the distribution of average effects:
}\DIFdelend \DIFaddbegin \DIFadd{although in our analysis of simulated data we set the off-diagonal elements of ${\bf L}_{0}$ to zero in the above equation, such that the variance in average effects is simply a power function of the genetic diversities \mbox{%DIFAUXCMD
\citep{zeng2018signatures}}\hskip0pt%DIFAUXCMD
. When $p_{\bar{\alpha}}=0$ average effects are independent of genetic diversity, and when $p_{\bar{\alpha}}=-1$ average effects scale inversely with genetic diversity. $p_{\bar{\alpha}}=-1$ is a common assumption in many related approaches \mbox{%DIFAUXCMD
\citep[e.g.][]{yang2011gcta} }\hskip0pt%DIFAUXCMD
and under this assumption $\sigma^2_{\bar{\alpha}}$ is the average contribution of a locus to the additive genic variance.
}

\DIFaddend By applying sum of squares theory \citep[page 355]{searle2006} to Equation \ref{eq2} we can obtain the \DIFdelbegin \DIFdel{expected $V_A(0)$ }\DIFdelend \DIFaddbegin \DIFadd{(posterior) expectation of $V_{\bar A}(0)$ }\DIFaddend after averaging over the distribution of average effects \DIFaddbegin \DIFadd{(Supplementary information \ref{App:alpha_random} and \mbox{%DIFAUXCMD
\citet{gianola2009additive}}\hskip0pt%DIFAUXCMD
)}\DIFaddend :

\begin{equation} \label{eq6}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < E[V_A(0)] &= E[\boldsymbol{\bar \alpha}^{\top}\textbf{L}_0\bar{\boldsymbol{\alpha}}]\\
%DIFDELCMD < &= Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
E[V_{\bar A}(0)] &= E[\boldsymbol{\bar \alpha}^{\top}\textbf{L}_0\bar{\boldsymbol{\alpha}}]\\
&= Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}\DIFaddend 
\end{equation}

where we aim to estimate $\boldsymbol{\mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}}$ through Equations \ref{eq:Edelta}\DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{--}\DIFaddend \ref{eq:covdelta} using multiple evolutionary replicates starting from a common base population.


Rather than working with the allele frequency changes directly, we project them on to a new (reduced) basis and denote this new vector of changes as $\Delta\overrightarrow{\bf p} = {\bf P}\Delta{\bf p}$ where ${\bf P}$ is some projection matrix. We chose a projection that collapses allele frequency changes into the non-null subspace of ${\bf L}_{0}$, since \DIFdelbegin \DIFdel{$V_A(0)$ }\DIFdelend \DIFaddbegin \DIFadd{$V_{\bar A}(0)$ }\DIFaddend only depends on this subspace \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\citep{de2015genomic}}\hskip0pt%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{(Supplementary information \ref{App:projection} and Supporting Information in \mbox{%DIFAUXCMD
\citet{de2015genomic}}\hskip0pt%DIFAUXCMD
)}\DIFaddend . To do this, let ${\bf U}_{\bf L}$ be the eigenvectors of ${\bf L}_{0}$ with non-zero eigenvalues and then the drift covariance in the reduced subspace is ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L}$. If we have ${\bf U}_2$ and ${\bf D}_2$ as the eigenvectors and a diagonal matrix of square-rooted eigenvalues of this matrix, then the projection matrix ${\bf P} = {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$ results in projected allele frequency changes that are identically and independently distributed under drift in the reduced subspace only (see \DIFdelbegin \DIFdel{Appendix }\DIFdelend \DIFaddbegin \DIFadd{Supplementary information }\DIFaddend \ref{App:projection}).

The mean and covariance of the projected allele frequency changes due to predictable selection are:

\begin{equation} 
\begin{array}{rl}
E[\Delta \overrightarrow{\bf p}_m] = &
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m
\boldsymbol{\mu}_{\bar{\alpha}}
\end{array}
\end{equation}

and 

\begin{equation} 
\begin{array}{rl}
COV(\Delta \overrightarrow{\bf p}_m, \Delta \overrightarrow{\bf p}_n) = &
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}_{n}
\end{array}
\end{equation}

\DIFdelbegin \DIFdel{In Appendix \ref{App:alpha_random} we determine permissible models for $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}$ and ${\bf V}_{\bar{\alpha}}$.  Of those, we identify the sensible biological model for the mean average effect:
}%DIFDELCMD < 

%DIFDELCMD < %%%
\begin{displaymath} 
\DIFdel{\begin{array}{rl}
\boldsymbol{\mu}_{\bar{\alpha}} = & \beta^{(0)}_{\bar{\alpha}}+\beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})
\end{array}
}\end{displaymath}%DIFAUXCMD
\DIFdel{where ${\bf p}_{0}$ is the frequency of the reference alleles at each locus in the base population and ${\bf q}_{0}=1-{\bf p}_{0}$. For the variance of the average effects, we identify the model 
}%DIFDELCMD < 

%DIFDELCMD < %%%
\begin{displaymath} 
\DIFdel{\begin{array}{rl}
{\bf V}_{\bar{\alpha}}=& \sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}
\end{array}
}\end{displaymath}%DIFAUXCMD
\DIFdel{although in our analysis of simulated data we set the off-diagonal elements of ${\bf L}_{0}$ to zero in the above equation, such that the variance in average effects is simply a power function of the genetic diversities \mbox{%DIFAUXCMD
\citep{zeng2018signatures}}\hskip0pt%DIFAUXCMD
. }\DIFdelend With $p_{\bar{\alpha}}$ known, the model is a linear mixed model with covariance structure due to the predictable response to selection being proportional (by a factor $\sigma^2_{\bar{\alpha}}$ that is to be estimated) to

\begin{equation} 
\DIFdelbegin %DIFDELCMD < {\bf %%%
\DIFdel{V}%DIFDELCMD < }%%%
\DIFdelend \DIFaddbegin \DIFadd{\overrightarrow{\bf V}}\DIFaddend _{m,n} \propto {\bf P}\boldsymbol{\mathcal{L}}_m{\bf L}_{0}^{p_{\bar{\alpha}}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}
\end{equation}
between replicates $m$ and $n$. When $\boldsymbol{\mathcal{L}}^{(m)}=\boldsymbol{\mathcal{L}}^{(n)}$ for all $n$ and $m$, then this can more easily be fitted by incorporating locus as a random effect with the above covariance structure. The \DIFdelbegin \DIFdel{fixed-effect covariate }\DIFdelend \DIFaddbegin \DIFadd{vector of expected values }\DIFaddend (shown for replicate $m$) \DIFaddbegin \DIFadd{is also proportional to  
}\DIFaddend 

\begin{equation} 
\DIFaddbegin \DIFadd{\overrightarrow{\boldsymbol \mu}_m \propto }\DIFaddend {\bf P}\boldsymbol{\mathcal{L}}^{(m)}({\bf p}_{0}-{\bf q}_{0})
\end{equation}
\DIFdelbegin \DIFdel{can also be fitted, with }\DIFdelend \DIFaddbegin 

\DIFadd{with the }\DIFaddend associated coefficient $\beta^{(1)}_{\bar{\alpha}}$ to be estimated\DIFdelbegin \DIFdel{in addition to the intercept, $\beta^{(0)}_{\bar{\alpha}}$}\DIFdelend . 

We estimate the parameters of the model by treating it as a separable linear mixed model problem
\citep{richards1961method}. Conditional on a value of ${p_{\bar{\alpha}}}$ the model is linear mixed model and the conditional (restricted) maximum likelihood can be obtained from asreml \citep{Butler.2023}. In order to maximise the (unconditional) likelihood we use the R function \DIFdelbegin \DIFdel{`optim ()' }\DIFdelend \DIFaddbegin \DIFadd{optim }\DIFaddend to find the value of  ${p_{\bar{\alpha}}}$ that results in the highest conditional likelihood. Note that the residual variance should equal one if there is no unpredictable response to selection. 

Although linear (mixed) models generate unbiased estimates of $\boldsymbol{\mu}_{\bar{\alpha}}$, the quadratic form $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$ will be upwardly biased by sampling error in \DIFdelbegin \DIFdel{${\boldsymbol \beta}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\beta^{(1)}_{\bar{\alpha}}$}\DIFaddend . To correct for this bias, we use the inverse Hessian (conditional on the best estimate of ${p_{\bar{\alpha}}}$) to get an approximate expression for the sampling \DIFdelbegin \DIFdel{(co)variance  matrix (${\bf S}_{\bar{\alpha}}$) of the two parameters}\DIFdelend \DIFaddbegin \DIFadd{variance  ($S_{\bar{\alpha}}$) of $\beta^{(1)}_{\bar{\alpha}}$}\DIFaddend , and use this in order to get an improved estimate of the quadratic form as follows (see \DIFdelbegin \DIFdel{Appendix \ref{App:bias_correction} }\DIFdelend \DIFaddbegin \DIFadd{Supplementary information \ref{App:bias_correction} for a general derivation}\DIFaddend ):

\begin{equation} 
\widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}}= \widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}\DIFdelbegin \DIFdel{-Tr}%DIFDELCMD < \left(%%%
\DIFdelend \DIFaddbegin \DIFadd{-}\DIFaddend {\bf X}^{\top}{\bf L}\DIFdelbegin \DIFdel{_0{\bf X}{\bf S}}\DIFdelend \DIFaddbegin \DIFadd{_0{\bf X}{S}}\DIFaddend _{\bar{\alpha}}
\DIFdelbegin %DIFDELCMD < \right)
%DIFDELCMD < %%%
\DIFdelend \end{equation}
where ${\bf X}$ is the fixed effect design matrix.

\DIFaddbegin \DIFadd{In addition, allele frequency changes will rarely be known without error and will most likely be estimated using a pool-seq approach. In such cases, it is necessary to add an additional covariance structure into the model that accommodates the estimation error. In Supplementary information \ref{App:pool-seq} we derive the covariance structure for projected allele-frequency change (in replicate $m$) as:
}


\begin{equation}
\DIFadd{\overrightarrow{\boldsymbol{\mathcal{E}}}_m = 2\sigma^2_o{\bf P}\left(\boldsymbol{\mathcal L}_{t_m,m}\circ{\bf Q}_{t_m,m}+\boldsymbol{\mathcal L}_{\tau_m,m}\circ{\bf Q}_{\tau_m,m}\right)}{\DIFadd{\bf P}}\DIFadd{^{\top}
}\end{equation}

\DIFadd{where element $ij$ of a ${\bf Q}$ matrix is the number of reads that span site $i$ and $j$ divided by the product of the coverages at the two sites. When $i=j$, $Q_{i,j}$ is simply the inverse of the coverage. When individuals have a constant probability of being sampled, $\sigma^2_o$ is expected to be one, but we treat it is a free parameter in order to capture any overdispersion \mbox{%DIFAUXCMD
\citep{McCullagh.1989}}\hskip0pt%DIFAUXCMD
.
}

\DIFaddend \subsection*{Comparison with  \citet{buffalo2019linked}}
\addcontentsline{toc}{subsection}{Comparison to the results of \citet{buffalo2019linked}}


To connect our work with \citet{buffalo2019linked} (henceforth `B\&C') it will be useful to express the covariance matrix  ${\bf L}$ in terms of a diagonal matrix of standard deviations,  ${\bf B}$, (half the square-root of the genetic diversities under random mating) and the correlation matrix, ${\bf R}$, such that  ${\bf L}={\bf B}{\bf R}{\bf B}$. We can then split the response to selection in generation $t$ into two parts:

\begin{equation}
\begin{array}{rrcl}
{\bf L}_t\boldsymbol{\alpha}_t =& {\bf B}_t{\bf B}_t\boldsymbol{\alpha}_t&+&{\bf B}_t({\bf R}_t-{\bf I}){\bf B}_t\boldsymbol{\alpha}_t\\
=&\underset{S}\Delta {\bf p}_t&+&\underset{L}\Delta {\bf p}_t
\end{array}
\end{equation}
where the first term is due to direct selection at the loci, and the second term is due to linkage-disequilibria with other selected loci. It will also be useful to distinguish the additive \textit{genetic} variance ($V_A(t)$) from the additive \textit{genic} variance  ($V_a(t)$) in generation $t$\DIFdelbegin \DIFdel{, i.e. }\DIFdelend :
\begin{equation}
V_A(t) = \boldsymbol{\alpha}_t{\bf L}_t\boldsymbol{\alpha}^{\top}_t
\end{equation}
versus
\begin{equation}
V_a(t) = \boldsymbol{\alpha}_t{\bf B}_t{\bf B}_t\boldsymbol{\alpha}^{\top}_t
\end{equation}
with the distinction being that the additive \emph{genetic} variance ($V_A(t)$) captures the contributions of both genetic diversities at individual loci and the linkage disequilibria between pairs of loci, while the additive \emph{genic} variance ($V_a(t)$) captures the contributions of genetic diversities only.

We can also think about the additive genetic/genic covariance in fitness between time points $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$:

\begin{equation}
C_A(\tau\rightarrow t) = \boldsymbol{\alpha}_{t}{\bf L}_t\boldsymbol{\alpha}^{\top}_{\tau}
\end{equation}

and

\begin{equation}
C_a(\tau\rightarrow t) = \boldsymbol{\alpha}_{t}{\bf B}_t{\bf B}_t\boldsymbol{\alpha}^{\top}_{\tau}
\end{equation}

These will differ from $V_A(t)$ or $V_a(t)$ when the average effects at generation $\tau$ are different from those at generation $t$. 
\DIFdelbegin \DIFdel{This could happen when the selective environment changes between generations $t$ and $\tau$, meaning parameters such as $s$ and $h$ change. The average effects will also change if the genetic composition of the population changes between generations $t$ and $\tau$ (i.e. ${\bf L}_{t}\neq{\bf L}_{\tau}$) and there is non-additivity (e.g. $h\neq0.5$) since the average effects are the coefficients of a multiple regression of the $c$'s on relative fitness (Equation \ref{eq1}).}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdelend 

In the theory section above, we assumed ${\bf L}_t$ and $\boldsymbol{\alpha}_t$ were known and so the change due to both direct and linked selection are fixed quantities, as is $V_A(t)$. In contrast, B\&C condition on ${\bf B}_t$ and $\boldsymbol{\alpha}_t$, and treat ${\bf R}_t$ as a random variable. Consequently, in B\&C, the change due to direct selection and $V_a(t)$ are fixed, as in our approach, since genetic diversities and average effects are known. However, the change due to indirect selection and $V_A(t)$ is random since the linkage-disequilibrium is unknown.  In our inference section we acknowledge that $\boldsymbol{\alpha}$ cannot be directly observed, but develop a model for the distribution of $\alpha$'s, where estimates of $V_A(t)$ can be made after marginalising $\boldsymbol{\alpha}$. Similarly, in the approach of B\&C the $\boldsymbol{\alpha}$'s and the elements of ${\bf B}$ for selected sites are also not directly observed, but they make a number of strong assumptions that effectively allow the joint distribution of the average effects and selected site diversities to be marginalised.\\

In \DIFdelbegin \DIFdel{Appendix }\DIFdelend \DIFaddbegin \DIFadd{Supplementary information }\DIFaddend \ref{App:BandC} we work through the derivation of B\&C using our own notation and retaining a full multi-locus treatment. For easy comparison with the present work, here we summarise both the explicit and implicit  assumptions underlying the general approach of B\&C:

\begin{itemize}

\item A) Allele frequency changes are only measured over a single generation.

\item B) There is no direct selection on the loci for which allele frequency change is measured.

\item C) The reference allele at a neutral locus is chosen arbitrarily.

\item D) The signed linkage-disequilibrium between selected sites is zero, which precludes processes such as Hill-Robertson interference. Under this assumption $V_A=V_a$.

\item E) Changes in ${\bf R}$ are due to recombination alone - selection and drift are absent. 

\item F) Nongametic-phase linkage disequilibrium is absent.  

\item G)  There is no relationship between the additive genic variation at a selected site and its LD with neutral sites, as measured through \DIFdelbegin \DIFdel{$R_{i_t, j_t}R_{i_\tau, j_\tau}$ }\DIFdelend \DIFaddbegin \DIFadd{$R_{t, ij}R_{\tau,ij}$ }\DIFaddend where $i$ is a neutral locus and $j$ a selected locus. Note that since genetic diversity determines the additive genic variation and LD (even measured as a correlation) is constrained by the genetic diversities at the two loci, this is unlikely to be met \citep{sved2018one}.

\item H) The average effects are constant, i.e. $\boldsymbol{\alpha}_t=\boldsymbol{\alpha}_{\tau}$ if estimates are to be interpreted as the additive genic variance (or additive genetic variance, if Assumption D is met) in generation $\tau$. If they are not constant, it is the additive genic/genetic covariance between generations $t$ and $\tau$ that is measured.  

\item I) The initial expected LD-structure between selected and neutral loci, \DIFdelbegin \DIFdel{$E[R_{i_t, j_t}^2]$}\DIFdelend \DIFaddbegin \DIFadd{$E[R_{t,i j}^2]$}\DIFaddend , is approximated from an expression for \DIFdelbegin \DIFdel{$E[L_{i_t, j_t}^2]$}\DIFdelend \DIFaddbegin \DIFadd{$E[L_{t,i j}^2]$}\DIFaddend , which is itself derived under mutation-recombination-drift balance (i.e. no selection). This assumption is partly relaxed in the \DIFdelbegin \DIFdel{appendix }\DIFdelend \DIFaddbegin \DIFadd{Appendix }\DIFaddend by assuming the expected LD-structure between selected and neutral loci is equal to the observed LD-structure between all loci, not distinguishing between selected and neutral loci (Assumption I-b). However, in many cases the genetic diversity at selected loci will be less than that found at (or assumed for) neutral loci and so \DIFdelbegin \DIFdel{$E[R_{i_t, j_t}^2]$ }\DIFdelend \DIFaddbegin \DIFadd{$E[R_{t, ij}^2]$ }\DIFaddend will likely be smaller than assumed \citep{sved2018one}.

\item J) The ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ ($\phi_{t,\tau}$), is constant across all selected loci. Under this assumption, dividing the estimate of $V_a(\tau)$ by $\phi_{t,\tau}$ gives an estimate of $V_a(t)$.

\item K) The recombination rate between two sites $g$ base pairs apart is given by $(1 - e^{-2g\bar{r}})/2$ (i.e. Haldane's \citeyearpar{haldane1919map} mapping function) where $\bar{r}$ is the average crossover rate per site per generation. 

\item L) Neutral and selected loci are distributed uniformly and independently across the genome such that the distance between them has a triangular distribution. 

\item M) Since the genetic diversity at selected sites is not measured, it is assumed that $\phi_{t,\tau}$ is equal to the average ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ across all neutral loci.
\end{itemize}

When applying the theory to data, the method of B\&C requires two additional assumptions:

\begin{itemize}

\item Ib) The average LD between selected and neutral sites is equal to the average LD observed between all sites: see Assumption I) above.

\item N) The (co)variance in allele frequency changes divided through by the average genetic diversity is a good approximation for the (co)variance of weighted allele frequency changes where the weights are the inverse of the square root of the genetic diversities. 

\item O) If allele frequencies are estimated from a sample, then the estimation error is binomially distributed.
\end{itemize}

Our approach relaxes most of these assumptions, but not all. Assumption E is only partly relaxed - the change in ${\bf R}$ does not assume a lack of drift but it does assume a lack of selection. We also make Assumption H if we choose to interpret \DIFdelbegin \DIFdel{$V_A(0)$ as }\DIFdelend \DIFaddbegin \DIFadd{$V_{\bar A}(0)$ as as }\DIFaddend an additive genetic variance \DIFaddbegin \DIFadd{(i.e. $V_{A}(0)$) }\DIFaddend rather than an additive genetic covariance \DIFaddbegin \DIFadd{over replicate/time-points}\DIFaddend . Assumptions E \& H result in the unpredictable response to selection being zero. While we do not make this assumption, we do assume that the unpredictable responses to selection are independent across replicates. However, when applying the theory to data we assume that the within-replicate (residual) (co)variances are driven by drift only (rather than an unpredictable response to selection) and that the drift (co)variances are equal to their expected values (conditional on ${\bf L}_0$). In reality, the within-replicate covariances are likely larger, due to the unpredictable response to selection\DIFdelbegin \DIFdel{and evolutionary variance in the drift (co)variances. These assumptions }\DIFdelend \DIFaddbegin \DIFadd{. This assumption }\DIFaddend might not be too severe if \DIFdelbegin \DIFdel{these two additional processes result }\DIFdelend \DIFaddbegin \DIFadd{the unpredictable response to selection results }\DIFaddend in within-replicate (co)variances that are proportional to those under pure drift\DIFdelbegin \DIFdel{. Under this scenario, the model should perform well, }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend although the residual variance may be higher than expected. In addition, in the absence of a recombination map, Assumption K may also be applied in our method, and if ${\bf L}_0$ cannot be partitioned into gametic-phase and nongametic-phase contributions, assumption F might also be made by substituting ${\bf L}_0$ for ${\bf L}^{'}_0$ in $\tilde{\bf L}_0\circ{\bf N}$ and $\tilde{\bf L}_0\circ{\bf M}$. By relaxing some of the more extreme assumptions of B\&C we are instead forced into making assumptions about the mean and covariance structure of the average effects of projected loci when making inferences. 


\subsection*{Multilocus simulations}
\addcontentsline{toc}{subsection}{Multilocus simulations}
To validate our method and inference approach, we performed multilocus simulations using msprime (version 1.2.0) \citep{kelleher2016efficient} and SLiM (version 4.2.2) \citep{haller2023slim}. The code for the simulations and the downstream analyses performed in R (version 4.3.3) is available on GitHub (\url{https://github.com/manas-ga/Va_simulations}) and includes the R library, \texttt{Vw}. We first describe the structure of the simulations in general terms \DIFdelbegin \DIFdel{. Towards the end of this section (see `Varying simulation parameters') we }\DIFdelend \DIFaddbegin \DIFadd{and then }\DIFaddend discuss the specifics of our parameter choices in the context of the scaling used \DIFdelbegin \DIFdel{in the simulations }\DIFdelend \DIFaddbegin \DIFadd{(see `Simulation parameters' below). While these simulations do incorporate dominance effects, it is important to acknowledge that they do not include epistatic interactions between loci. They also assume random mating and non-overlapping generations. Furthermore, it is also important to note that genetic variation in fitness in our simulations was maintained, primarily, by drift-recombination-mutation-selection equilibrium, and our simulations do not capture other mechanisms of maintenance of genetic variation for fitness such as balancing selection or frequency-dependent selection}\DIFaddend .

We simulated a single, contiguous 1 million base-pair long genomic region. Our simulations had two distinct phases: the first phase simulated the history of an ancestral population and the second phase simulated a typical evolve and resequence experiment with independent replicate experimental populations derived from a base population drawn from the ancestral population.  

\subsubsection*{Model for fitness}

We used an additive model \DIFaddbegin \DIFadd{across loci }\DIFaddend for log absolute fitness, $log(W)$, as in \citet{buffalo2019linked}. \DIFdelbegin \DIFdel{The breeding }\DIFdelend \DIFaddbegin \DIFadd{This choice was motivated by the fact that the variance in $log(W)$ is approximately equal to the variance in relative fitness (see Appendix 1 in \mbox{%DIFAUXCMD
\citet{lynch1998}}\hskip0pt%DIFAUXCMD
). Across-locus additivity implies that the genotypic }\DIFaddend value of log fitness for individual $k$ is equal to \DIFdelbegin \DIFdel{$u_k = \sum_{i=1}^{n_L}{c_{k,i}}{\eta_i}$, where  , as before, ${c_{k,i}}$ represents the proportion of copies of the reference allele in }\DIFdelend \DIFaddbegin \DIFadd{$Y_k = \sum_{i=1}^{n_L}{y_{k,i}}$, where  ${y_{k,i}}$ represents the genotypic contribution made by locus $i$ to the log absolute fitness of }\DIFaddend individual $k$\DIFdelbegin \DIFdel{at locus $i$, and $\eta_i$ is the }\DIFdelend \DIFaddbegin \DIFadd{. Within loci, we employed the classical quantitative genetic fitness scheme (pp. 67 in \mbox{%DIFAUXCMD
\citet{lynch1998}}\hskip0pt%DIFAUXCMD
) adapted for }\emph{\DIFadd{proportions}} \DIFaddend (\DIFdelbegin \DIFdel{average) effect of the allele on log fitness}\DIFdelend \DIFaddbegin \DIFadd{$c_{k,i}$'s) (as opposed to counts) of reference alleles within individuals: 
}

\begin{equation}
\DIFadd{\begin{array}{rl}

y_{k,i} =

\begin{cases}
    0 & \text{if } c_{k,i} = 0 \\
    (1 + {\kappa}_i)\eta_i/2 & \text{if } c_{k,i} = 0.5 \\
    \eta_i & \text{if } c_{k,i} = 1
\end{cases}

\end{array} 
}\end{equation}

\DIFadd{where $\kappa$ determines the degree of dominance. Note that $\kappa=0$ implies additivity and $\kappa=-1$ complete recessivity. The average effect for log absolute fitness at locus $i$ is then given by $\eta_i^{(a)} = \eta_i[1 + {\kappa}_i(q_i - p_i)]$ (see Equation 4.10b in \mbox{%DIFAUXCMD
\citet{lynch1998}}\hskip0pt%DIFAUXCMD
)}\DIFaddend . The average effects for (relative) fitness are well approximated by the \DIFdelbegin \DIFdel{$\eta$}\DIFdelend \DIFaddbegin \DIFadd{$\eta^{(a)}$}\DIFaddend 's when they are small in magnitude, but higher-order approximations are required when the \DIFdelbegin \DIFdel{$\eta$}\DIFdelend \DIFaddbegin \DIFadd{$\eta^{(a)}$}\DIFaddend 's are large (see \DIFdelbegin \DIFdel{Appendix }\DIFdelend \DIFaddbegin \DIFadd{Supplementary information }\DIFaddend \ref{App:loglinear}). To obtain the log fitness of each individual we added a noise term drawn from a standard normal distribution (mean = 0, variance = 1) to the \DIFdelbegin \DIFdel{breeding }\DIFdelend \DIFaddbegin \DIFadd{genotypic }\DIFaddend value.  The \DIFaddbegin \DIFadd{absolute }\DIFaddend fitness of each individual \DIFdelbegin \DIFdel{is }\DIFdelend \DIFaddbegin \DIFadd{was }\DIFaddend then obtained by exponentiating the individual's log fitness.  

We sampled the $\eta$'s from a distribution comprising a weighted mixture of three distributions: (1) a point mass at $\eta = 0$ representing neutral mutations, (2) a reflected gamma distribution with shape = 0.3 and scale = $\eta_{scale}$ (typically \DIFdelbegin \DIFdel{0.033}\DIFdelend \DIFaddbegin \DIFadd{0.066}\DIFaddend , unless specified otherwise) representing deleterious mutations, and (3) a gamma distribution with shape = 0.3 and scale = $\eta_{scale}$ (typically \DIFdelbegin \DIFdel{0.033}\DIFdelend \DIFaddbegin \DIFadd{0.066}\DIFaddend , unless specified otherwise) representing beneficial mutations. Thus, for both deleterious and beneficial mutations, the mean absolute $\eta$ (\DIFaddbegin \DIFadd{i.e. $E[|\eta|]$) (}\DIFaddend scale $\times$ shape) was, typically, \DIFdelbegin \DIFdel{0.01}\DIFdelend \DIFaddbegin \DIFadd{0.02}\DIFaddend . The ratio of the frequency of beneficial to deleterious mutations, and $\eta_{scale}$ varied among simulations. Below, we refer to the distribution of non-neutral $\eta$'s (i.e. omitting mixture component (1) described above) as the `distribution of fitness effects' (DFE), but note that this is in fact the distribution of non-zero effects on log fitness.

\subsubsection*{Phase 1 (`history phase'): Simulating the history of an ancestral population}

We first used a neutral coalescent simulation implemented in msprime \citep{kelleher2016efficient} to construct genealogies for 2,500 diploid genomes (i.e. $N_e$ = 2,500). To initialise a (non-equilibrium) set of selected loci, we then simulated mutations at a rate $\mu_{msp}$, using the pyslim package to attach fitness effects ($\eta$) drawn randomly from the non-neutral part of the distribution described above. Since derived mutations are rare, and the DFE is predominantly deleterious, this will generate a positive relationship between the reference allele frequency and the fitness effects $\eta$'s (and therefore the $\alpha$'s, i.e. the average effects for relative fitness), such that $\beta^{(1)}_{\bar \alpha} >0$ but there should be no relationship between genetic diversities and the $\eta$'s (i.e. $p_{\bar \alpha} = 0$). We implemented the fitness model described above by \DIFdelbegin \DIFdel{adapting }\DIFdelend \DIFaddbegin \DIFadd{using }\DIFaddend SLiM's \citep{haller2023slim} default recipe for polygenic selection \DIFaddbegin \DIFadd{(}\DIFaddend in the Wright-Fisher mode\DIFdelbegin \DIFdel{. }\DIFdelend \DIFaddbegin \DIFadd{). SLiM code for implementing dominance effects in a quantitative genetic framework was adapted from  \mbox{%DIFAUXCMD
\citet{schaal2022inversion}}\hskip0pt%DIFAUXCMD
. }\DIFaddend To reach mutation-selection-drift balance,  we then let this population of 2,500 individuals evolve forward in time with selection for 25,000 generations\DIFdelbegin \DIFdel{(see below for an explanation on the consequence of setting $N_e = 2500$ on other parameter choices)}\DIFdelend . Non-neutral mutations drawn from the same DFE were allowed to occur in this period at a rate given by $\mu_{SLiM}$.  At generation 25,000, as the alleles reach mutation-selection-drift balance, we expect $\beta^{(1)}_{\bar \alpha}$ to have become more positive and $p_{\bar \alpha}$ to have become more negative, better reflecting a real population undergoing selection. 

In generation 25,000, we sampled $N_0$ diploid individuals (typically 1000, unless specified otherwise) from this population, which then go on to become the base population in the next phase of the simulation. At this stage, we generated complete genomes for the $N_0$ individuals in the base population by using pyslim to add neutral mutations to the tree sequence recorded so far. To obtain our target number of loci, $n_L$ (typically 65,000, unless specified otherwise), we set the neutral mutation rate to be $(n_L-n_{L_\mathcal{S}})/g$ where $n_{L_\mathcal{S}}$ is the number of non-neutral segregating sites already present and $g$ is the total branch length of the recorded tree sequence. We recorded the phased genotype of each parent at each locus, allowing  us to construct ${\bf L}_0$ and ${\bf L}^{'}_0$. 

\subsubsection*{Phase 2 (`experiment phase'): Simulating an evolve and resequence experiment}

In the second phase of our simulations, again implemented in SLiM, we first allowed the base population to undergo one round of reproduction without selection to establish replicate experimental populations (typically \DIFaddbegin \DIFadd{1,000 individuals in each of }\DIFaddend 10 replicates, unless specified otherwise). Next, we allowed each of these populations to evolve forward in time \DIFaddbegin \DIFadd{(typically three generations, unless specified otherwise) }\DIFaddend with selection as in the history phase. \DIFdelbegin \DIFdel{We allowed the number of generations in the experiment to be either 1, 3, or 5. }\DIFdelend Since our goal was to estimate $V_A$ in the base population, we restricted our analyses only to the set of loci segregating in the base population. Any new mutations in subsequent generations would, in all likelihood, occur at loci outside this set.  Therefore, we did not simulate new mutations during the experiment phase. For each of the independent replicate populations, we recorded the genome-wide vector of allele frequencies in each generation of the experiment. 

\subsubsection*{\DIFdelbegin \DIFdel{Varying the true levels of $V_A$}\DIFdelend \DIFaddbegin \DIFadd{Simulation parameters}\DIFaddend }

\DIFaddbegin \subsubsection*{\textit{\DIFadd{Varying the true levels of $V_A$}}}

\DIFaddend We varied the true (i.e. simulated) levels of $V_A$ \DIFdelbegin \DIFdel{in the base population }\DIFdelend from \textit{ca.} 0.01 to 0.1 by \DIFdelbegin \DIFdel{changing the rate }\DIFdelend \DIFaddbegin \DIFadd{varying the number }\DIFaddend of non-neutral \DIFaddbegin \DIFadd{segregating sites ($n_{L_\mathcal{S}}$) in the base population using a range of rates of non-neutral }\DIFaddend mutations in the history phase \DIFdelbegin \DIFdel{, implemented in }\DIFdelend \DIFaddbegin \DIFadd{in both }\DIFaddend msprime ($\mu_{msp}$) and SLiM ($\mu_{SLiM}$). \DIFdelbegin \DIFdel{In simulations with $\eta_{scale} = 0.033$ }\DIFdelend \DIFaddbegin \DIFadd{For example, in simulations with $E[|\eta|] = 0.02$ (i.e. $\eta_{scale} = 0.066$) }\DIFaddend and no beneficial mutations, we varied $\mu_{msp}$ between $5.56 \times 10^{-9}$ and $5.56 \times 10^{-8}$ and $\mu_{SLiM}$ between $5.56 \times 10^{-7}$ and $5.56 \times 10^{-6}$\DIFaddbegin \DIFadd{, which resulted in  $n_{L_\mathcal{S}}$ varying between }\emph{\DIFadd{ca.}} \DIFadd{10,000 and 64,000 in the base population }\DIFaddend (for other scenarios see Table \DIFdelbegin \DIFdel{\ref{tab:Table_1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{tab:sim_params}}\DIFaddend ). We set $\mu_{msp}$ to be an order of magnitude smaller than $\mu_{SLiM}$ in most simulations because otherwise all individuals would have had a fitness of zero at the end of the coalescent part of the history phase. This extreme mutation load arises because deleterious alleles, having previously evolved under neutrality, would segregate at fairly high frequencies. However, the choice of $\mu_{msp}$ is  unlikely to significantly affect the composition of the base population in most simulations, since the non-neutral genetic diversity of the base population of the experiment phase was primarily determined by the drift-recombination-mutation-selection equilibrium reached over the course of the 25,000 generation long forward simulation, and therefore primarily dependent on $\mu_{SLiM}$.

\DIFdelbegin %DIFDELCMD < \begin{table}
%DIFDELCMD <     %%%
\DIFdelendFL \DIFaddbeginFL \begin{table}[H]
    \DIFaddendFL \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
        \DIFdelbeginFL \DIFdelFL{$\eta_{scale}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$|\kappa|$}\DIFaddendFL &\DIFaddbeginFL \DIFaddFL{$E[|\eta|]$}&\DIFaddendFL $\mu_{ben}:\mu_{del}$ &\textbf{$\mu_{msp}$}  &\textbf{$\mu_{SLiM}$}  & $n_{L_\mathcal{S}}$\\
        \hline
        \DIFdelbeginFL \DIFdelFL{0.033 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0}\DIFaddendFL &\DIFaddbeginFL \DIFaddFL{0.02}& \DIFaddendFL 0 & $5.56\times10^{-8}$ -- $5.56\times10^{-7}$ &$5.56\times10^{-7}$ --  $5.56\times10^{-6}$  & 10058  -- 63755\\
        \DIFdelbeginFL \DIFdelFL{0.033 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0}\DIFaddendFL &\DIFaddbeginFL \DIFaddFL{0.02}& \DIFaddendFL 0.0002 & $5.56\times10^{-8}$ --  $5.56\times10^{-7}$ & $5.56\times10^{-7}$ -- $5.56\times10^{-6}$ & 9742 -- 63797\\
         \DIFdelbeginFL \DIFdelFL{0.033 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0}\DIFaddendFL &0.02& \DIFaddbeginFL \DIFaddFL{0.02  }& \DIFaddendFL $2.0\times10^{-8}$ -- $2.0\times10^{-7}$ & $2.0\times10^{-7}$ -- $2.0\times10^{-6}$ & 3127 --  29999\\
         \DIFdelbeginFL \DIFdelFL{0.045 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0}\DIFaddendFL &\DIFaddbeginFL \DIFaddFL{0.03}& \DIFaddendFL 0 & $3.6\times10^{-8}$ --  $3.6\times10^{-7}$ & $3.6\times10^{-7}$ --  $3.6\times10^{-6}$ & 6565 --  42097\\
         \DIFdelbeginFL \DIFdelFL{0.1 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0}\DIFaddendFL &\DIFaddbeginFL \DIFaddFL{0.06}& \DIFaddendFL 0 & $1.8\times10^{-8}$ -- $1.6\times10^{-7}$ & $1.8\times10^{-7}$ -- $1.6\times10^{-6}$ & 2998 --  18011 \\
         \DIFaddbeginFL \DIFaddFL{0.5}&\DIFaddFL{0.03}&\DIFaddFL{0}&\DIFaddFL{$7.2\times10^{-8}$ -- $3.24\times10^{-7}$}&\DIFaddFL{$7.2\times10^{-7}$ -- $3.24\times10^{-6}$}&\DIFaddFL{13738 -- 49299}\\
         \DIFaddFL{0.75}&\DIFaddFL{0.03}&\DIFaddFL{0}&\DIFaddFL{$7.5\times10^{-8}$ -- $2.07\times10^{-7}$}&\DIFaddFL{$7.5\times10^{-7}$ -- $2.07\times10^{-6}$}&\DIFaddFL{16870 -- 38695}\\
         \DIFaddendFL \hline
    \end{tabular}
    \caption{The ranges for the rates for non-neutral mutations used in the history phase of the full simulations implemented in msprime ($\mu_{msp}$) (the coalescent simulation) and SLiM ($\mu_{SLiM}$) (the forward simulation of the history), along with the ranges for the resulting number of non-neutral sites segregating in the population at the end of the history phase ($n_{L_\mathcal{S}}$) in simulations with different values of the \DIFdelbeginFL \DIFdelFL{scale }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{absolute degree of dominance }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{$\eta_{scale}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$|\kappa|$}\DIFaddendFL )\DIFaddbeginFL \DIFaddFL{, the mean }\DIFaddendFL of the gamma distribution from which \DIFdelbeginFL \DIFdelFL{$\eta$'s }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{effect sizes }\DIFaddendFL for \DIFdelbeginFL \DIFdelFL{non-neutral mutations }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{log absolute fitness }\DIFaddendFL were sampled \DIFaddbeginFL \DIFaddFL{for non-neutral mutations ($E[|\eta|]$)}\DIFaddendFL , and the ratio of the rate of beneficial mutations to the rate of deleterious mutations in the history phase ($\mu_{ben}:\mu_{del}$). Note that the ranges for the number of selected loci, $n_{L_\mathcal{S}}$, are only shown for the simulations where the map length in the history phase was 0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL .}
    \DIFdelbeginFL %DIFDELCMD < \label{tab:Table_1}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{tab:sim_params}
\DIFaddendFL \end{table}

\subsubsection*{\DIFdelbegin \DIFdel{Simplified simulations}\DIFdelend \DIFaddbegin \textit{\DIFadd{Number of segregating sites ($n_L$)}}\DIFaddend }

\DIFdelbegin \DIFdel{In addition to the full simulations described above,we performed a set of simplified, proof-of-principle simulations }\DIFdelend \DIFaddbegin \DIFadd{The requirement for handling large $n_L \times n_L$ matrices (e.g. ${\bf L}_0$, ${\bf L}^{'}_0$, $\bf M$, and $\bf N$, etc.) imposed an upper bound of around 70,000 on $n_L$ to permit the analysis of simulations in parallel. Under most scenarios the entire target range of simulated $V_A$ (i.e. approximately 0.01 }\DIFaddend to \DIFdelbegin \DIFdel{test the logic }\DIFdelend \DIFaddbegin \DIFadd{0.1) could be achieved without $n_{L_\mathcal{S}}$ exceeding 65,000. Therefore, in general, we set $n_L$ to 65,000 (but see `Simplified simulations' below). However, under a small minority of scenarios -- for example, at higher map lengths in the history phase (\ref{fig:full_params}B) or under strong dominance (\ref{fig:combined_dominance}) -- generating a larger $V_A$ required significantly more than 65,000 non-neutral segregating sites. Consequently, in such cases, we had to discard simulations in which $n_{L_\mathcal{S}}$ was greater than 65,000 which generally happened at the higher mutation rates and, therefore, the higher levels of $V_A$. 
}

\subsubsection*{\textit{\DIFadd{Map length of the simulated region}}}

\DIFadd{There are two recombination-related parameters likely to influence the performance }\DIFaddend of our method\DIFdelbegin \DIFdel{. These simulations were different from the full simulations in three ways: }%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{: }\DIFaddend (1) \DIFdelbegin \DIFdel{The history phase was highly abbreviated -- the forward simulation implemented in SLiM lasted only a single generation without any selection. This meant that the ancestral population }\DIFdelend \DIFaddbegin \DIFadd{the $V_A$ per map length, and (2) the density of segregating sites per unit map length. Since our simulations were scaled down in an important way }\DIFaddend -- \DIFdelbegin \DIFdel{from which replicate experimental population were founded }\DIFdelend \DIFaddbegin \DIFadd{namely, they assumed that $V_A$ was limited to only about 65,000 segregating sites as opposed to millions of sites in real populations }\DIFaddend -- \DIFdelbegin \DIFdel{had evolved entirely under neutrality. 
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{(}\DIFdelend \DIFaddbegin \DIFadd{it was not possible to simultaneously set parameters (1) and (}\DIFaddend 2) \DIFdelbegin \DIFdel{Rather than attach $\eta$'s to the derived alleles generated with msprime, we attached the $\eta$'s randomly with respect to either of the two alleles segregating at the locus. Amendments (1) and (2)generate a scenario where there is no relationship between allele frequency and $\eta$: both $p_{\bar \alpha}$ and $\beta^{(1)}_{\bar \alpha}$ are expected to be zero}\DIFdelend \DIFaddbegin \DIFadd{close to their realistic values. Therefore, we varied the effective map length from 0.001 to 2 morgans which spans scenarios where either the total map length of the simulated region is comparable to a typical }\emph{\DIFadd{D. melanogaster}} \DIFadd{autosome ($\sim$0.5 morgan) or the density of segregating sites is comparable ($\sim$0.065 morgan). Exact settings are detailed in the `Reference parameters' section below. The typical }\emph{\DIFadd{D. melanogaster}} \DIFadd{map-length was determined from an effective crossover rate of $10^{-8}$ \mbox{%DIFAUXCMD
\citep{comeron2012many,wang2023variation} }\hskip0pt%DIFAUXCMD
and a 50Mb chromosome. The typical site-density was determined under the assumption that there are one million segregating sites per morgan, which is reasonably consistent with a recent evolve-and-resequence study employing }\emph{\DIFadd{D. melanogaster}} \DIFadd{(\mbox{%DIFAUXCMD
\citet{Bitter.2024}}\hskip0pt%DIFAUXCMD
: 827,200 and 893,465 sites on Chromosome 2 and 3 respectively)}\DIFaddend . 

\DIFaddbegin \DIFadd{Since we only simulated a population of 2,500 individuals in the history phase, which is $\sim$500 times smaller than the estimate of $N_e$ in }\emph{\DIFadd{D. melanogaster}} \DIFadd{\mbox{%DIFAUXCMD
\citep{campos2013codon, campos2019effects}}\hskip0pt%DIFAUXCMD
, we scaled our map-length upwards by a factor of 500 to achieve the target effective map-length described above (\mbox{%DIFAUXCMD
\citet{campos2019effects} }\hskip0pt%DIFAUXCMD
but see \mbox{%DIFAUXCMD
\citet{dabi2025population} }\hskip0pt%DIFAUXCMD
and \mbox{%DIFAUXCMD
\citet{ferrari2025parameter} }\hskip0pt%DIFAUXCMD
for potential issues). On the other hand, since the experiment phase simulates a realistic evolve-and-resequence experiment with $N_e \approx 1,000$, this scaling was not applied to map lengths in the experiment phase (see `Reference parameters' below). In what follows, the map-lengths implemented in the simulations are reported rather than the target effective map-lengths. 
}

\subsubsection*{\textit{\DIFadd{Degree of dominance}}}

\DIFadd{In the simulations with dominance effects (i.e. $\kappa \neq 0$) we always modelled deleterious alleles to be recessive. In practical terms, this meant that ${\kappa}_i$ was set to be positive when $\eta_i$ was positive, and ${\kappa}_i$ was set to be negative when $\eta_i$ was negative. For simplicity, in a given simulation, we assumed $|\kappa_i|$ to be the same across all loci, although the actual dominance deviation, $d_i = \kappa_i \eta_i$ would be locus-specific. We simulated two different levels of $|\kappa|$: (1) $|\kappa| = 0.5$, and }\DIFaddend (\DIFdelbegin \DIFdel{3)Given that the ancestral population had evolved without selection, these simplified simulations had considerably higher genetic diversities compared to }\DIFdelend \DIFaddbegin \DIFadd{2) $|\kappa| = 0.9$.  These correspond to $h=0.25$ and $h=0.05$, respectively, when the heterozygous fitness is $1 - hs$. While $h=0.25$ is consistent with the theoretical expectation from a fitness landscape based model \mbox{%DIFAUXCMD
\citep{manna2011fitness}}\hskip0pt%DIFAUXCMD
, $h = 0.05$, where every deleterious allele is almost completely recessive is probably extreme. Since full simulations with dominance were up to two orders of magnitude slower than their additive counterparts, we switched on dominance effects only in }\DIFaddend the \DIFdelbegin \DIFdel{full simulations . This meant that fewer segregating non-neutral sites ($n_{L_\mathcal{S}}$) were required to achieve true levels of $V_A$ between 0.01 and 0.1. Therefore, in these simulations, we set $n_L$ to be 3000, much lower than the 65, }\DIFdelend \DIFaddbegin \DIFadd{last 5,}\DIFaddend 000 \DIFdelbegin \DIFdel{used for the full simulations. We achieved this by varying $\mu_{msp}$ between $3 \times 10^{-9}$ and $2.35 \times 10^{-8}$.  $\mu_{SLiM}$ was set to 0 in these simulations. This resulted in $n_{L_\mathcal{S}}$ at the end }\DIFdelend \DIFaddbegin \DIFadd{generations }\DIFaddend of the history phase \DIFdelbegin \DIFdel{being between 160 and 1902. We then added neutral mutations using a suitable rate as described above such that $n_L$ was expected to be 3000. 
}\DIFdelend \DIFaddbegin \DIFadd{(i.e. from generation 20,001) as well as in the experiment phase. Relative to additive simulations, full simulations with dominance also required significantly more segregating sites to generate a given level of $V_A$. To generate sufficient $V_A$ (i.e. between }\emph{\DIFadd{ca.}} \DIFadd{0.01 and 0.1) while keeping $n_{L_\mathcal{S}}$ below 67,500, we simulated deleterious mutations from a gamma distribution with a slightly larger mean effect on log fitness (i.e. E}[\DIFadd{|$\eta|] = 0.03$) in the history phase and set $|\kappa|$ to either 0.5 or 0.75. To test our method against extreme dominance (i.e. $|\kappa| = 0.9$), we performed additional full simulations in which  we simulated the entire history phase under additivity, and switched on dominance effects only in the experiment phase. While the resulting genetic composition was far from the expected equilibrium, deleterious alleles were expected to be segregating at substantially lower frequencies than in the simplified simulations.  
}\DIFaddend 

\subsubsection*{\DIFdelbegin \DIFdel{Varying simulation parameters}\DIFdelend \DIFaddbegin \textit{\DIFadd{Reference parameters}}\DIFaddend }

Our aim was to investigate the sensitivity of our method to the following parameters: (1) map length in the history phase (0.5 \DIFdelbegin \DIFdel{morgans}\DIFdelend \DIFaddbegin \DIFadd{morgan}\DIFaddend , 5 morgans, 50 morgans, 250 morgans), (2) map length in the experiment phase (0.01 \DIFdelbegin \DIFdel{morgans}\DIFdelend \DIFaddbegin \DIFadd{morgan}\DIFaddend , 0.2 \DIFdelbegin \DIFdel{morgans}\DIFdelend \DIFaddbegin \DIFadd{morgan}\DIFaddend , 2 morgans), (3) number of replicate populations in the experiment phase (3, 5, 10), (4) the population size of each of the replicate populations (100, 500, \DIFdelbegin \DIFdel{1000}\DIFdelend \DIFaddbegin \DIFadd{1,000}\DIFaddend ), (5) number of generations over which allele frequency changes were recorded in the experiment phase (1, 3, 5), (6) the ratio of the rates of beneficial to deleterious mutations (0\%, 0.02 \%, 2\%), and (7) the \DIFdelbegin \DIFdel{scale of the DFE, $\eta_{scale}$ (0.033, 0.045, 0.100).
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Our final choice of parameter ranges was limited by computational resources. Namely, the requirement for large $n_L \times n_L$ matrices (e.g. ${\bf L}_0$, ${\bf L}^{'}_0$, $\bf M$, and $\bf N$, etc.) imposed an upper bound of around 70,000 on $n_L$ to permit the analysis of simulations in parallel. For full simulations, the number of }\DIFdelend \DIFaddbegin \DIFadd{mean of the gamma distribution from which }\DIFaddend non-neutral \DIFdelbegin \DIFdel{segregating sites ($n_{L_\mathcal{S}}$) was typically smaller than 65, 000 (see Table \ref{tab:Table_1}).
Therefore, in general, we set $n_L$ to 65}\DIFdelend \DIFaddbegin \DIFadd{$\eta$'s were sampled, $E[|\eta|]$ (0.03, 0.03, 0.06)}\DIFaddend , \DIFdelbegin \DIFdel{000 in the full simulations. However, as the map length in the history phase increased, $n_{L_\mathcal{S}}$ also increased, presumably as a consequence of the strength of background selection being weakened by greater recombination. For the simulations where $\eta_{scale}$ was 0.033, accommodating all levels of map length in the history phase }\DIFdelend \DIFaddbegin \DIFadd{and }\DIFaddend (\DIFdelbegin \DIFdel{up to 250 morgans) , would have required us to increase $n_L$ to more than 100000, which was beyond the maximum $n_L$ we could handle. Therefore, for $\eta_{scale} = 0.033$, we restricted ourselves to only those simulations where $n_{L_\mathcal{S}}$ was less than or equal to 65000. When the map length in }\DIFdelend \DIFaddbegin \DIFadd{8) }\DIFaddend the \DIFdelbegin \DIFdel{history phasewas }\DIFdelend \DIFaddbegin \DIFadd{degree of dominance, $\kappa$ (0, }\DIFaddend 0.5\DIFdelbegin \DIFdel{morgans, we could analyse simulations in which the true $V_A$ spanned the whole of the target range (0.01 to 0.1) . However,for higher map lengths, the analyses we present here do not include simulations where the true $V_A$ was close to the higher end of the target range (see Figure \ref{fig:Figure 4}B) .   
}\DIFdelend \DIFaddbegin \DIFadd{, 0.9).
}\DIFaddend 

\DIFdelbegin \DIFdel{Our choices for recombination rates (or map lengths) were dictated by the fact that our simulations were scaled in two ways relative to, say, the global }\emph{\DIFdel{Drosophila melanogaster}} %DIFAUXCMD
\DIFdel{population: (1) }\DIFdelend \DIFaddbegin \DIFadd{Rather than vary all parameters in a fully factorial design, we selected a reference parameter set and explored the sensitivity of the method by changing each parameter in turn. The reference parameter set was (1) a map length of 0.5 morgan }\DIFaddend in the history phase \DIFdelbegin \DIFdel{of our simulations, we simulate a population of 2, 500 individuals, which is 532 times smaller than $1.33 \times 10^6$, the estimate of $N_e$ in }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{\mbox{%DIFAUXCMD
\citep{campos2013codon, campos2019effects}}\hskip0pt%DIFAUXCMD
, and (2) we assume that all the heritable variation in fitness is limited to a genomic region that is one million base-pairs long - nearly 200 times smaller than the }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{genome. 
Therefore, the effective crossover rate in }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{would need to be scaled appropriately. We assumed the true effective crossover rate in }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{to be $1 \times 10^{-8}$ per generation per site, which -- to control for the absence of crossovers in males -- is half the standard estimate of female recombination rate in European }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{\mbox{%DIFAUXCMD
\citep{wang2023variation} }\hskip0pt%DIFAUXCMD
(also see \mbox{%DIFAUXCMD
\citet{comeron2012many}}\hskip0pt%DIFAUXCMD
) . To account for }\DIFdelend (\DIFdelbegin \DIFdel{1), the recombination rate would need to be scaled up by a factor of 532 such that the product of $N_e$ and the recombination rate remains conserved (similar to Table 1 in \mbox{%DIFAUXCMD
\citet{campos2019effects}}\hskip0pt%DIFAUXCMD
). The map length of the simulated region would then be 5.32 morgans. However, our study focuses on the }\textit{\DIFdel{total}} %DIFAUXCMD
\DIFdel{additive genetic variation for a trait, and therefore, we also need to account for (}\DIFdelend \DIFaddbegin \DIFadd{2) a map length of }\DIFaddend 2 \DIFdelbegin \DIFdel{).  
Specifically, since all the sites that code for fitness in our simulations are concentrated in a region that is about 50 times smaller than a typical }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{chromosome, we would need to further scale up the recombination rate 50-fold such that the average number of crossovers between a randomly chosen pair of sites is comparable to a typical }\emph{\DIFdel{D. melanogaster}} %DIFAUXCMD
\DIFdel{chromosome. Under this scaling the map length of the simulated region would then be 266 morgans.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{It is important to note that our methodrelies on linkage disequilibria $D_{ij}$ at the end of the history phase , as well as the crossover rate $r_{ij}$ between pairs of loci during the experiment phase. 
Accounting only for (1) , and using a map length of 5.32 morgans, could in principle lead to reasonable $D_{ij}$'s . However, the $r_{ij}$'s will be considerably lower. Accounting for both (1) and (2), however, would result in reasonable $r_{ij}$'s but much lower $D_{ij}$'s. Therefore, in our simulations, we try to span this entire range by running simulations with the map length in the history phase chosen to be either 0.5,5, 50,or 250 morgans. We use a similar logic for choosing recombination rates in the experiment phase. However, our goal in the experiment phase was to simulate an actual population with census size $N_0$ individuals,rather than mimicking the effects of evolution at a global scale with a realistic $N_e$. Therefore, in the experiment phase we do not account for (1). Instead we vary the map length in the experiment phase over a broad range  (0.01 to 2 morgans) that spans both extremes -- having a reasonable crossover rate per site per generation ($1 \times 10^{-8}$) at one end of the simulated parameter range - which translates to a map length of 0.01 morgans - and having a sensible average $r_{ij}$ between pairs of site at the other end of the range, by using a map length comparable to that in }\emph{\DIFdel{D. melanogaster}}%DIFAUXCMD
\DIFdel{. }%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Rather than vary all parameters in a fully factorial design, we selected a reference parameter set and explored the sensitivity of the method by changing each parameter in turn. The reference parameter set was (1) a map length of 0.5 }\DIFdelend morgans in the \DIFdelbegin \DIFdel{history phase (2) a map length of 2 morgans in the experiment phase, }\DIFdelend \DIFaddbegin \DIFadd{experiment phase, }\DIFaddend (3) 10 \DIFdelbegin \DIFdel{replicate populations in the }\DIFdelend \DIFaddbegin \DIFadd{replicate populations in the }\DIFaddend experiment phase, (4) \DIFdelbegin \DIFdel{a population size of 1000 }\DIFdelend \DIFaddbegin \DIFadd{a population size of 1,000 }\DIFaddend in each of the \DIFdelbegin \DIFdel{replicate populations in the experiment phase, (}\DIFdelend \DIFaddbegin \DIFadd{replicate populations in the experiment phase, (}\DIFaddend 5) 3 \DIFdelbegin \DIFdel{generations over which allele frequency changes were recorded in the experiment phase,  }\DIFdelend \DIFaddbegin \DIFadd{generations over which allele frequency changes were recorded in the experiment phase, (6) no beneficial mutations in the history phase, }\DIFaddend (\DIFdelbegin \DIFdel{6) no beneficial mutations in the history phase, and (}\DIFdelend 7) \DIFdelbegin \DIFdel{0.033 for the scale of the DFE, $\eta_{scale}$.
The reference parameter set was chosen to best reflect }\DIFdelend \DIFaddbegin \DIFadd{$E[|\eta|] = 0.02$, and (8) complete additivity (i.e. $\kappa=0$). The reference parameter set was chosen to best reflect }\DIFaddend evolve-and-resequence experiments using \emph{D. melanogaster}. 

\DIFdelbegin \DIFdel{For logistical reasons, in the simulations in which we varied the map length in the history phase, we could not span the entire target range for $V_A$ }\DIFdelend \DIFaddbegin \DIFadd{Note that we varied $E[|\eta|]$ by using three different values (0.066, 0.09, and 0.2) for scale of the gamma distribution ($\eta_{scale}$) from which the $\eta$'s for non-neutral mutations were drawn while keeping the shape parameter fixed to 0.3. This meant that the coefficient of variation was fixed to $1/\sqrt{0.3}$.  
}

\subsubsection*{\DIFadd{Simplified simulations}}

\DIFadd{In addition to the full simulations described above, we performed a set of simplified, proof-of-principle simulations to test the logic of our method. These simulations were different from the full simulations in three ways:
}

\DIFaddend (\DIFaddbegin \DIFadd{1) The history phase was highly abbreviated -- the forward simulation implemented in SLiM lasted only a single generation without any selection. This meant that the ancestral population -- from which replicate experimental population were founded -- had evolved entirely under neutrality. 
}

\DIFadd{(2) Rather than attach $\eta$'s to the derived alleles generated with msprime, we attached the $\eta$'s randomly with respect to either of the two alleles segregating at the locus. Amendments (1) and (2) generate a scenario where there is no relationship between allele frequency and $\eta$:  both $p_{\bar \alpha}$ and $\beta^{(1)}_{\bar \alpha}$ are expected to be zero.  
}

\DIFadd{(3) Given that the ancestral population had evolved without selection, these simplified simulations had considerably higher genetic diversities compared to the full simulations. This meant that fewer segregating non-neutral sites ($n_{L_\mathcal{S}}$) were required to achieve true levels of $V_A$ between }\DIFaddend 0.01 \DIFdelbegin \DIFdel{to }\DIFdelend \DIFaddbegin \DIFadd{and }\DIFaddend 0.1\DIFdelbegin \DIFdel{) when $\eta_{scale}$ was set to its default level of 0.033 (see above) }\DIFdelend . \DIFdelbegin \DIFdel{Therefore, we ran an additional set of full simulations in which we varied the map length in the history phase while setting $\eta_{scale}$ to 0.045. In these simulations }\DIFdelend \DIFaddbegin \DIFadd{Therefore}\DIFaddend , \DIFdelbegin \DIFdel{even at a map length of 250 morgans, }\DIFdelend \DIFaddbegin \DIFadd{in these simulations, we set $n_L$ to be 3,000, much lower than the 65,000 used for the full simulations. We achieved this by varying $\mu_{msp}$ between $3 \times 10^{-9}$ and $2.35 \times 10^{-8}$. $\mu_{SLiM}$ was set to 0 in these simulations. This resulted in }\DIFaddend $n_{L_\mathcal{S}}$ \DIFdelbegin \DIFdel{seldom exceeded }\DIFdelend \DIFaddbegin \DIFadd{at the end of the history phase being between 160 and 1,902. We then added neutral mutations using a suitable rate as described above such that $n_L$ was expected to be 3,000. 
}

\subsubsection*{\DIFadd{Simulating pool-seq}}

\DIFadd{To investigate the consequences of sampling noise around true allele frequencies in real data, we reanalysed the reference sets for full and simplified simulations with allele frequencies in the experiment phase obtained via simulated pool-seq. Specifically, we investigated the sensitivity of our approach to the pool-seq coverage (i.e. the expected number of reads spanning a given locus) and the degree of overdispersion in the number of individuals sampled by simulating the stochastic process of mapping reads to individuals and positions in the genome at random. We assumed that the number of reads mapping to individual $k$ followed a Poisson distribution with the mean $\lambda_{x, k}$) sampled from a log-normal distribution with parameters $\mu_x$ and $V_x$. Varying $V_x$ allowed us to control the degree of heterogeneity in the probabilities with which individuals are sampled. For a given level of coverage and read length, we determined the expected number of reads mapping to an individual ($E[\lambda_{x}]$). For a given value of $V_x$ and read-length, using the expression for the mean of a lognormal distribution ($E[\lambda_{x}] = exp(\mu_x + V_x/2)$),  we chose $\mu_x$ to achieve the target coverage: $\mu_x = log(E[\lambda_{x}]) - V_x/2$. We mapped reads to the genomes of various individuals in the population by sampling the starting positions for each read from a uniform distribution.
}

\DIFadd{To select the length of the reads in these simulations, we first note that the expected number of segregating sites spanned by a 150 base-pair read in a recent evolve-and-resequence study \mbox{%DIFAUXCMD
\citep{Bitter.2024} }\hskip0pt%DIFAUXCMD
(827,200 segregating sites on chromosome 2 which is $\sim$50 Mb in length) is approximately 2.5. To achieve this, we fixed the read length to be 800 while analysing simplified simulations ($\sim$ 3,000 segregating sites) and 37 when analysing full simulations ($\sim$ }\DIFaddend 65,000 \DIFaddbegin \DIFadd{segregating sites). We used four different combinations of coverage and $V_x$: (1) coverage = 100x, $V_x = 0$; (2) coverage = 500x, $V_x = 0$; (3) coverage = 1000x}\DIFaddend , \DIFdelbegin \DIFdel{allowing us to set $n_L$ to 67, 500 for all map lengths. }\DIFdelend \DIFaddbegin \DIFadd{$V_x = 0$); (4) coverage = 1000x, $V_x = log(2)$. Note that $V_x = 0$ corresponds to a situation where individuals are sampled without overdispersion.
}\DIFaddend 

\subsubsection*{Comparison with B\&C}

To compare the precision and the accuracy of our approach to that of B\&C, we performed additional simplified and full simulations. Although originally designed for the covariance in allele frequency change between multiple time points, B\&C's method can be readily adapted to allele frequency changes recorded over a single generation in multiple independent evolutionary replicates (see Equation \ref{Eq:BCcov13} and \citet{Buffalo.2020}). We set simulation parameters to their reference values (see above) with a few modifications. First, to make comparisons of biases clearer, we reduced noise by employing 50 replicate populations, and second, allele frequency change in the experiment phase was recorded over a single generation. We also ran these simulations at four different levels of map length in the history phase: 0.5 \DIFdelbegin \DIFdel{morgans}\DIFdelend \DIFaddbegin \DIFadd{morgan}\DIFaddend , 5 morgans, 50 morgans, and 100 morgans.

To investigate the consequences of Assumptions B, Ib, and N, we implemented B\&C's method using six different approaches. For clarity, we label the six approaches using a code (see Table \DIFdelbegin \DIFdel{\ref{tab:Table_2}}\DIFdelend \DIFaddbegin \DIFadd{\ref{tab:BC_approaches}}\DIFaddend ) that indicates with superscripts whether an assumption is required (+) or not required (0) for an approach to work. To test Assumption B, we recorded allele frequency changes at either all segregating sites ($B^+$) or neutral sites only ($B^0$). To test Assumption Ib, we used either the average LD between all sites ($Ib^+$) or the average LD between selected sites with neutral sites ($Ib^0$). And finally, we either divided the (co)variance in allele frequency change throughout by twice the average genetic diversity ($N^+$; analogous to Equation 16 in B\&C) or used the (co)variance of weighted allele frequency change, where the weights are the inverse of the square root of twice the genetic diversity ($N^0$).  

\DIFdelbegin %DIFDELCMD < \begin{table}
%DIFDELCMD <     %%%
\DIFdelendFL \DIFaddbeginFL \begin{table}[H]
    \DIFaddendFL \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        Approach & $\Delta\textbf{p}$ & Average LD between &  $Cov(\Delta\textbf{p}_m,\Delta\textbf{p}_n)$  \\
         \hline
         $B^+Ib^+N^+$&all sites&all sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^0Ib^+N^+$&neutral sites&all sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^0Ib^0N^+$&neutral sites&selected \& neutral sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^+Ib^+N^0$&all sites&all sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         $B^0Ib^+N^0$&neutral sites&all sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         $B^0Ib^0N^0$&neutral sites&selected \& neutral sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         \hline
    \end{tabular}
    \caption{We applied B\&C's method to our simulations using six different approaches. The requirement of Assumptions B, Ib, and N is indicated using superscripts ("+" when required and "0" when not required). We used allele frequency change ($\Delta\textbf{p}$) at either all segregating sites (Assumption B required) or at neutral segregating sites only (Assumption B not required). We computed average LD using either the LD between all segregating sites (Assumption Ib required) or the LD between selected and neutral sites (Assumption Ib not required). We used either the (co)variance in $\Delta\textbf{p}$ divided throughout by twice the average genetic diversity (Assumption N required) or the (co)variance in weighted $\Delta\textbf{p}$ (i.e. $\Delta\overrightarrow{\textbf{p}}$) where the weights are the square roots of twice the genetic diversity at each site (Assumption N not required).}
    \DIFdelbeginFL %DIFDELCMD < \label{tab:Table_2}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{tab:BC_approaches}
\DIFaddendFL \end{table}


\section*{Results}
\addcontentsline{toc}{section}{Results}
\subsection*{Simplified simulations}

We begin by discussing results from the simplified simulations in which we expect there to be no relationship between allele frequencies and $\alpha$'s. Under our reference parameter set \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{(no dominance, map length in history = 0.5 morgan, map length in the experiment = 2 morgans), }\DIFaddend our method provided precise and unbiased estimates of $V_A$ throughout the simulated range (0.01-- 0.1) (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 1}A}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_main}a}\DIFaddend ). Furthermore, the estimates of $p_{\bar \alpha} $ \DIFdelbegin \DIFdel{, $\beta^{(0)}_{\bar{\alpha}}$, }\DIFdelend and $\beta^{(1)}_{\bar{\alpha}}$ were centred around 0 as expected (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 1}B-D). We next investigated how this relationship between the true and estimated levels }\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_main}b-c), and the residual variance was marginally above 1 (\ref{fig:simplified_main}d). Next, we investigated how our estimates }\DIFaddend of $V_A$ \DIFdelbegin \DIFdel{was }\DIFdelend \DIFaddbegin \DIFadd{were }\DIFaddend affected by changing (1) map length of the genomic region being simulated, (2) population size of each replicate population in the evolve and resequence experiment, (3) number of replicate populations, and (4) number of generations over which allele frequency changes were recorded in the experiment. \DIFdelbegin \DIFdel{Our estimates }\DIFdelend \DIFaddbegin \DIFadd{Estimates }\DIFaddend of $V_A$ remained unbiased as the map length in the experiment became smaller, although estimates became noisier, particularly at higher values of $V_A$ (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 2}A}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_params}a}\DIFaddend ).  As expected, estimates also became noisier as the number of individuals, replicate populations, or generations became smaller (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 2}B-D}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_params}b-d}\DIFaddend ). However, estimates appeared upwardly biased when the number of replicate populations or generations was small (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 2}C-D). }\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_params}c-d). Estimates of $V_A$ from simplified simulations incorporating dominance effects in the fitness model were generally precise, but exhibited a small upward bias when dominance effects were large in magnitude (\ref{fig:combined_dominance}a). As the degree of dominance increased, the estimates of $p_{\bar \alpha} $ and $\beta^{(1)}_{\bar{\alpha}}$ became increasingly more negative and the residual variance became larger (\ref{fig:combined_dominance}b-c). 
}\DIFaddend 

\begin{figure}[H]
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.15]{Figures/Fig1.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.15]{Figures/simplified_main.jpg}
\DIFaddendFL \caption{Results of simplified simulations  (map length in the history phase = 0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL , map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = \DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1}\DIFaddendFL ,\DIFaddbeginFL \DIFaddFL{000, }\DIFaddendFL number of generations = 3, \DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.033$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the mean of the gamma distribution from which effect sizes for log absolute fitness were sampled for non-neutral mutations ($E[|\eta|]$}\DIFaddendFL ) \DIFaddbeginFL \DIFaddFL{= 0.02, and no dominance (i.e. $\kappa$ = 0))}\DIFaddendFL . (\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. \DIFaddbeginFL \DIFaddFL{The inference of $V_A$ was obtained by modelling the mean and the }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{co}\DIFaddendFL )\DIFaddbeginFL \DIFaddFL{variance of the average effects for relative fitness as $\boldsymbol{\mu}_{\bar{\alpha}} = \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})$ and ${\bf V}_{\bar{\alpha}}=\sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}$, respectively.   (b)}\DIFaddendFL -(\DIFdelbeginFL \DIFdelFL{D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{d}\DIFaddendFL ) Histograms of the estimates of $p_{\bar \alpha} $, \DIFdelbeginFL \DIFdelFL{$\beta^{(0)}_{\bar{\alpha}}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$\beta^{(1)}_{\bar{\alpha}}$}\DIFaddendFL , and \DIFdelbeginFL \DIFdelFL{$\beta^{(1)}_{\bar{\alpha}}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the residual variance}\DIFaddendFL , respectively. The vertical red \DIFdelbeginFL \DIFdelFL{line indicates 0.}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{lines indicate null expectations (0 for $p_{\bar \alpha} $ and $\beta^{(1)}_{\bar{\alpha}}$, and 1 for the residual variance). The black dashed lines indicate the means of the respective distributions.}\DIFaddendFL }
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 1}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:simplified_main}
\DIFaddendFL \end{figure}

\begin{figure}[H]
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.12]{Figures/Fig2.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.12]{Figures/simplified_params.jpg}
\DIFaddendFL \caption{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for simplified simulations at different levels of (\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ) map length in the experiment, (\DIFdelbeginFL \DIFdelFL{B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{b}\DIFaddendFL ) population size of each replicate population in the evolve and resequence experiment, (\DIFdelbeginFL \DIFdelFL{C}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{c}\DIFaddendFL ) number of replicate populations, and (\DIFdelbeginFL \DIFdelFL{D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{d}\DIFaddendFL ) number of generations \DIFdelbeginFL \DIFdelFL{for }\DIFdelendFL over which allele frequency changes were recorded in the experiment. In each case, other than the parameter to be varied, the other parameters were fixed at their default values\DIFaddbeginFL \DIFaddFL{: the mean of the gamma distribution from which effect sizes for log absolute fitness were sampled for non-neutral mutations }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.033$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|]$) = 0.02}\DIFaddendFL , map length in the history phase = 0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL , map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = \DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1}\DIFaddendFL ,\DIFaddbeginFL \DIFaddFL{000, }\DIFaddendFL number of generations = 3\DIFaddbeginFL \DIFaddFL{, and no dominance ($\kappa$ = 0}\DIFaddendFL )\DIFaddbeginFL \DIFaddFL{)}\DIFaddendFL . The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$.}
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 2}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:simplified_params}
\DIFaddendFL \end{figure}

\DIFaddbegin \begin{figure}[H]
\includegraphics[scale = 0.12]{Figures/combined_dominance.jpg}
\caption{\DIFaddFL{Results of simulations with map lengths in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1,000, number of generations = 3, and different degrees of dominance: $\kappa$ = 0 (green), $\kappa$ = 0.5 (blue), $\kappa$ = 0.75 (magenta) and $\kappa$ = 0.9 (grey). (a-d) are the results from the simplified simulations with the map length in the history phase = 0.5 morgan and the mean of the gamma distribution from which effect sizes for log absolute fitness are sampled for non-neutral mutations ($E[|\eta|]$) = 0.02. (a) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. (b-d) Estimates of model parameters $p_{\bar \alpha}$, $\beta^{(1)}_{\bar{\alpha}}$, and the residual variance, respectively. (e-f) Scatter plot of estimates of $V_A$ vs true values from full simulations (with $E[|\eta|] = 0.03$) when the map length in the history phase was either 0.5 morgan (e) or 5 morgans (f).}}
  \label{fig:combined_dominance}
\end{figure}

\DIFaddend \subsection*{Full simulations}
In our full simulations we let the ancestral population evolve forward in time with selection for \DIFdelbegin \DIFdel{25000 }\DIFdelend \DIFaddbegin \DIFadd{25,000 }\DIFaddend generations before simulating the experiment. In these simulations, we expect the population to be at drift-recombination-mutation-selection equilibrium, such that $p_{\alpha} $ is negative and $\beta^{(1)}_{\bar{\alpha}}$ is positive. Results from our \DIFdelbegin \DIFdel{standard set (Figure \ref{fig:Figure 3}}\DIFdelend \DIFaddbegin \DIFadd{reference set (no dominance, map length in history = 0.5 morgan, map length in the experiment = 2 morgans}\DIFaddend ) suggest that not only does our method provide precise and unbiased estimates of $V_A$ \DIFaddbegin \DIFadd{(\ref{fig:full_main}a)}\DIFaddend , but it does so by correctly estimating the signs of $p_{\alpha}$ and $\beta^{(1)}_{\bar{\alpha}}$ (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 3}B,D}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_main}b-c}\DIFaddend ). As before, estimates of $V_A$ became slightly noisier at shorter map lengths during the experiment (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}A}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}a}\DIFaddend ). The quality of our estimates of $V_A$ was not significantly affected by adding beneficial mutations during the history phase (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}C}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}c}\DIFaddend ). On the other hand, our estimates were downwardly biased at larger map lengths in the history phase (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}B}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}b}\DIFaddend , also see \DIFdelbegin \DIFdel{Figure \ref{fig:Figure S1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_ml_eta0.045}}\DIFaddend ) and when non-neutral loci had on average larger fitness effects (\DIFaddbegin \DIFadd{$E[|\eta|]$) (}\DIFaddend i.e. when $\eta_{scale}$ was larger) (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}D}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}d}\DIFaddend ). The bias at larger \DIFdelbegin \DIFdel{$\eta_{scale}$ }\DIFdelend \DIFaddbegin \DIFadd{$E[|\eta|]$ }\DIFaddend was likely driven by the loss of additive genic variance at large-effect loci during the experiment (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure S2}A-D}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:lost_va}a-d}\DIFaddend ).  

\DIFaddbegin \DIFadd{When we simulated the history phase under additivity and switched on dominance only in the experiment phase, we obtained fairly reliable estimates of $V_A$ (\ref{fig:full_dominance_sprinkled}). However, switching on dominance in the last 5,000 generations of the history phase resulted in estimates that were significantly upwardly biased, especially when dominance effects were strong (\ref{fig:combined_dominance}e). However, at the relatively low map length in the history phase (0.5 morgan) used in these simulations, the additive genetic variance for fitness was substantially lower than the additive genic variance (\ref{fig:full_dominance_vA_va}). This suggested the build up of unusually high negative linkage disequilibria between recessive deleterious alleles, generating pseudo-overdominance \mbox{%DIFAUXCMD
\citep{ohta1970development, abu2023conditions}}\hskip0pt%DIFAUXCMD
, a phenomenon typically observed in regions of extremely low recombination \mbox{%DIFAUXCMD
\citep{salson2025interplay}}\hskip0pt%DIFAUXCMD
. At higher levels of map length in the history phase (5 morgans), our method provided unbiased estimates of $v_A$ (\ref{fig:combined_dominance}f).     
}

\DIFaddend Finally, we re-analysed our standard set of full simulations in two different ways (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}E-F}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}e-f}\DIFaddend ). First, to accommodate cases in which phased genomes, and therefore ${\bf L}^{'}_{0}$, are unavailable, we assumed that ${\bf L}^{''}_{0}$ was 0 and set ${\bf L}^{'}_{0}$ = $\bf L_0$. In other words, we assumed that $\tilde{\bf L}_0$ = ${\bf L}_0$. Our analyses suggest that this assumption leads to a slight downward bias in our estimates of $V_A$ (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}E}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}e}\DIFaddend ). Second, to account for instances where $N_E$ in the experiment phase is unknown, we replaced our estimate of $N_E$ in the experiment phase by the number of individuals. Our analyses suggest that this does not affect our estimates of $V_A$ in any way (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 4}F}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:full_params}f}\DIFaddend ), with the faster than expected drift being absorbed by an increased residual variance (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure S3}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:residual_var_NE}}\DIFaddend ): estimates of $N_E$ can be obtained by dividing the assumed value of $N_E$ by the estimated residual variance. 

\begin{figure}[H]
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.15]{Figures/Fig3.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.15]{Figures/full_main.jpg}
\DIFaddendFL \caption{Results of full simulations with a burn-in phase of \DIFdelbeginFL \DIFdelFL{25000 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{25,000 }\DIFaddendFL generations (map length in the history phase = 0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL , map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = \DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1}\DIFaddendFL ,\DIFaddbeginFL \DIFaddFL{000, }\DIFaddendFL number of generations = 3, \DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.033$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the mean of the gamma distribution from which effect sizes for log absolute fitness were sampled for non-neutral mutations ($E[|\eta|]$}\DIFaddendFL ) \DIFaddbeginFL \DIFaddFL{= 0.02, and no dominance (i.e. $\kappa$ = 0))}\DIFaddendFL . (\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. \DIFaddbeginFL \DIFaddFL{The inference of $V_A$ was obtained by modelling the mean and the }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{co}\DIFaddendFL )\DIFaddbeginFL \DIFaddFL{variance of the average effects for relative fitness as $\boldsymbol{\mu}_{\bar{\alpha}} = \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})$ and ${\bf V}_{\bar{\alpha}}=\sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}$, respectively.  (b)}\DIFaddendFL -(\DIFdelbeginFL \DIFdelFL{D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{d}\DIFaddendFL ) Histograms of the estimates of $p_{\bar \alpha} $, \DIFdelbeginFL \DIFdelFL{$\beta^{(0)}_{\bar{\alpha}}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$\beta^{(1)}_{\bar{\alpha}}$}\DIFaddendFL , and \DIFdelbeginFL \DIFdelFL{$\beta^{(1)}_{\bar{\alpha}}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the residual variance}\DIFaddendFL , respectively. The vertical red \DIFdelbeginFL \DIFdelFL{line indicates 0.}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{lines indicate null expectations (0 for $p_{\bar \alpha} $ and $\beta^{(1)}_{\bar{\alpha}}$, and 1 for the residual variance). The black dashed lines indicate the means of the respective distributions.}\DIFaddendFL }
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 3}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:full_main}
\DIFaddendFL \end{figure}

\begin{figure}[H]
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.12]{Figures/Fig4.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.12]{Figures/full_params.jpg}
\DIFaddendFL \caption{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for full simulations with a burn-in phase of \DIFdelbeginFL \DIFdelFL{25000 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{25,000 }\DIFaddendFL generations at different values of (\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ) map length in the experiment phase, (\DIFdelbeginFL \DIFdelFL{B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{b}\DIFaddendFL ) map length during the history phase, (\DIFdelbeginFL \DIFdelFL{C}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{c}\DIFaddendFL ) the ratio of rates of beneficial and deleterious mutations in the history phase, and (\DIFdelbeginFL \DIFdelFL{D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{d}\DIFaddendFL ) \DIFdelbeginFL \DIFdelFL{$\eta_{scale}$ }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the mean of the gamma distribution from which effect sizes }\DIFaddendFL for \DIFaddbeginFL \DIFaddFL{log absolute fitness were sampled for }\DIFaddendFL non-neutral mutations \DIFaddbeginFL \DIFaddFL{($E[|\eta|]$)}\DIFaddendFL . In each case, other than the parameter to be varied, the other parameters were fixed at their default values (map length in the history phase = 0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL , map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = \DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1}\DIFaddendFL ,\DIFaddbeginFL \DIFaddFL{000, }\DIFaddendFL number of generations = 3\DIFdelbeginFL \DIFdelFL{)}\DIFdelendFL , \DIFdelbeginFL \DIFdelFL{$\eta_{scale}$ for non-neutral mutations }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|]$ }\DIFaddendFL = \DIFdelbeginFL \DIFdelFL{0.033}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.02, and no dominance (i.e. $\kappa$ = 0))}\DIFaddendFL . The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. The effect of analysing the standard set of simulations (\DIFdelbeginFL \DIFdelFL{Figure \ref{fig:Figure 3}}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\ref{fig:full_main}}\DIFaddendFL ) (\DIFdelbeginFL \DIFdelFL{E}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{e}\DIFaddendFL ) without partitioning $\tilde{\bf L}_0$ into its gametic (${\bf L}^{'}_{0}$) and non-gametic phase (${\bf L}^{''}_{0}$) components, and (\DIFdelbeginFL \DIFdelFL{F}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{f}\DIFaddendFL ) using \DIFdelbeginFL \DIFdelFL{$N_E = N = 1000$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$N_E = N = 1,000$}\DIFaddendFL . Note that in (F), a large number of green points are eclipsed by the blue points.}
\DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 4}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:full_params}
\DIFaddendFL \end{figure}


\DIFaddbegin \subsection*{\DIFadd{Simulating pool-seq}}

\DIFadd{When we incorporated the expected covariance structure due to pool-seq sampling in our models, the performance of our method was practically unaffected by obtaining allele frequencies in the experiment phase using simulated pool-seq in the simplified simulations (\ref{fig:poolseq_simplified}A), although a modest negative bias was observed at low (100x) coverage in the full simulations (\ref{fig:poolseq_full}). Additionally, both in the simplified and the full simulations, the degree of overdispersion in the number of reads mapping to an individual did not adversely affect our estimates of $V_A$. Along expected lines (see Supplementary information \ref{App:pool-seq}), omitting the covariance structure of pool-seq sampling from our models led to estimates of $V_A$ that were significantly downwardly biased, with virtually no $V_A$ detected at 100x coverage (\ref{fig:poolseq_simplified}B).   
}

\newpage
\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/poolseq_simplified.jpg}
\caption{\DIFaddFL{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for simplified simulations (map length in the history phase = 0.5 morgan, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1,000, number of generations = 3, the mean of the gamma distribution from which effect sizes for log absolute fitness were sampled for non-neutral mutations ($E[|\eta|]$) = 0.02, and no dominance (i.e. $\kappa$ = 0)) using either exact allele frequencies in the experiment phase (green), or allele frequencies in the experiment phase obtained via simulated pool-seq implemented using three different levels of coverage (expected number of reads mapping a segregating site: 1000x (magenta), 500x (blue), and 100x (grey)) without any overdispersion in the number of reads mapping to an individual, as well as estimates obtained from simulated pool-seq implemented at 1000x coverage with overdispersion in the number of reads mapping to an individual (orange). Reads were modelled to be 800 base-pairs long. The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. Estimates of $V_A$ were obtained by either incorporating (a) or omitting (b) the expected covariance structure due to pool-seq sampling in the models.}}
  \label{fig:poolseq_simplified}
\end{figure}

\DIFaddend \subsection*{Comparison with B\&C}

In both simplified and full simulations, all implementations of B\&C's method resulted in a strong upward bias at low recombination rates in the history phase (Figures \DIFdelbegin \DIFdel{\ref{fig:Figure 5} and\ref{fig:Figure 6}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_simplified} and\ref{fig:BC_full}}\DIFaddend ). This was likely a consequence of Assumption G being violated; the correlation between the contribution of a selected site $j$ to $V_a$ and the persistent association of this site with neutral alleles ($\sum_{ \mathcal{N}_i}(R_{{i_m}{j_m}}R_{{i_n}{j_n}})$) was considerably higher than 0 when the map length in the history phase was low (panel H of Figures \DIFdelbegin \DIFdel{\ref{fig:Figure 5} and \ref{fig:Figure 6}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_simplified} and \ref{fig:BC_full}}\DIFaddend ). In contrast, the estimates of $V_A$ provided by our method were unbiased and had far greater precision compared to any of the six implementations of B\&C's method in the simplified simulations (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 5}G}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_simplified}g}\DIFaddend ), although there was a small upward bias at low recombination rates in the full simulations (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 6}G}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_full}g}\DIFaddend ). Due to the difficulty of distinguishing selected from unselected sites, B\&C suggested that the average LD between all sites could be used instead of the LD between selected and unselected sites (Assumption Ib) and indeed this assumption seems to be well justified (panels \DIFdelbegin \DIFdel{D \& F in Figures \ref{fig:Figure 5} and \ref{fig:Figure 6} }\DIFdelend \DIFaddbegin \DIFadd{d \& f in Figures \ref{fig:BC_simplified} and \ref{fig:BC_full} }\DIFaddend are very similar). However, an inability to distinguish selected from unselected sites would likely mean that B\&C's method is applied to allele frequency change data from \emph{all} segregating sites, contravening Assumption \DIFdelbegin \DIFdel{B}\DIFdelend \DIFaddbegin \DIFadd{b}\DIFaddend . This results in considerable overestimation of $V_A$ in simplified simulations (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 5}A-B}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_simplified}a-b}\DIFaddend ) but not in full simulations (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 6}A-B}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_full}a-b}\DIFaddend ). Under all scenarios the bias in the method of B\&C can be reduced (but not eliminated) by relaxing Assumption N (compare panels \DIFdelbegin \DIFdel{B, D, and F in Figures \ref{fig:Figure 5}}\DIFdelend \DIFaddbegin \DIFadd{b, d, and f in Figures \ref{fig:BC_simplified}}\DIFaddend -\DIFdelbegin \DIFdel{\ref{fig:Figure 6} to panels A, C and E}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:BC_full} to panels a, c and e}\DIFaddend ). Under assumption N, it is assumed that the (co)variance in allele frequency change weighted by the square root of twice the genetic diversities can be approximated by the (co)variances in allele frequency change divided through by twice the average diversities. However, this approximation is not required. 

\newgeometry{left=1cm,bottom=2cm, top=1cm, right=1cm}
\begin{landscape}
\begin{figure}[H]
\begin{center}
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.14]{Figures/Fig5.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.14]{Figures/BC_simplified.jpg}
\DIFaddendFL \end{center}
\caption{Estimates of $V_A$ obtained using our method (\DIFdelbeginFL \DIFdelFL{G}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{g}\DIFaddendFL ) and various applications of the B\&C Approach (\DIFdelbeginFL \DIFdelFL{A--F}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a--f}\DIFaddendFL ) from simplified simulations with varying 
    map lengths in the history phase: 0.5 \DIFdelbeginFL \DIFdelFL{morgans }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan }\DIFaddendFL (green), 5 morgans (magenta), 50 morgans (blue), and 100 morgans (grey). The solid black line indicates the 1:1 line. Each application of B\&C is defined in terms of which three assumptions (B, Ib, N) are required or not (designated with a \DIFaddbeginFL \DIFaddFL{`}\DIFaddendFL $+$\DIFaddbeginFL \DIFaddFL{' }\DIFaddendFL or \DIFaddbeginFL \DIFaddFL{`}\DIFaddendFL 0\DIFaddbeginFL \DIFaddFL{' }\DIFaddendFL superscript, respectively). Assumption B is that allele frequencies are tracked at unselected loci only, Assumption Ib is that the average LD between all sites is equal to the average LD between selected and unselected sites, and Assumption N is that the covariance between projected allele frequency changes is equal to the covariance between allele frequencies changes scaled by the average projection (see Table \DIFdelbeginFL \DIFdelFL{\ref{tab:Table_2} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\ref{tab:BC_approaches} }\DIFaddendFL for details). Panel \DIFdelbeginFL \DIFdelFL{H }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{h }\DIFaddendFL is the correlation between the contribution of a selected sites to $V_a$ and their persistent associations with neutral alleles (i.e. deviations from Assumption G in B\&C)}
    \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 5}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:BC_simplified}
\DIFaddendFL \end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[H]
\begin{center}
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.14]{Figures/Fig6.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.14]{Figures/BC_full.jpg}
\DIFaddendFL \end{center}
\caption{Estimates of $V_A$ obtained using our method (\DIFdelbeginFL \DIFdelFL{G}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{g}\DIFaddendFL ) and various applications of the B\&C Approach (\DIFdelbeginFL \DIFdelFL{A--F}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a--f}\DIFaddendFL ) from full simulations with varying map lengths in the history phase: 0.5 \DIFdelbeginFL \DIFdelFL{morgans }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan }\DIFaddendFL (green), 5 morgans (magenta), 50 morgans (blue), and 100 morgans (grey). The solid black line indicates the 1:1 line. Each application of B\&C is defined in terms of which three assumptions (B, Ib, N) are required or not (designated with a \DIFaddbeginFL \DIFaddFL{`}\DIFaddendFL $+$\DIFaddbeginFL \DIFaddFL{' }\DIFaddendFL or \DIFaddbeginFL \DIFaddFL{`}\DIFaddendFL 0\DIFaddbeginFL \DIFaddFL{' }\DIFaddendFL superscript, respectively). Assumption B is that allele frequencies are tracked at unselected loci only, Assumption Ib is that the average LD between all sites is equal to the average LD between selected and unselected sites, and Assumption N is that the covariance between projected allele frequency changes is equal to the covariance between allele frequencies changes scaled by the average projection (see Table \DIFdelbeginFL \DIFdelFL{\ref{tab:Table_2} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\ref{tab:BC_approaches} }\DIFaddendFL for details). Panel \DIFdelbeginFL \DIFdelFL{H }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{h }\DIFaddendFL is the correlation between the contribution of a selected sites to $V_a$ and their persistent associations with neutral alleles (i.e. deviations from Assumption G in B\&C). For clarity of presentation, in (\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ), (\DIFdelbeginFL \DIFdelFL{C}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{c}\DIFaddendFL ), and (\DIFdelbeginFL \DIFdelFL{E}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{e}\DIFaddendFL ), we have restricted the range of the y axis between 0 and 0.35. As a consequence, points having an estimate of $V_A$ above 0.35 have been excluded from the plot for 0.5 \DIFdelbeginFL \DIFdelFL{morgans }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan }\DIFaddendFL (green).}
    \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure 6}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:BC_full}
\DIFaddendFL \end{figure}
\end{landscape}
\restoregeometry


\section*{Discussion}
\addcontentsline{toc}{section}{Discussion}

In this paper we estimate the additive genetic variance for relative fitness ($V_A$) directly from the change in the genetic composition of a population caused by selection. Assuming only the absence of meiotic drive, we show that $V_A$ can be conveniently expressed as a function of the genome-wide genetic diversity matrix $\textbf{L}$, and the vector of genome-wide expected allele frequency change due to selection\DIFaddbegin \DIFadd{, }\DIFaddend $E[\Delta{\textbf{p}}]$. In our inference approach, we describe how a linear mixed model can be employed to estimate $E[\Delta{\textbf{p}}]$ via independent evolutionary replicates derived from the same base population with a known $\textbf{L}$ -- a common feature of evolve-and-resequence studies.  Unlike alternative methods \citep{buffalo2019linked}, this allows us to obtain estimates of $V_A$ that are largely robust to the underlying genetic properties of the population and the genetic architecture of fitness. Moreover, the underlying \DIFdelbegin \DIFdel{modeling }\DIFdelend \DIFaddbegin \DIFadd{modelling }\DIFaddend framework not only allows $V_A$ to be estimated, but allows inferences about the relationship between effect sizes and allele frequency.    

Although $E[\Delta{p}]$'s at individual loci cannot be usefully estimated, for our purposes it is sufficient to estimate their distribution as parameterised through the mean vector $\boldsymbol{\mu_{\bar{\alpha}}}$ and the (co)variance matrix $\boldsymbol{V_{\bar{\alpha}}}$ for the distribution of the average effects for fitness, the $\alpha$'s. Our inference approach uses a low-dimensional (\DIFdelbegin \DIFdel{4-parameter}\DIFdelend \DIFaddbegin \DIFadd{3-parameter}\DIFaddend ), but biologically sensible, model for the means and (co)variances. It is superficially surprising that such a simple model for an $n_L$ (the number of loci) dimensional distribution can produce accurate results. However, in a typical dataset one expects the number of individuals, $N$, to be far smaller than the number of loci, $n_L$. Therefore, the non-null subspace of $\textbf{L}$ has only $N$ dimensions, and we can work with allele frequency changes projected into this reduced space. This provides a route to understanding how the distribution of $\alpha$'s can be estimated from selected changes in allele frequency that must be negligible compared to the impact of drift: the projection defines `\emph{chunks}' of genome, and it is the frequency changes in these chunks, rather than individual alleles, that are tracked. Since the aggregate fitness effects of alleles across chunks will be more substantial, they can be more easily detected. Moreover, since these aggregate effects may involve a large number of loci, they will, thanks to the central limit theorem, tend to normality and, conditional on the projection, converge in distribution. Since the projection is defined by ${\bf L}$, a model of the $\alpha$'s that conditions on aspects of ${\bf L}$ ($p-q$ and $pq$ in our case) is expected to be sufficient.      

The results of our simulations demonstrate that our approach provides usefully precise and consistent estimates of $V_A$ over a wide range of parameter combinations and experimental designs. In the simplified simulations, in which the relationship between allele frequencies and $\alpha$'s was expected to be absent, the model requires only a single parameter: the variance in average effects, $\sigma^2_{\bar{\alpha}}$. If such a model is assumed, this is a relatively straightforward inference problem and the method of \citet{buffalo2019linked} can give accurate estimates if selected and neutral sites can be distinguished, and certain patterns of recombination and linkage-disequilibrium hold.  Although our approach does not assume such a model, it can accurately infer $V_A$ and also the lack of relationship between allele frequencies and $\alpha$'s, with the \DIFdelbegin \DIFdel{three }\DIFdelend \DIFaddbegin \DIFadd{two }\DIFaddend parameters that determine the relationship between allele frequency and $\alpha$ all centered on their null expectations (\DIFdelbegin \DIFdel{Figure \ref{fig:Figure 1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{fig:simplified_main}}\DIFaddend ). However, in reality, independence between allele frequency and $\alpha$ seems implausible at mutation-selection-drift balance, and the elevated contribution of high-diversity loci to $V_A$ under the simple, but unrealistic, scenario may result in greater power to detect $V_A$.

At mutation-selection-drift balance a negative relationship is expected between $\alpha$'s and allele frequencies \citep{Charlesworth.2010}. Although it could be argued that the strength of this relationship will be reduced in experimental evolution studies, which generally expose populations to novel environmental stressors (such as a laboratory environment, pathogens \citep{basu2024experimental}, extreme population densities \citep{joshi1996density} and temperatures \citep{singh2015egg, hsu2024reproductive}, desiccation \citep{gibbs1997physiological}, malnutrition \citep{kawecki2021genomic}, or toxic substances \citep{godinho2024limits, xiao2019experimental}) it seems unlikely that no relationship would persist. Even under the more realistic scenario of our full simulations, in which the base population had evolved under selection for 25,000 generations, our approach provided reliable estimates of $V_A$ that were remarkably robust to the details of the distribution of fitness effects, such as the relative frequency of beneficial mutations, or properties of the population such as the recombination rate. Furthermore, it did so by correctly inferring a negative relationship between fitness effects of alleles and genetic diversity, and a positive relationship between fitness effects and $p-q$, as expected under mutation-selection balance.

\DIFdelbegin \DIFdel{Although our method }\DIFdelend \DIFaddbegin \DIFadd{An important assumption of our method is that any consistent change in the $\alpha$'s is vanishingly small in the time-frame over which allele frequency changes are recorded. However, when fitness-causing alleles act non-additively, $\alpha$'s depend on allele frequency and so are expected to change as allele frequencies change. In spite of this, in the simplified simulations where allele frequency change was expected to be large, the performance of the method was minimally affected when allowing dominance at all loci. Moreover, given the form $\alpha_i \approx \eta_i[1 - \kappa_i(p_i-q_i)]$ (where the product $\eta_i\kappa_i$ is always positive in our simulations), the method correctly inferred that the two parameters describing the relationship between the $\alpha$'s and allele frequencies would become increasingly negative with the degree of dominance (\ref{fig:combined_dominance}). Surprisingly, when we allowed dominance effects in the history phase and so allele frequencies and effects had come to an equilibrium we found that our method overestimated $V_A$ to varying degrees depending on how recessive the deleterious allele was. However, this was not because of a failure of the infinitesimal approximation in the experimental phase, but because substantial negative LD had built up during the history phase and our model of $V_{\bar \alpha}$ failed to capture this: the additive genetic variance was roughly half the additive genic variance.  It seems that our simulations were resulting in substantial pseudo-overdominance \mbox{%DIFAUXCMD
\citep{abu2023conditions} }\hskip0pt%DIFAUXCMD
- a phenomenon characteristic of regions of very low recombination \mbox{%DIFAUXCMD
\citep{salson2025interplay}}\hskip0pt%DIFAUXCMD
. When we performed identical simulations at higher recombination rates in the history phase, this problem was not observed.
}

\DIFadd{Our method }\DIFaddend generally performs well \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{in other respects, although }\DIFaddend some biases were observed. In terms of experimental design, small upward biases are evident when power is low - either because there are few replicates and/or allele frequency change is only calculated over a single generation. In terms of genetic architecture, our approach marginally underestimates $V_A$ when the fitness effects of new non-neutral mutations are large. This downward bias seems to arise because there is a large contribution of rare highly deleterious variants to $V_A$ and these get lost during the experimental phase. Nevertheless, even when 25\% of $V_A$ was lost during the course of the experiment the impact on estimates was rather minor.  Similarly, modest downward biases were observed when the recombination rate in the history phase was increased, but the source of this bias has been harder to diagnose. Increasing the recombination rate resulted in an increase in the number of segregating selected sites and their genetic diversity, and a steeper relationship between $\alpha$ and genetic diversity, consistent with a reduction in the effects of background selection \citep{charlesworth1993effect} on weakly selected sites \citep{stephan1999effect}.  While it is not clear why this causes downward bias in the estimates, it is also unclear whether real populations would ever have such extreme genetic architecture where the bulk of the additive genetic variance for fitness is caused by highly deleterious variants segregating at very low frequencies. In order to make the forward simulations manageable we were working with considerably smaller population and genome sizes than are typical of real populations. It is not clear, however, whether the standard rescaling of mutations rates, recombination rates and selection coefficients to accommodate this downsizing results in genetic architectures that would be typical of larger populations and larger genomes \citep{dabi2025population}. 

While our method performs well when applied to simulated data, application to real-world data would involve overcoming a number of challenges. First, we require genome-wide allele frequency change data from multiple independent evolutionary replicates -- although this should be readily available for most evolve-and-resequence experiments \DIFdelbegin \DIFdel{. }\DIFdelend \DIFaddbegin \DIFadd{using approaches such as pool-seq. An important point of consideration, therefore, is the minimum pool-seq coverage that the method requires. For our simplified simulations, there was little deterioration in model performance as coverage dropped or overdispersion increased, suggesting modest coverage (100x) should be sufficient if the appropriate covariance structure is used. While this might be surprising, the relevant parameter is probably not coverage }\emph{\DIFadd{per se}}\DIFadd{, but the number of reads overlapping at least one segregating site per unit map length, as this determines how accurately the frequency of a `chunk' of genome can be measured. Using a similar argument, \mbox{%DIFAUXCMD
\citet{tilk2019accurate} }\hskip0pt%DIFAUXCMD
demonstrated that supplementing pool-seq sampling with haplotype inference tools can result in nearly 500x `effective' coverage at 10x empirical coverage. Given the ancestral haplotype structure is a core requirement of our method, it may be possible that even greater precision could be achieved by also using such tools. However, this could come with the risk that estimation errors are correlated across replicates and be mistaken for patterns of selection. For our full simulations, a moderate downward bias was observed at 100x coverage. While this may suggest that our method demands relatively high coverage ($\geq$500x), it is worth noting that we only implemented an approximate (i.e. diagonal) covariance structure for pool-seq sampling while analysing our simulations due to computational limitations. Incorporating the full covariance structure should lead to improved estimates.
}

\DIFaddend Second, we require the genetic diversity matrix $\textbf{L}$ in the base population from which the replicates are derived. This is not always the case for evolve-and-resequence studies, in which base populations are often split into replicate baseline populations long before the experiment, or when newer selection regimes are derived mid-experiment \citep{burke2010genome,singh2015egg,gupta2016no, robinson2023evolution}. Furthermore, our method requires that sufficient individuals from the base population are individually sequenced  to estimate  $\textbf{L}$, or -- even better --  its gametic phase ($\textbf{L}^{'}$) and non-gametic phase ($\textbf{L}^{''}$) components, although the required phasing should become more readily available with long-read sequencing. Third, to predict how $\textbf{L}$ evolves, we require an estimate of the recombination probability between all pairs of segregating sites, such as a recombination map for the population. In reality, recombination maps are likely to have been derived from other populations, in which recombination patterns may differ \citep{johnston2024understanding}. Although recombination maps can be approximated, for example by using Haldane's mapping function, it is not clear how sensitive the method is to errors in the recombination map. Fourth, our method requires the mean number of generations over which allele frequency changes are calculated, which may be hard to infer with overlapping generations. \DIFdelbegin \DIFdel{As a first approximation, $V_A\approx E[\Delta({\bf p}^{\top})]{\bf L}^{-1}E[\Delta({\bf p})]/(\tau-t)^2$ where $\tau-t$ is }\DIFdelend \DIFaddbegin \DIFadd{Since allele-frequency change will be roughly proportional to }\DIFaddend the number of generations \DIFdelbegin \DIFdel{over which allele frequency is tracked. Consequently, estimates }\DIFdelend \DIFaddbegin \DIFadd{that have elapsed ($n_g$), and $V_A$ is quadratic in allele-frequency change, estimates of $V_A$ }\DIFaddend might be out by a factor \DIFdelbegin \DIFdel{$(\tau-t)^2/(\widehat{\tau-t})^2$}\DIFdelend \DIFaddbegin \DIFadd{$(n_g/\widehat{n_g})^2$, where $\widehat{n_g}$ is the assumed number of generations}\DIFaddend . Fifth, our method uses effective population size to predict how $\textbf{L}$ evolves ($N_e$) and to derive expressions for the drift (co)variance ($N_E$). Although reliable estimates of both effective population sizes may be hard to obtain, this is unlikely to be a major issue because: (i) $\textbf{L}^{'}$ decays with a rate roughly proportional to $1 - 1/N_e$ (likely making it insensitive to errors in estimating  $N_e$)  and (ii) our simulations suggest that using the wrong $N_E$ does not adversely affect our estimates of $V_A$ because the \DIFdelbegin \DIFdel{mispecification }\DIFdelend \DIFaddbegin \DIFadd{mis-specification }\DIFaddend is absorbed by the residual variance of the model. Sixth, our simulations minimise the unpredictable response to selection \DIFdelbegin \DIFdel{because our fitness model is close to being additive and so the average effects remain relatively constant as allele frequencies change}\DIFdelend \DIFaddbegin \DIFadd{by modelling a constant environment}\DIFaddend . However, with \DIFdelbegin \DIFdel{greater non-additivity and/or }\DIFdelend selection coefficients that vary in time or across replicates, the unpredictable response to selection will be greater. Indeed in outdoor mesocosms of \emph{D. melanogaster}, \citet{Bitter.2024} report that allele frequency changes can switch signs over time-points separated by a matter of weeks in spite of exhibiting highly concordant evolution between replicates. It is not clear to what degree this will affect inferences. Finally, selection can often act in different ways in different contexts such as space \citep{whitlock2015modern, delph2018study}, time, and between the two sexes \citep{schenkel2018making}. Our approach captures the effects of selection averaged over all these different contexts. Specifically, if loci have different fitness effects in males and females, we effectively estimate $(V_{A,f} + V_{A,m} + 2COV_{A,mf})/4$, where $V_{A,f}$ and $V_{A,m}$ are the additive genetic variances for relative fitness in females and males respectively, and $COV_{A,mf}$ is the intersexual additive genetic covariance for relative fitness. For these reasons, when applied to replicate populations, our estimates of $V_A$ are perhaps best thought of as the additive genetic \emph{covariance} in fitness between replicates. Although rarely made explicit, estimates from wild systems should be interpreted in the same way: the additive genetic covariance between the environments in which relatives live \citep{Vehvilainen.2008}.   

Analysing data from wild populations is likely to entail further challenges. For example, in natural populations, allele frequency change from immigration may be consequential, and without some modification is likely to be mistaken for allele frequency change caused by natural selection \citep{simon2024contribution}. Furthermore, replicate populations are unlikely to be available for natural systems -- with some exceptions such as Trinidadian guppies \citep{reznick1996life} -- although with some modifications our method could be adapted to use allele frequency change data from multiple time points. However, a lack of individual-level sequences in the base population would mean that the estimates of $\textbf{L}$ will likely be considerably noisier in natural populations. 

While we accept that the data requirements for our method are steep, and the list of caveats appears long, we do think that information about $V_A$ can be successfully leveraged from current evolve and resequence studies. Going forward, we hope this work will inform future evolve and resequence study design, and that estimates of $V_A$ from a wide range of organisms and environments \DIFdelbegin \DIFdel{becomes }\DIFdelend \DIFaddbegin \DIFadd{become }\DIFaddend available. Partitioning $V_A$ into genomic features is an obvious next step, and in the future we hope to go beyond simply knowing the magnitude of $V_A$ and start to understand its underlying causes.

\section*{Data \DIFdelbegin \DIFdel{Availability Statement}\DIFdelend \DIFaddbegin \DIFadd{availability statement}\DIFaddend }
\addcontentsline{toc}{section}{Data Availability Statement}
This study does not use any data. The code used for simulations and analyses is available in the following GitHub repository: \url{https://github.com/manas-ga/Va_simulations}.

\section*{Acknowledgments}
\addcontentsline{toc}{section}{Acknowledgments}

The authors would like to thank Bill Hill, Brian Charlesworth, Peter Keightley, Konrad Lohse, Bruce Walsh, Ben Longdon and Vince Buffalo for their insightful comments, and The Argyle for hosting us at the early stages of this project. Computer simulations \DIFaddbegin \DIFadd{and analyses }\DIFaddend described here were performed on the AC3 computing cluster based at Ashworth Laboratories, \DIFaddbegin \DIFadd{and on Eddie, }\DIFaddend the University of Edinburgh\DIFaddbegin \DIFadd{'s main high performance computing facility}\DIFaddend .

\section*{\DIFdelbegin \DIFdel{Funding}\DIFdelend \DIFaddbegin \DIFadd{Study funding}\DIFaddend }
\addcontentsline{toc}{section}{\DIFdelbegin \DIFdel{Funding}\DIFdelend \DIFaddbegin \DIFadd{Study funding}\DIFaddend }
This work was funded by a Natural Environment Research Council (NERC) grant (reference: NE/W001330/1). For the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) license to any Author Accepted Manuscript version arising from this submission.

\section*{Conflict of \DIFdelbegin \DIFdel{Interest}\DIFdelend \DIFaddbegin \DIFadd{interest}\DIFaddend }
\addcontentsline{toc}{section}{Conflict of \DIFdelbegin \DIFdel{Interest}\DIFdelend \DIFaddbegin \DIFadd{interest}\DIFaddend }
The authors have no conflicts of interest to declare.

\putbib
\end{bibunit}
\newpage
\begin{longtable}{|p{2cm}|p{13cm}|}
\hline
Symbol&Description\\
\hline
\DIFdelbegin \DIFdel{$w$}\DIFdelend \DIFaddbegin \DIFadd{${\bf B}$}\DIFaddend &\DIFdelbegin \DIFdel{Relative fitness}\DIFdelend \DIFaddbegin \DIFadd{Diagonal matrix of standard deviations for the $c$'s}\DIFaddend \\
\DIFdelbegin \DIFdel{$W$}\DIFdelend \DIFaddbegin \DIFadd{$c_{k,i}$}\DIFaddend & \DIFdelbegin \DIFdel{Absolute fitness}\DIFdelend \DIFaddbegin \DIFadd{Number of reference alleles at locus $i$ for individual $k$ divided by 2.}\DIFaddend \\
\DIFdelbegin \DIFdel{$V_A$}%DIFDELCMD < &%%%
\DIFdel{Additive genetic variance for relative fitness}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$V_a$}%DIFDELCMD < &%%%
\DIFdel{Additive genic variance for relative fitness}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$t_m$}%DIFDELCMD < &%%%
\DIFdel{Time at which allele frequencies are first measured in replicate $m$.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$\tau_m$}%DIFDELCMD < &%%%
\DIFdel{Time at which allele frequencies are finally measured in replicate $m$.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdelend $C_{A}(t\rightarrow\tau)$&Additive genetic covariance for relative fitness between generation $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$.\\
$C_{a}(t\rightarrow\tau)$&Additive genic covariance for relative fitness between generation $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$.\\
\DIFdelbegin \DIFdel{$\boldsymbol{\alpha}_{t,m}$}\DIFdelend \DIFaddbegin \DIFadd{${\bf D}_{2}$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of average effects for relative fitness at time $t$ in replicate $m$.}\DIFdelend \DIFaddbegin \DIFadd{Diagonal matrix of square-rooted eigenvalues of $\boldsymbol{\mathcal{D}}$}\DIFaddend \\
\DIFdelbegin \DIFdel{$\bar{\boldsymbol{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mathcal{D}}_m$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of mean average effects for relative fitness.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$\Delta{\bf \alpha}_{t,m}$}%DIFDELCMD < &%%%
\DIFdel{Vector of deviations of the average effects for relative fitness at time $t$ in }\DIFdelend \DIFaddbegin \DIFadd{Matrix that gives the covariance in allele frequency changes between generation $t_m$ and $\tau_m$ in }\DIFaddend replicate $m$ \DIFdelbegin \DIFdel{from the global mean}\DIFdelend \DIFaddbegin \DIFadd{due to drift}\DIFaddend .\\
\DIFdelbegin \DIFdel{$c_{k,i}$}\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mathcal{E}}_m$}\DIFaddend &\DIFdelbegin \DIFdel{Number of reference alleles at locus $i$ for individual $k$ divided by 2.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$n_L$}%DIFDELCMD < &%%%
\DIFdel{Number of loci.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$N_{t,m}$}%DIFDELCMD < &%%%
\DIFdel{Census population size at time $t$ in replicate $m$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$N_{e_{t,m}}$}%DIFDELCMD < &%%%
\DIFdel{Variance effective population size at time $t$ in replicate $m$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$N_{E_{t,m}}$}%DIFDELCMD < &%%%
\DIFdel{Variance effective population size at time $t$ in replicate $m$ ignoring the impact of linked-selection}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$\boldsymbol{\eta}_{t,m}$}%DIFDELCMD < &%%%
\DIFdel{Linear model coefficients for the $c$'s on $log(W)$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf p}_{t,m}$}%DIFDELCMD < & %%%
\DIFdel{Vector of reference allele frequencies at time $t$ }\DIFdelend \DIFaddbegin \DIFadd{Matrix that gives the covariance in allele frequency change estimation errors }\DIFaddend in replicate $m$.\\
\DIFdelbegin \DIFdel{${\bf q}_{t,m}$}\DIFdelend \DIFaddbegin \DIFadd{${\bf F}_{t\tau}$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of alternate allele frequencies at time $t$ in replicate $m$}\DIFdelend \DIFaddbegin \DIFadd{${\bf W}_{t\tau}$ but with the diagonals set to zero}\DIFaddend .\\
\DIFdelbegin \DIFdel{$\Delta {\bf p}_{t,m}$}\DIFdelend \DIFaddbegin \DIFadd{$g$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of reference allele frequency changes between time $t$ and $t+1$ in replicate $m$.}\DIFdelend \DIFaddbegin \DIFadd{Total branch length of the tree sequence recorded in the history phase of the simulations}\DIFaddend \\
\DIFdelbegin \DIFdel{$\Delta {\bf p}_{m}$}\DIFdelend \DIFaddbegin \DIFadd{${\bf H}_{t\tau}$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of reference allele frequency changes between time $t_m$ and $\tau_m$ in replicate $m$}\DIFdelend \DIFaddbegin \DIFadd{${\bf W}_{t\tau}$ but with the off-diagonals set to zero}\DIFaddend .\\
${\bf L}_{t,m}$&Covariance matrix of c's at time $t$ in replicate $m$.\\
${\bf L}^{'}_{t,m}$&Covariance matrix of $c$'s at time $t$ in replicate $m$ due to being on the same gametic contribution. \\
${\bf L}^{''}_{t,m}$&Covariance matrix of $c$'s at time $t$ in replicate $m$ due to being on different gametic contributions. \\
$\Delta{\bf L}^{'}_{t,m}$&The stochastic change in ${\bf L}^{'}$ between time zero and $t$ in replicate $m$.\\
\DIFdelbegin \DIFdel{$z_{i_{t},j_{t}}$}%DIFDELCMD < &%%%
\DIFdel{$(1-r_{i_{t},j_{t}})(1-\frac{1}{2N_{e_t}})$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{$\zeta_{i_{t},j_{t}}$}%DIFDELCMD < &%%%
\DIFdel{$r_{i_{t},j_{t}}(1-\frac{1}{2N_{e_t}})$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdelend $\tilde{\bf L}_{0}$&Weighted sum of ${\bf L}^{'}_0$ and ${\bf L}^{''}_0$ with weights for element $ij$ being 1 and \DIFdelbegin \DIFdel{$z_{i_{0},j_{0}}/\zeta_{i_{0},j_{0}}$ }\DIFdelend \DIFaddbegin \DIFadd{$z_{{0},ij}/\zeta_{{0},ij}$ }\DIFaddend respectively.\\
\DIFdelbegin \DIFdel{$r_{i,j}$}\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mathcal{L}}_{t,m}$}\DIFaddend &\DIFdelbegin \DIFdel{Recombination rate between loci $i$ }\DIFdelend \DIFaddbegin \DIFadd{A matrix that gives, when post-multiplied by $\boldsymbol{\alpha}$, the predictable change in allele frequency due to selection between generation $t_m$ }\DIFaddend and \DIFdelbegin \DIFdel{$j$.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf R}_{+}$}%DIFDELCMD < &%%%
\DIFdel{Matrix of recombination probabilities.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf R}_{-}$}%DIFDELCMD < &%%%
\DIFdel{Matrix of non-recombination probabilities.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf N}_{t,m}$}%DIFDELCMD < &%%%
\DIFdel{Matrix of weights for $\tilde{\bf L}_{0}$ that givesthe expected ${\bf L}$ at time $t>0$ in replicate $m$.}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf N}_{m}$}%DIFDELCMD < &%%%
\DIFdel{Matrix of weights for $\tilde{\bf L}_{0}$ that gives the sum of the expected ${\bf L}$ from time $t_m>0$ to $\tau_m$ }\DIFdelend \DIFaddbegin \DIFadd{$t_m+1$ }\DIFaddend in replicate $m$.\\
$\boldsymbol{\mathcal{L}}_m$&A matrix that gives, when post-multiplied by $\boldsymbol{\alpha}$, the predictable change in allele frequency due to selection between generation $t_m$ and $\tau_m$ in replicate $m$.\\
${\bf M}_{t,m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the covariance in allele frequency changes  due to drift between time $t>0$ and $t+1$ in replicate $m$.\\
${\bf M}_{m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the covariance in allele frequency changes  due to drift between time $t_m>0$ and $\tau_m$ in replicate $m$\DIFaddbegin \\
\DIFadd{$n_L$}&\DIFadd{Number of loci}\\
\DIFadd{$n_{L_\mathcal{S}}$}&\DIFadd{Number of non-neutral segregating sites}\\
\DIFadd{$N_{t,m}$}&\DIFadd{Census population size at time $t$ in replicate $m$}\\
\DIFadd{$N_{e_{t,m}}$}&\DIFadd{Variance effective population size at time $t$ in replicate $m$}\\
\DIFadd{$N_{E_{t,m}}$}&\DIFadd{Variance effective population size at time $t$ in replicate $m$ ignoring the impact of linked-selection}\\
\DIFadd{${\bf N}_{t,m}$}&\DIFadd{Matrix of weights for $\tilde{\bf L}_{0}$ that gives the expected ${\bf L}$ at time $t>0$ in replicate $m$}\DIFaddend .\\
\DIFdelbegin \DIFdel{$\boldsymbol{\mathcal{D}}_m$}\DIFdelend \DIFaddbegin \DIFadd{${\bf N}_{m}$}\DIFaddend &Matrix \DIFaddbegin \DIFadd{of weights for $\tilde{\bf L}_{0}$ }\DIFaddend that gives the \DIFdelbegin \DIFdel{covariance in allele }\DIFdelend \DIFaddbegin \DIFadd{sum of the expected ${\bf L}$ from time $t_m>0$ to $\tau_m$ in replicate $m$.}\\
\DIFadd{$\mathcal{N}$}&\DIFadd{Used as a subscript to indicate the set of neutral loci.}\\
\DIFadd{$O_{ij}$}& \DIFadd{Number of pool-seq reads spanning sites $i$ and $j$. If $i=j$, $O_{ij}$ is the coverage.}\\
\DIFadd{$p_{\bar{\alpha}}$}&\DIFadd{Parameter that takes ${\bf L}_0$ to some power }\\
\DIFadd{${\bf p}_{t,m}$}& \DIFadd{Vector of reference allele frequencies at time $t$ in replicate $m$.}\\
\DIFadd{$\Delta {\bf p}_{t,m}$}&\DIFadd{Vector of reference allele }\DIFaddend frequency changes between \DIFdelbegin \DIFdel{generation }\DIFdelend \DIFaddbegin \DIFadd{time $t$ and $t+1$ in replicate $m$.}\\
\DIFadd{$\Delta {\bf p}_{m}$}&\DIFadd{Vector of reference allele frequency changes between time }\DIFaddend $t_m$ and $\tau_m$ in replicate $m$\DIFdelbegin \DIFdel{due to drift}\DIFdelend .\\
\DIFaddbegin \DIFadd{${\bf P}$}&\DIFadd{Projection matrix for allele frequencies.}\\
\DIFadd{${\bf q}_{t,m}$}& \DIFadd{Vector of alternate allele frequencies at time $t$ in replicate $m$.}\\
\DIFadd{${\bf Q}_m$}& \DIFadd{Matrix that is proportional to the covariance in allele frequency change estimation errors in replicate $m$.}\\
\DIFadd{$r_{ij}$}&\DIFadd{Recombination rate between loci $i$ and $j$.}\\
\DIFadd{$R_{t,ij}$}&\DIFadd{Correlation in allele count between locus $i$ and $j$ at time $t$ (Note the use of the uppercase to distinguish from the recombination rate $r$).}\\
\DIFadd{${\bf R}_{+}$}&\DIFadd{Matrix of recombination probabilities.}\\
\DIFadd{${\bf R}_{-}$}&\DIFadd{Matrix of non-recombination probabilities.}\\
\DIFadd{${\bf R}$}&\DIFadd{Correlation matrix of the $c$'s.}\\
\DIFadd{${\bf S}_{\bar{\alpha}}$}&\DIFadd{Sampling covariance matrix for the parameters of the regression on the mean average effects, $\boldsymbol{\beta}_{\bar{\alpha}}$.\ }\\
\DIFadd{$\mathcal{S}$}&\DIFadd{Used as a subscript to indicate the set of selected loci.}\\
\DIFadd{$t_m$}&\DIFadd{Time at which allele frequencies are first measured in replicate $m$.}\\
\DIFadd{${\bf U}_{\bf L}$}&\DIFadd{Eigenvectors of ${\bf L}_0$.}\\
\DIFadd{${\bf U}_{2}$}&\DIFadd{Eigenvectors of $\boldsymbol{\mathcal{D}}$}\\
\DIFaddend $\boldsymbol{\mathcal{U}}_m$&Matrix that gives the covariance in allele frequency changes between generation $t_m$ and $\tau_m$ in replicate $m$ due to the unpredictable response to selection.\\
\DIFdelbegin \DIFdel{$\boldsymbol{\mu}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$V_a(t)$}\DIFaddend &\DIFdelbegin \DIFdel{Vector of expected values }\DIFdelend \DIFaddbegin \DIFadd{Additive genic variance for relative fitness at time $t$}\\
\DIFadd{$V_A(t)$}&\DIFadd{Additive genetic variance for relative fitness at time $t$}\\
\DIFadd{$V_{\bar A}(t)$}&\DIFadd{Additive genetic covariance between replicate/time-points for relative fitness in a population with genotypic composition equal to that at time $t$.}\\
\DIFadd{$V_x$}&\DIFadd{Variance of the normal distribution from which $log(\lambda_{x})$'s are sampled}\\
\DIFadd{$\bf{V}_{\bar{\alpha}}$}&\DIFadd{Covariance matrix }\DIFaddend for the mean average effects.\\\DIFdelbegin \DIFdel{$\beta^{(0)}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{\
$w$}\DIFaddend &\DIFdelbegin \DIFdel{Intercept of the }\DIFdelend \DIFaddbegin \DIFadd{Relative fitness}\\
\DIFadd{$W$}&\DIFadd{Absolute fitness}\\
\DIFadd{${\bf W}_{t\tau}$}&\DIFadd{A matrix with the $ij^{th}$ element equal to $R_{t,ji}R_{\tau,ki}(b_{\tau,i}/b_{t,i})$}\\
\DIFadd{${\bf X}$}&\DIFadd{Design matrix for the }\DIFaddend regression of the mean average effects on \DIFdelbegin \DIFdel{some covariate}\DIFdelend \DIFaddbegin \DIFadd{${\bf p}_0 - {\bf q}_0$}\DIFaddend .\\
\DIFdelbegin \DIFdel{$\beta^{(1)}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{${y_{k,i}}$}\DIFaddend &\DIFdelbegin \DIFdel{Slope of the regression of the mean average effects on some covariate}\DIFdelend \DIFaddbegin \DIFadd{Genotypic contribution made by locus $i$ to the log absolute fitness ($log(W)$) of individual $k$}\\
\DIFadd{$Y_k$}&\DIFadd{Genotypic value of log fitness for individual $k$}\\
\DIFadd{$z_{t,ij}$}&\DIFadd{$(1-r_{t,ij})(1-\frac{1}{2N_{e_t}})$}\\
\DIFadd{$\boldsymbol{\alpha}_{t,m}$}& \DIFadd{Vector of average effects for relative fitness at time $t$ in replicate $m$}\DIFaddend .\\
\DIFdelbegin \DIFdel{${\bf X}$}\DIFdelend \DIFaddbegin \DIFadd{$\bar{\boldsymbol{\alpha}}$}\DIFaddend & \DIFdelbegin \DIFdel{Design matrix for the regression of the }\DIFdelend \DIFaddbegin \DIFadd{Vector of }\DIFaddend mean average effects \DIFdelbegin \DIFdel{on some covariate}\DIFdelend \DIFaddbegin \DIFadd{for relative fitness}\DIFaddend .\\
\DIFdelbegin \DIFdel{${\bf S}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\Delta{\bf \alpha}_{t,m}$}\DIFaddend &\DIFdelbegin \DIFdel{Sampling covariance matrix for the parameters of the regression of the mean average effects on some covariate.\ }\DIFdelend \DIFaddbegin \DIFadd{Vector of deviations of the average effects for relative fitness at time $t$ in replicate $m$ from the global mean.}\DIFaddend \\
\DIFdelbegin \DIFdel{$\bf{V}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\beta^{(1)}_{\bar{\alpha}}$}\DIFaddend &\DIFdelbegin \DIFdel{Covariance matrix for the }\DIFdelend \DIFaddbegin \DIFadd{Slope of the regression of the }\DIFaddend mean average effects \DIFaddbegin \DIFadd{on ${\bf p}_0 - {\bf q}_0$}\DIFaddend .\\
\DIFdelbegin \DIFdel{\
$p_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\zeta_{t,ij}$}\DIFaddend &\DIFdelbegin \DIFdel{Parameter that takes ${\bf L}_0$ to some power }\DIFdelend \DIFaddbegin \DIFadd{$r_{t,ij}(1-\frac{1}{2N_{e_t}})$}\DIFaddend \\
\DIFdelbegin \DIFdel{$\sigma^{2}_{\bar{\alpha}}$}\DIFdelend \DIFaddbegin \DIFadd{$\eta_{i}$}\DIFaddend & \DIFdelbegin \DIFdel{Proportionality constant that relates $\bf{V}_{\bar{\alpha}}$ to ${\bf L}_{0}^{p_{\bar{\alpha}}}$.}\DIFdelend \DIFaddbegin \DIFadd{Difference between the genotypic contributions to $log(W)$ by the reference and non-reference homozygotes at locus $i$}\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf P}$}\DIFdelend \DIFaddbegin \DIFadd{$\eta_i^{(a)}$}\DIFaddend &\DIFdelbegin \DIFdel{Projection matrix for allele frequencies.}\DIFdelend \DIFaddbegin \DIFadd{Average effect for $log(W)$ at locus $i$}\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf U}_{\bf L}$}\DIFdelend \DIFaddbegin \DIFadd{$\eta_{scale}$}\DIFaddend &\DIFdelbegin \DIFdel{Eigenvectors of ${\bf L}_0$.}\DIFdelend \DIFaddbegin \DIFadd{Scale of the gamma distribution from which $\eta's$ were sampled in the history phase of the simulations}\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf U}_{2}$}\DIFdelend \DIFaddbegin \DIFadd{$\kappa_i$}\DIFaddend &\DIFdelbegin \DIFdel{Eigenvectors of $\boldsymbol{\mathcal{D}}$}\DIFdelend \DIFaddbegin \DIFadd{Degree of dominance at locus $i$ for log absolute fitness. }\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf D}_{2}$}\DIFdelend \DIFaddbegin \DIFadd{$\lambda_{x,k}$}\DIFaddend &\DIFdelbegin \DIFdel{Diagonal matrix of square-rooted eigenvalues of $\boldsymbol{\mathcal{D}}$}\DIFdelend \DIFaddbegin \DIFadd{Mean of the Poisson distribution from which the number of reads mapping to individual $k$ are sampled while simulating pool-seq }\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf B}$}\DIFdelend \DIFaddbegin \DIFadd{$\mu_{msp}$}\DIFaddend &\DIFdelbegin \DIFdel{Diagonal matrix of standard deviations for the $c$'s}\DIFdelend \DIFaddbegin \DIFadd{Mutation rate for non-neutral mutations in the coalescent part of the history phase of the simulations}\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf R}$}\DIFdelend \DIFaddbegin \DIFadd{$\mu_{SLiM}$}\DIFaddend & \DIFdelbegin \DIFdel{Correlation matrix of the $c$'s.}\DIFdelend \DIFaddbegin \DIFadd{Mutation rate for non-neutral mutations in the forward part of the history phase of the simulations}\DIFaddend \\
\DIFdelbegin \DIFdel{$R_{j_t,i_t}$}\DIFdelend \DIFaddbegin \DIFadd{$\mu_x$}\DIFaddend &\DIFdelbegin \DIFdel{Correlation in allele count between locus $i$ and $j$ at time $t$ (Note the use of the uppercase to distinguish from the recombination rate $r$).}\DIFdelend \DIFaddbegin \DIFadd{Mean of the normal distribution from which $log(\lambda_{x})$'s are sampled}\DIFaddend \\
\DIFdelbegin \DIFdel{${\bf W}_{t\tau}$}\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\mu}_{\bar{\alpha}}$}\DIFaddend &\DIFdelbegin \DIFdel{A matrix with the $ij^{th}$ element equal to $R_{j_t,i_t}R_{k_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$}%DIFDELCMD < \\
%DIFDELCMD < %%%
\DIFdel{${\bf H}_{t\tau}$}%DIFDELCMD < &%%%
\DIFdel{${\bf W}_{t\tau}$ but with the off-diagonals set to zero}\DIFdelend \DIFaddbegin \DIFadd{Vector of expected values for the mean average effects}\DIFaddend .\\
\DIFdelbegin \DIFdel{${\bf F}_{t\tau}$}\DIFdelend \DIFaddbegin \DIFadd{$\sigma^{2}_{\bar{\alpha}}$}\DIFaddend &\DIFdelbegin \DIFdel{${\bf W}_{t\tau}$ but with the diagonals set to zero}\DIFdelend \DIFaddbegin \DIFadd{Proportionality constant that relates $\bf{V}_{\bar{\alpha}}$ to ${\bf L}_{0}^{p_{\bar{\alpha}}}$}\DIFaddend .\\
\DIFdelbegin \DIFdel{$\mathcal{S}$}\DIFdelend \DIFaddbegin \DIFadd{$\sigma^2_o$}\DIFaddend & \DIFdelbegin \DIFdel{Used as a subscript to indicate the set of selected loci}\DIFdelend \DIFaddbegin \DIFadd{Parameter for scaling sampling (co)variances for allele frequencies: values greater than 1 indicate overdispersion}\DIFaddend .\\
\DIFdelbegin \DIFdel{$\mathcal{N}$}\DIFdelend \DIFaddbegin \DIFadd{$\tau_m$}\DIFaddend &\DIFdelbegin \DIFdel{Used as a subscript to indicate the set of neutral loci}\DIFdelend \DIFaddbegin \DIFadd{Time at which allele frequencies are finally measured in replicate $m$}\DIFaddend .\\
$\phi_{t,\tau}$&The ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ assumed constant across all selected loci.\\
\DIFaddbegin \DIFadd{$\overrightarrow{}$}&\DIFadd{Used above a symbol to indicate it is on the projected space.}\\
\DIFadd{$\widehat{\ \ \ \ }$}&\DIFadd{Used above a symbol to indicate an estimate.}\\
\DIFaddend \hline
\caption{Notation}
\label{tab:notation}
\end{longtable}

\newpage
\DIFaddbegin 

\begin{center}
    \DIFaddend {\Large \bf Supplementary \DIFdelbegin \DIFdel{data}\DIFdelend \DIFaddbegin \DIFadd{information}\DIFaddend }
\DIFaddbegin \end{center}
\DIFaddend 



\begin{bibunit}

\setcounter{equation}{0}
    \renewcommand{\theequation}{S\arabic{equation}}
    \setcounter{figure}{0}
    \DIFdelbegin %DIFDELCMD < \renewcommand{\thefigure}{S\arabic{figure}}
%DIFDELCMD <     %%%
\DIFdelend \DIFaddbegin \renewcommand{\thefigure}{Supplementary Figure \arabic{figure}}
    \DIFaddend \setcounter{section}{0}
    \renewcommand{\thesection}{S\arabic{section}}

    
%\addcontentsline{toc}{section}{Appendix}
\section{\DIFdelbegin \DIFdel{Appendix 1: }\DIFdelend The dynamics of ${\bf L}$ under drift and recombination.} \label{Appendix:LD}
%\addcontentsline{toc}{subsection}{Appendix 3: The dynamics of ${\bf L}$ under drift and recombination.}
\DIFaddbegin \DIFadd{As outlined in the section `Extending our approach to practical situations' our goal is to infer the additive genetic variance for relative fitness in the base population ($V_{\bar A}(0)$) using genome-wide allele frequency changes between generations $t$ and $\tau$. In order to derive the expected allele frequency change due to selection over this time period, we first derive the expected dynamics of $\bf L$ under drift and recombination.
}\DIFaddend 

The matrix ${\bf L}$ is a covariance matrix whose elements are proportional to the genotypic linkage-disequilbria (off-diagonals) or variance in genotypic allele frequencies (diagonals) at the start of a generation, before selection has acted. We can decompose  ${\bf L}$ into ${\bf L}^{'}$ and ${\bf L}^{''}$ following the notation of \citet{buffalo2019linked} where ${\bf L}^{'}$ represents the (co)variances that arise due to alleles in the same gamete and ${\bf L}^{''}$ represents the (co)variances that arise due to alleles in the different gametic contributions of a genotype. Note that in \citet{Santiago.1998} the primes have a subtly different meaning after the initial generation, as the double prime in following generations designates gametic phase disequilibrium due to recombination and nongametic phase disequilibrium in the initial generation. The elements of ${\bf L}^{'}$ and ${\bf L}^{''}$ have direct correspondences with genetic diversities and additive measures of disequilibria. Under the notation of \citet{Weir.1989} (see also \citet{bulmer1980mathematical}, Chapter 12), the diagonal elements of ${\bf L}^{'}$ are half the gametic genetic diversities (\DIFdelbegin \DIFdel{$\pi_i=p_i(1-p_i)=2L^{'}_{i,i}$}\DIFdelend \DIFaddbegin \DIFadd{$\pi_i=p_i(1-p_i)=2L^{'}_{ii}$}\DIFaddend ), and the off-diagonals are half the gametic-phase disequilibria (\DIFdelbegin \DIFdel{$D_{i,j}=2L^{'}_{i,j}$}\DIFdelend \DIFaddbegin \DIFadd{$D_{ij}=2L^{'}_{ij}$}\DIFaddend ). Note that \citet{Weir.1989} uses $\pi$ to denote $p_i(1-p_i)$ rather than the more usual (and less natural) $2p_i(1-p_i)$. The diagonal elements of ${\bf L}^{''}$ are half the additive coefficients of Hardy Weinberg disequilibria (\DIFdelbegin \DIFdel{$D_{i}=2L^{''}_{i,i}$}\DIFdelend \DIFaddbegin \DIFadd{$D_{i}=2L^{''}_{ii}$}\DIFaddend ), and the off-diagonals are half the nongametic-phase disequilibria (\DIFdelbegin \DIFdel{$D_{i/j}=2L^{''}_{i,j}$}\DIFdelend \DIFaddbegin \DIFadd{$D_{i/j}=2L^{''}_{ij}$}\DIFaddend ). 

To see these correspondences, imagine two bi-allelic loci, $i$ and $j$, with reference/alternate alleles A/a and B/b, respectively. There are four possible gametic haplotypes, and we can denote the frequency of haplotype \DIFdelbegin \DIFdel{$mn$ as $p_{mn}$ }\DIFdelend \DIFaddbegin \DIFadd{$AB$ as $p_{AB}$ }\DIFaddend in the gametes and the frequency of allele \DIFdelbegin \DIFdel{$m$ as $p_m$ ($m$ and $n$ are indexing variables for allelic states at locus A/a and locus B/b, respectively)}\DIFdelend \DIFaddbegin \DIFadd{$A$ as $p_A$}\DIFaddend . The proportion of copies of the reference allele at locus $i$ in a randomly chosen individual\DIFdelbegin \DIFdel{-- i.e. }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend $c_i$\DIFdelbegin \DIFdel{-- }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend can be decomposed into into the sum of maternal and paternal contribution: $c_i = m_i+f_i$ where $m_i$ (or $f_i$) takes the value 1/2 if the mother (or the father) contributed a reference allele and 0 if not. Then,

\begin{equation}
\begin{array}{rl}
L_{i,j} =& COV(c_i, c_j)\\
        =& COV(m_i+f_i,  m_j+f_j)\\
        =& COV(m_i,  m_j)+COV(f_i,f_j)+COV(m_i,  f_j)+COV(f_i,  m_j)\\
\end{array}
\end{equation}

Assuming haplotype frequencies are identical in male and female gametes we get

\begin{equation}
\begin{array}{rl}
L_{i,j} =& (p_{AB}-p_{A}p_{B})/4+(p_{AB}-p_{A}p_{B})/4+(p_{A/B}-p_{A}p_{B})/4+(p_{A/B}-p_{A}p_{B})/4\\
=& (p_{AB}-p_{A}p_{B})/2+(p_{A/B}-p_{A}p_{B})/2\\
=& D_{i,j}/2+D_{i/j}/2\\
\end{array}
\end{equation}

where $p_{A/B}$ is the frequency of zygotes that have an A from their mother and a B from their father, or vice versa.  When $i=j$,

\begin{equation}
\begin{array}{rl}
L_{i,i} =& COV(c_i, c_i)\\
=& (p_{A}^2-p_{A})/2+(p_{A/A}-p_{A}^2)/2\\
=& \pi_i/2+D_{i}/2\\
\end{array}
\end{equation}

where $p_{A/A}$ is the frequency of $A$ homozygotes. The term $D_i$ is an alternative, additive, measure of deviation from Hardy-Weinberg Equilibrium than the more commonly used inbreeding coefficient, $F$. 

To derive expressions for the dynamics of ${\bf L}^{'}$ and ${\bf L}^{''}$, note that ${\bf L}^{''}$ is generated anew each generation \DIFaddbegin \DIFadd{and }\DIFaddend under random mating \DIFdelbegin \DIFdel{and in a finite population }\DIFdelend has zero expectation such that

\begin{equation}
L^{''}\DIFdelbegin \DIFdel{_{i_{t+1}, j_{t+1}} }\DIFdelend \DIFaddbegin \DIFadd{_{{t+1},i j} }\DIFaddend = e^{''}\DIFdelbegin \DIFdel{_{i_{t+1}, j_{t+1}}
}\DIFdelend \DIFaddbegin \DIFadd{_{{t+1},ij}
}\DIFaddend \end{equation}

where \DIFdelbegin \DIFdel{$e^{''}_{i_{t+1}, j_{t+1}}$ }\DIFdelend \DIFaddbegin \DIFadd{$e^{''}_{{t+1},ij}$ }\DIFaddend is a stochastic term with mean zero and variance given in \citet{Weir.1996}. The elements of ${\bf L}^{'}$ under recombination and drift are \citep{Hill.1968, Santiago.1998}

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < L^{'}_{i_{t+1},j_{t+1}} =& \left(1-\frac{1}{2N_{e_t}}
%DIFDELCMD < \right)\left((1-r_{i_{t},j_{t}})L^{'}_{i_{t},j_{t}} + r_{i_{t},j_{t}}L^{''}_{i_{t},j_{t}}\right)+e^{'}_{i_{t+1},j_{t+1}}\\
%DIFDELCMD < =& z_{i_{t},j_{t}}L^{'}_{i_{t},j_{t}} + \zeta_{i_{t},j_{t}}L^{''}_{i_{t},j_{t}}+e^{'}_{i_{t+1},j_{t+1}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
L^{'}_{{t+1},ij} =& \left(1-\frac{1}{2N_{e_t}}
\right)\left((1-r_{t,ij})L^{'}_{t,ij} + r_{t,ij}L^{''}_{t,ij}\right)+e^{'}_{{t+1},ij}\\
=& z_{t,ij}L^{'}_{t,ij} + \zeta_{t,ij}L^{''}_{t,ij}+e^{'}_{{t+1},ij}\\
\end{array}\DIFaddend 
\end{equation}

where \DIFdelbegin \DIFdel{$z_{i_{t},j_{t}}=(1-r_{i_{t},j_{t}})(1-\frac{1}{2N_{e_t}})$ and  $\zeta_{i_{t},j_{t}}=r_{i_{t},j_{t}}(1-\frac{1}{2N_{e_t}})$, with $r_{i_{t},j_{t}}$ }\DIFdelend \DIFaddbegin \DIFadd{$z_{{t},ij}=(1-r_{{t},ij})(1-\frac{1}{2N_{e_t}})$ and  $\zeta_{{t},ij}=r_{{t},ij}(1-\frac{1}{2N_{e_t}})$, with $r_{{t},ij}$ }\DIFaddend being the recombination rate between locus $i$ and $j$ in generation $t$, and $N_{e_t}$ the effective population size in generation $t$. \DIFdelbegin \DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{In the absence of selection, the }\DIFaddend stochastic terms, \DIFdelbegin \DIFdel{$e^{'}_{i_{t+1},j_{t+1}}$}\DIFdelend \DIFaddbegin \DIFadd{$e^{'}_{{t+1},ij}$}\DIFaddend , have zero mean and are uncorrelated over time, with variances given by \citet[][Eq 25, although those variances must be divided by 4 here since we are working with the frequency of alleles in individuals rather than gametes]{Ohta.1969}. The covariances between, for example, \DIFdelbegin \DIFdel{$e^{'}_{i_{t+1},j_{t+1}}$ and $e^{'}_{k_{t+1},l_{t+1}}$ }\DIFdelend \DIFaddbegin \DIFadd{$e^{'}_{{t+1},ij}$ and $e^{'}_{{t+1},kl}$ }\DIFaddend are not given in \citet{Ohta.1969}, and may be unknown. \DIFdelbegin \DIFdel{As a consequence,
}\DIFdelend \DIFaddbegin \DIFadd{Using the above results we can derive a recursion for $L^{'}$ at some arbitrary time $t$:
}\DIFaddend 

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < L^{'}_{i_{1},j_{1}} =& z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}}\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{2},j_{2}} =& z_{i_{1},j_{1}}(z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}})+\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+e^{'}_{i_{2},j_{2}}\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{3},j_{3}} =& 
%DIFDELCMD < z_{i_{2},j_{2}}(z_{i_{1},j_{1}}(z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}})+\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+e^{'}_{i_{2},j_{2}})\\
%DIFDELCMD < &+\zeta_{i_{2},j_{2}}L^{''}_{i_{2},j_{2}}+e^{'}_{i_{3},j_{3}}\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{3},j_{3}} =&z_{i_{2},j_{2}}z_{i_{1},j_{1}}z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+z_{i_{2},j_{2}}z_{i_{1},j_{1}}\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+z_{i_{2},j_{2}}z_{i_{1},j_{1}}e_{i_{1},j_{1}}^{'}\\
%DIFDELCMD < &+z_{i_{2},j_{2}}\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+z_{i_{2},j_{2}}e_{i_{2},j_{2}}^{'}+\zeta_{i_{2},j_{2}}L^{''}_{i_{2},j_{2}}+e_{i_{3},j_{3}}^{'}\\
%DIFDELCMD < \\
%DIFDELCMD < \cdots \hspace{0.3cm}= &\cdots\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\sum_{k=0}^{t-1}\zeta_{i_{k},j_{k}}L^{''}_{i_{k},j_{k}}\prod_{u=k+1}^{t-1}z_{i_{u},j_{u}}\\
%DIFDELCMD < &+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\
%DIFDELCMD < 

%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}\prod_{k=1}^{t-1}z_{i_{k},j_{k}}\\
%DIFDELCMD < &+\sum_{k=1}^{t-1}\zeta_{i_{k},j_{k}}L^{''}_{i_{k},j_{k}}\prod_{u=k+1}^{t-1}z_{i_{u},j_{u}}+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\frac{\zeta_{i_{0},j_{0}}}{z_{i_{0},j_{0}}}L^{''}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\sum_{k=1}^{t-1}\frac{\zeta_{i_{k},j_{k}}}{z_{i_{k},j_{k}}}L^{''}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}\\
%DIFDELCMD < &+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\
%DIFDELCMD < \\
%DIFDELCMD < L^{'}_{i_{t},j_{t}} =&\left(L^{'}_{i_{0},j_{0}}+\frac{\zeta_{i_{0},j_{0}}}{z_{i_{0},j_{0}}}L^{''}_{i_{0},j_{0}}\right)\prod_{k=0}^{t-1}z_{i_{k},j_{k}}\\
%DIFDELCMD < &+\sum_{k=1}^{t-1}\left(e^{'}_{i_{k},j_{k}}+\frac{\zeta_{i_{k},j_{k}}}{z_{i_{k},j_{k}}}L^{''}_{i_{k},j_{k}}\right) \prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
L^{'}_{{1},ij} =& z_{{0},ij}L^{'}_{{0},ij}+\zeta_{{0},ij}L^{''}_{{0},ij}+e^{'}_{{1},ij}\\
\\
L^{'}_{{2},ij} =& z_{{1},ij}(z_{{0},ij}L^{'}_{{0},ij}+\zeta_{{0},ij}L^{''}_{{0},ij}+e^{'}_{{1},ij})+\zeta_{{1},ij}L^{''}_{{1},ij}+e^{'}_{{2},ij}\\
\\
L^{'}_{{3},ij} =& 
z_{{2},ij}(z_{{1},ij}(z_{{0},ij}L^{'}_{{0},ij}+\zeta_{{0},ij}L^{''}_{{0},ij}+e^{'}_{{1},ij})+\zeta_{{1},ij}L^{''}_{{1},ij}+e^{'}_{{2},ij})\\
&+\zeta_{{2},ij}L^{''}_{{2},ij}+e^{'}_{{3},ij}\\
\\
L^{'}_{{3},ij} =&z_{{2},ij}z_{{1},ij}z_{{0},ij}L^{'}_{{0},ij}+z_{{2},ij}z_{{1},ij}\zeta_{{0},ij}L^{''}_{{0},ij}+z_{{2},ij}z_{{1},ij}e_{{1},ij}^{'}\\
&+z_{{2},ij}\zeta_{{1},ij}L^{''}_{{1},ij}+z_{{2},ij}e_{{2},ij}^{'}+\zeta_{{2},ij}L^{''}_{{2},ij}+e_{{3},ij}^{'}\\
\\
\cdots \hspace{0.3cm}= &\cdots\\
\\
L^{'}_{{t},ij} =&L^{'}_{{0},ij}\prod_{k=0}^{t-1}z_{{k},ij}+\sum_{k=0}^{t-1}\zeta_{{k},ij}L^{''}_{{k},ij}\prod_{u=k+1}^{t-1}z_{{u},ij}\\
&+\sum_{k=1}^{t-1}e^{'}_{{k},ij}\prod_{u=k}^{t-1}z_{{u},ij}+e^{'}_{{t},ij}\\

\\
L^{'}_{{t},ij} =&L^{'}_{{0},ij}\prod_{k=0}^{t-1}z_{{k},ij}+\zeta_{{0},ij}L^{''}_{{0},ij}\prod_{k=1}^{t-1}z_{{k},ij}\\
&+\sum_{k=1}^{t-1}\zeta_{{k},ij}L^{''}_{{k},ij}\prod_{u=k+1}^{t-1}z_{{u},ij}+\sum_{k=1}^{t-1}e^{'}_{{k},ij}\prod_{u=k}^{t-1}z_{{u},ij}+e^{'}_{{t},ij}\\
\\
L^{'}_{{t},ij} =&L^{'}_{{0},ij}\prod_{k=0}^{t-1}z_{{k},ij}+\frac{\zeta_{{0},ij}}{z_{{0},ij}}L^{''}_{{0},ij}\prod_{k=0}^{t-1}z_{{k},ij}+\sum_{k=1}^{t-1}\frac{\zeta_{{k},ij}}{z_{{k},ij}}L^{''}_{{k},ij}\prod_{u=k}^{t-1}z_{{u},ij}\\
&+\sum_{k=1}^{t-1}e^{'}_{{k},ij}\prod_{u=k}^{t-1}z_{{u},ij}+e^{'}_{{t},ij}\\
\\
L^{'}_{{t},ij} =&\left(L^{'}_{{0},ij}+\frac{\zeta_{{0},ij}}{z_{{0},ij}}L^{''}_{{0},ij}\right)\prod_{k=0}^{t-1}z_{{k},ij}\\
&+\sum_{k=1}^{t-1}\left(e^{'}_{{k},ij}+\frac{\zeta_{{k},ij}}{z_{{k},ij}}L^{''}_{{k},ij}\right) \prod_{u=k}^{t-1}z_{{u},ij}+e^{'}_{{t},ij}
\end{array}\DIFaddend 
\label{eq:LD1}
\end{equation}
\\
 Having the matrix ${\bf N}_t$ with the $ij^{th}$ element \DIFdelbegin \DIFdel{being the relevant $\prod_{k=0}^{t-1}z_k$}\DIFdelend \DIFaddbegin \DIFadd{$\prod_{k=0}^{t-1}z_{k, ij}$}\DIFaddend , we have for $t>0$

\begin{equation}
{\bf L}_{t}= {\bf N}_t\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_t+{\bf L}^{''}_t
\label{eq:LD3}
\end{equation}

where $\circ$ is the Hadamard product. The first term is the expected ${\bf L}$ (and ${\bf L}^{'}$) in generation $t$, conditional on the genotypic composition of the population in generation 0, where $\tilde{\bf L}_{0}$ is the sum of ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$ with the elements of the latter weighted by \DIFdelbegin \DIFdel{$\zeta_{i_{0},j_{0}}/z_{i_{0},j_{0}}=r_{i_0,j_0}/(1-r_{i_0,j_0})$}\DIFdelend \DIFaddbegin \DIFadd{$\zeta_{{0},ij}/z_{{0},ij}=r_{0,ij}/(1-r_{0,ij})$}\DIFaddend . $\Delta {\bf L}^{'}_t$ is a matrix with elements equal to the sum of the stochastic terms involving $e$ in Equation \ref{eq:LD1} and represents stochastic changes in ${\bf L}^{'}$ from generation 0 to generation $t$. ${\bf L}^{''}_t$ are the new nongametic-phase disequilibria that arise in generation $t$. Note that if replicate populations are initiated from the offspring of Generation $0$, then the stochastic terms, $\Delta {\bf L}^{'}_t$ and ${\bf L}^{''}_t$, will be unique in each replicate although the deterministic part is shared. If recombination rates are constant in time \DIFdelbegin \DIFdel{$r_{i_t, j_t}=r_{i, j}$ then $\zeta_{i_{0},j_{0}}/z_{i_{0},j_{0}} = r_{i,j}/(1-r_{i,j})$ and $\prod_{k=0}^{t-1}z_{i_{k},j_{k}} =(1-r_{i,j})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_k}})$}\DIFdelend \DIFaddbegin \DIFadd{$r_{t, ij}=r_{i j}$ then $\zeta_{{0},ij}/z_{{0},ij} = r_{ij}/(1-r_{ij})$ and $\prod_{k=0}^{t-1}z_{{k},ij} =(1-r_{ij})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_k}})$}\DIFaddend . When population sizes are also constant then \DIFdelbegin \DIFdel{$\prod_{k=0}^{t-1}z_{i_{k},j_{k}} =(1-r_{i,j})^{t}(1-\frac{1}{2N_e})^t$}\DIFdelend \DIFaddbegin \DIFadd{$\prod_{k=0}^{t-1}z_{{k},ij} =(1-r_{ij})^{t}(1-\frac{1}{2N_e})^t$}\DIFaddend . 


\section{\DIFdelbegin \DIFdel{Appendix 2: Derivation for the }\DIFdelend \DIFaddbegin \DIFadd{The }\DIFaddend mean \DIFdelbegin \DIFdel{, within-replicate (co)variances, }\DIFdelend and \DIFdelbegin \DIFdel{between replicate }\DIFdelend (co)\DIFdelbegin \DIFdel{variances }\DIFdelend \DIFaddbegin \DIFadd{variance }\DIFaddend of allele frequency changes.}
%\addcontentsline{toc}{subsection}{Appendix 4: Derivation for the mean, within-replicate (co)variances and between replicate (co)variances allele frequency changes.}
\label{App:dist}

\DIFdelbegin \DIFdel{Both }\DIFdelend \DIFaddbegin \DIFadd{Given our model for the dynamics of ${\bf L}$ (See Supplementary information \ref{Appendix:LD}) we can derive the mean and (co)variance of the allele-frequency changes within a replicate. Here expectations and variances are taken with respect to the evolutionary process, which not only includes the effects of drift (}\DIFaddend $\underset{D}\Delta {\bf p}$\DIFaddbegin \DIFadd{) but also stochastic changes in  ${\bf L}$ }\DIFaddend and \DIFdelbegin \DIFdel{$\underset{U}\Delta {\bf p}$ have expectation zero such that the conditional mean }\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\alpha}$. The change in allele frequency in replicate $m$ }\DIFaddend is

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < E\left[\Delta {\bf p}_m\right] =& \sum_{t=t_m}^{\tau_m-1}E\left[({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}\right]\\
%DIFDELCMD < =& \left(\sum_{t=t_m}^{\tau_m-1}({\bf N}_{t,m}\circ\tilde{\bf L}_0)\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\
%DIFDELCMD < 

%DIFDELCMD < =& \left(\tilde{\bf L}_0\circ\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\
%DIFDELCMD < =& \left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\Delta {\bf p}_m
=&\sum_{t=t_m}^{\tau_m-1} \left({\bf L}_t{\boldsymbol{\alpha}}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
=& \sum_{t=t_m}^{\tau_m-1} \left(({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}+\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+({\bf N}_{t,m}\circ\tilde{\bf L}_0)\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
\end{array}\DIFaddend 
\end{equation}

where \DIFdelbegin \DIFdel{${\bf N}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}$ which is null if $t_m=0$ and $\tau_m=1$. Under the same assumptions }\DIFdelend \DIFaddbegin \DIFadd{$\Delta{\bf L}_{t,m} =\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}$}\DIFaddend , \DIFdelbegin \DIFdel{the conditional between-replicate covariance has a similar form 
}\DIFdelend \DIFaddbegin \DIFadd{$\bar{\boldsymbol{\alpha}}$ is a vector of mean average effects and $\Delta\boldsymbol{\alpha}_{t,m}$ a vector of deviations specific to time $t$ and replicate $m$. By definition, drift is non-directional and so $E\left[ \underset{D}\Delta {\bf p}_{t, m}\right]={\bf 0}$. We also assume that the unpredictable response to selection has zero expectation which requires that deviations in ${\bf L}$ and $\boldsymbol{\alpha}$ from their predicted means are zero on average ($E[\Delta{\bf L}]={\bf 0}$ and $E[\Delta\boldsymbol{\alpha}]={\bf 0}$) and there is no correlation between them ($COV(\Delta{\bf L}, \Delta\boldsymbol{\alpha})=0$). Under the infinitesimal model these assumptions should hold approximately since changes in the diagonal elements of ${\bf L}$ are not driven by selection \mbox{%DIFAUXCMD
\citep{Barton.2017} }\hskip0pt%DIFAUXCMD
and changes in the off-diagonal change only slowly with selection \mbox{%DIFAUXCMD
\citep{Bulmer.1971}}\hskip0pt%DIFAUXCMD
. Similarly, since the expected change in ${\bf L}$ is slow, the induced change in $\boldsymbol{\alpha}$ in the presence of non-additive gene action should be minor. Making these assumptions we have:
}\DIFaddend 

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})
%DIFDELCMD < =&\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)VAR(\bar{\boldsymbol{\alpha}})\left(\tilde{\bf L}_0\circ{\bf N}^{(n)}\right)\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
E\left[\Delta {\bf p}_m\right] =& \sum_{t=t_m}^{\tau_m-1}({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}\\
=& \left(\tilde{\bf L}_0\circ\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}\right)\bar{\boldsymbol{\alpha}}\\
=& \left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)\bar{\boldsymbol{\alpha}}\\
=& \boldsymbol{\mathcal L}_m\bar{\boldsymbol{\alpha}}\\
\end{array}\DIFaddend 
\end{equation}

where \DIFdelbegin \DIFdel{$m$ and $n$ are a pair of replicates}\DIFdelend \DIFaddbegin \DIFadd{${\bf N}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}$ and $\boldsymbol{\mathcal L}_m=\tilde{\bf L}_0\circ{\bf N}^{(m)}$}\DIFaddend .  The within-replicate (co)variances are more challenging to derive\DIFdelbegin \DIFdel{as they not only include the predictable response to selection, but also the effects of drift and the unpredictable response to selection . In what follows, we assume $E\left[\Delta\boldsymbol{\alpha}\right]=0$ and $COV(\Delta{\bf L}^{'}+{\bf L}^{''}, \bar{\boldsymbol{\alpha}})=0$ such that the predictable and unpredictable response to selection are independent. In addition, we will assume $COV(\Delta{\bf L}^{'}+{\bf L}^{''}, \Delta\boldsymbol{\alpha})=0$ and that all $\Delta\boldsymbol{\alpha}$ are independent of each other. Since }\DIFdelend \DIFaddbegin \DIFadd{. The variance due to the unpredictable selection at time $t$ in replicate $m$ is 
}

\begin{tiny}
\begin{equation}
\DIFadd{\begin{array}{rl}
VAR\left(\underset{U}\Delta {\bf p}_{t, m}\right)=&VAR\left((\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m})\Delta\boldsymbol{\alpha}_{t, m}\right)\\
&VAR(\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}\bar{\boldsymbol{\alpha}}^{\top}+\boldsymbol{\mathcal L}_{t,m}VAR(\Delta\boldsymbol{\alpha}_{t,m})\boldsymbol{\mathcal L}_{t,m}+VAR(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m})VAR(\Delta\boldsymbol{\alpha}_{t, m})\\
\end{array}
}\end{equation}
\end{tiny}

\DIFadd{In addition, covariances between the unpredictable response at different time points within a replicate will be non-zero because }\DIFaddend $\Delta {\bf L}^{'}_t$ is the sum of stochastic changes from generation $1$ to $t$ \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{and so }\DIFaddend $COV(\Delta {\bf L}^{'}_{t_1, m}, \Delta {\bf L}^{'}_{t_2, m})=VAR(\Delta {\bf L}^{'}_{t_1, m})$ when $t_1\leq t_2$\DIFdelbegin \DIFdel{. Note }\DIFdelend \DIFaddbegin \DIFadd{, although }\DIFaddend $COV({\bf L}^{''}_{t_1, m}, {\bf L}^{''}_{t_2, m})=0$. \DIFdelbegin \DIFdel{These assumptions allow the simplification:
}\DIFdelend \DIFaddbegin \DIFadd{This gives
}\DIFaddend 


\begin{tiny}
\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& VAR\left(\sum_{t=t_m}^{\tau_m-1}\left(({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t, m}+\underset{D}\Delta {\bf p}_{t, m}\right)\right)\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& \sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left((({\bf N}_{t_1}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_1, m}+\underset{D}\Delta {\bf p}_{t_1, m}, (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_2, m}+\underset{D}\Delta {\bf p}_{t_2, m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)+\sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left((({\bf N}_{t_1}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_1, m},  (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_2, m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)+\left(\sum_{t_1=t_m}^{\tau_m-1} (({\bf N}_{t_1}\circ\tilde{\bf L}_0))\right)VAR(\bar{\boldsymbol{\alpha}})\left(\sum_{t_2=t_m}^{\tau_m-1} (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\right)\\
%DIFDELCMD < &+\sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left(\underset{U}\Delta {\bf p}_{t_1, m},\underset{U}\Delta {\bf p}_{t_2, m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)+\left(\sum_{t_1=t_m}^{\tau_m-1} (({\bf N}_{t_1}\circ\tilde{\bf L}_0))\right)VAR(\bar{\boldsymbol{\alpha}})\left(\sum_{t_2=t_m}^{\tau_m-1} (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\right)\\
%DIFDELCMD < &+\sum_{t=t_m}^{\tau_m-1}(2(\tau^m-t)+1)VAR\left(\underset{U}\Delta {\bf p}_{t,m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)+\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)VAR(\bar{\boldsymbol{\alpha}})\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)\\
%DIFDELCMD < &+\sum_{t=t_m}^{\tau_m-1}(2(\tau^m-t)+1)VAR\left(\underset{U}\Delta {\bf p}_{t,m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
COV\left(\underset{U}\Delta {\bf p}_{t_1, m}, \underset{U}\Delta {\bf p}_{t_2, m}\right)=
&VAR(\Delta{\bf L}^{'}_{t, m})\bar{\boldsymbol{\alpha}}\bar{\boldsymbol{\alpha}}^{\top}\\
\end{array}\DIFaddend 
\end{equation}
\end{tiny}

\DIFdelbegin \DIFdel{which requires an expressions for $VAR\left(\underset{U}\Delta {\bf p}_{t, m}\right)$ and $VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)$. The variance due to unpredictable selection is:
}\DIFdelend \DIFaddbegin \DIFadd{when $t_1\leq t_2$. Consequently, the total variance in the unpredictable response to selection will be
}\DIFaddend 

\begin{tiny}
\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < VAR\left(\underset{U}\Delta {\bf p}_{t, m}\right)=&VAR\left((\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}+(({\bf N}_{t, m}\circ\tilde{\bf L}_0))\Delta\boldsymbol{\alpha}_{t,m}+(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m})\Delta\boldsymbol{\alpha}_{t, m}\right)\\
%DIFDELCMD < =&VAR\left(
%DIFDELCMD < (\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}\right)+VAR\left((({\bf N}_{t, m}\circ\tilde{\bf L}_0)\Delta\boldsymbol{\alpha}_{t,m}\right)+VAR\left((\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\Delta\boldsymbol{\alpha}_{t,m}\right)\\
%DIFDELCMD < 

%DIFDELCMD < =&VAR\left(
%DIFDELCMD < \Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}\right)VAR\left(\bar{\boldsymbol{\alpha}}\right)\\
%DIFDELCMD < &+(({\bf N}_{t, m}\circ\tilde{\bf L}_0)VAR\left(\Delta\boldsymbol{\alpha}_{t,m}\right)(({\bf N}_{t, m}\circ\tilde{\bf L}_0)VAR\left(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}\right)VAR\left(\Delta\boldsymbol{\alpha}_{t,m}\right)\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
VAR\left(\underset{U}\Delta {\bf p}_{m}\right)=
&\sum_{t=t_m}^{\tau_m-1}(2(\tau_m-t)+1)VAR(\Delta{\bf L}^{'}_{t, m})\bar{\boldsymbol{\alpha}}\bar{\boldsymbol{\alpha}}^{\top}\\
&+\sum_{t=t_m}^{\tau_m-1}\left(VAR({\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}\bar{\boldsymbol{\alpha}}^{\top}+\boldsymbol{\mathcal L}_{t,m}VAR(\Delta\boldsymbol{\alpha}_{t,m})\boldsymbol{\mathcal L}_{t,m}+VAR(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m})VAR(\Delta\boldsymbol{\alpha}_{t, m})\right)\\
\end{array}\DIFaddend 
\end{equation}
\end{tiny}

and cannot be simplified \DIFaddbegin \DIFadd{- we simply refer to it as $\boldsymbol{\mathcal{U}}_m$}\DIFaddend .\\

For the drift \DIFdelbegin \DIFdel{covariances}\DIFdelend \DIFaddbegin \DIFadd{(co)variances}\DIFaddend , note that under random mating, haplotypes are drawn from a multinomial with $2N$ trials. Using AB, Ab, AB and aB to denote the \emph{number} of each haplotypes in the gamete pool, the number of $mn$ haplotypes has variance $2Np_{mn}(1-p_{mn})$ and the covariance in the numbers of $mn$ and $op$ haplotypes is $-2Np_{mn}p_{op}$ where $p_{mn}$ is the frequency of the $mn$ halpotype in the gamete pool (i.e the parental haplotype frequencies modified by recombination). The covariance in the number of A and B alleles sampled, is therefore 


\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < COV(AB+Ab, AB+aB) =& COV(AB, AB)+COV(AB, aB)\\
%DIFDELCMD < &+COV(Ab, AB)+COV(Ab, aB)\\
%DIFDELCMD < =& 2N\left[p_{AB}(1-p_{AB})-p_{AB}p_{aB}-p_{Ab}p_{AB}-p_{Ab}p_{aB}\right]\\
%DIFDELCMD < =& 2N\left[p_{AB}(1-p_{AB}-p_{aB})-p_{Ab}(p_{AB}+p_{aB})\right]\\
%DIFDELCMD < =& 2N\left[p_{AB}(1-p_{B})-p_{Ab}p_{B}\right]\\
%DIFDELCMD < =& 2N\left[p_{AB}-(p_{Ab}+p_{AB})p_{B}\right]\\
%DIFDELCMD < =& 2N\left[p_{AB}-p_{A}p_{B}\right]\\
%DIFDELCMD < =& 4N\bar{L}^{'}_{i,j}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
COV(AB+Ab, AB+aB) =& COV(AB, AB)+COV(AB, aB)\\
&+COV(Ab, AB)+COV(Ab, aB)\\
=& 2N\left[p_{AB}(1-p_{AB})-p_{AB}p_{aB}-p_{Ab}p_{AB}-p_{Ab}p_{aB}\right]\\
=& 2N\left[p_{AB}(1-p_{AB}-p_{aB})-p_{Ab}(p_{AB}+p_{aB})\right]\\
=& 2N\left[p_{AB}(1-p_{B})-p_{Ab}p_{B}\right]\\
=& 2N\left[p_{AB}-(p_{Ab}+p_{AB})p_{B}\right]\\
=& 2N\left[p_{AB}-p_{A}p_{B}\right]\\
=& 4N\bar{L}^{'}_{ij}\\
\end{array}\DIFaddend 
\end{equation}

where \DIFdelbegin \DIFdel{$\bar{L}^{'}_{i,j}$ }\DIFdelend \DIFaddbegin \DIFadd{$\bar{L}^{'}_{ij}$ }\DIFaddend is the gametic-phase linkage disequilibria that would be achieved in an infinite population. We can divide through by $(1/2N)^2$ to obtain the drift covariance in frequency (rather than counts) as \DIFdelbegin \DIFdel{$\bar{L}^{'}_{i,j}/N$ }\DIFdelend \DIFaddbegin \DIFadd{$\bar{L}^{'}_{ij}/N$ }\DIFaddend (i.e the drift (co)variances in a allele frequency from generation $t$ to $t+1$ are proportional to the gametic-phase disequilibria in generation $t+1$ that would be achieved in an infinite population conditional on the genotypic composition of the population in generation $t$). This recovers the well known result for the drift variance in allele frequency: \DIFdelbegin \DIFdel{$\bar{L}^{'}_{i,i}/N = p_i(1-p_i)/2N$}\DIFdelend \DIFaddbegin \DIFadd{$\bar{L}^{'}_{ii}/N = p_i(1-p_i)/2N$}\DIFaddend . We can replace the census population size, $N$, with the effective population size $N_E$, since this approximates the sampling of genotypes in non-idealised populations well \citep{ethier1980diffusion}. However, note that $N_E$ differs from $N_e$ in that it does include the impact of linked selection since this is conditioned on in the expectation, \DIFdelbegin \DIFdel{$E[{\bf p}]$}\DIFdelend \DIFaddbegin \DIFadd{$E[\Delta{\bf p}]$}\DIFaddend . In matrix terms (since \DIFdelbegin \DIFdel{$\bar{L}^{'}_{i_{t+1},j_{t+1}}=L^{'}_{i_t,j_t}r_{i,j}+L^{''}_{i_t,j}(1-r_{i,j})$}\DIFdelend \DIFaddbegin \DIFadd{$\bar{L}^{'}_{{t+1},ij}=L^{'}_{t,ij}r_{ij}+L^{''}_{t,ij}(1-r_{ij})$}\DIFaddend ):

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}} \bar{\bf L}^{'}_{t+1,m}\\
%DIFDELCMD < VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[{\bf R}_{-}\circ{\bf L}^{'}_{t,m}+{\bf R}_{+}\circ{\bf L}^{''}_{t, m}\right]\\
%DIFDELCMD < 

%DIFDELCMD < VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[\left({\bf R}_{-}\circ\left({\bf N}_{t, m}\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_{t, m}\right)+{\bf R}_{+}\circ{\bf L}^{''}_{t, m}\right) \right]\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}} \bar{\bf L}^{'}_{t+1,m}\\
VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[{\bf R}_{-}\circ{\bf L}^{'}_{t,m}+{\bf R}_{+}\circ{\bf L}^{''}_{t, m}\right]\\

VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[{\bf R}_{-}\circ\left({\bf N}_{t, m}\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_{t, m}\right)+{\bf R}_{+}\circ{\bf L}^{''}_{t, m} \right]\\
VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[{\bf R}_{-}\circ{\bf N}_{t, m}\circ\tilde{\bf L}_{0}+{\bf R}_{-}\circ\Delta {\bf L}^{'}_{t, m}+{\bf R}_{+}\circ{\bf L}^{''}_{t, m} \right]\\
\label{eq:drift_var}
\end{array}\DIFaddend 
\end{equation}

where ${\bf R}_{+}$ and ${\bf R}_{\_}$ are matrices with the $ij_{th}$ \DIFdelbegin \DIFdel{being $r_{i,j}$ and $1-r_{i,j}$ }\DIFdelend \DIFaddbegin \DIFadd{elements being $r_{ij}$ and $1-r_{ij}$ }\DIFaddend respectively. The expected drift terms (\DIFdelbegin \DIFdel{conditional on ${\bf L}_0$) are }\DIFdelend \DIFaddbegin \DIFadd{averaged over the evolutionary stochasticity in ${\bf L}$) is }\DIFaddend therefore:

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right] =& \frac{1}{N_{E_{t,m}}}\left({\bf R}_{-}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\right)\\
\end{array}
\end{equation}

We define a new matrix ${\bf M}_{t,m}$ with the $ij^{th}$ element being \DIFdelbegin \DIFdel{$(1-r_{i,j})/N_{E_{t,m}}$ }\DIFdelend \DIFaddbegin \DIFadd{$(1-r_{ij})/N_{E_{t,m}}$ }\DIFaddend (${\bf M}_{t,m}=\frac{1}{N_{E_{t,m}}}{\bf R}_{-}$) to give

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right] 
=& {\bf M}_{t,m}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\\
\end{array}
\end{equation}


Since the drift terms are independent, this gives:

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{m}\right)\right]=&\sum_{t=t_m}^{\tau_m-1}E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right]\\
=& \sum_{t=t_m}^{\tau_m-1}\frac{1}{N_{E_{t,m}}}\left({\bf R}_{-}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\right)\\\\
=& \tilde{\bf L}_{0}\circ\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}\\
=& \tilde{\bf L}_{0}\circ{\bf M}^{(m)}\\
\end{array}
\end{equation}

where ${\bf M}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}$ and is null when $t_m=0$ and $\tau_m=1$.  Note the $ij^{th}$ element of \DIFdelbegin \DIFdel{${\bf M}_{t,m}\circ{\bf N}_{t,m}=(1-r_{i,j})^{t+1}\frac{1}{N_{E_t}}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$ }\DIFdelend \DIFaddbegin \DIFadd{${\bf M}_{t,m}\circ{\bf N}_{t,m}=(1-r_{ij})^{t+1}\frac{1}{N_{E_t}}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$ }\DIFaddend which reduces to \DIFdelbegin \DIFdel{$(1-r_{i,j})^{t+1}\frac{1}{N_{e_m}}(1-\frac{1}{2N_{e_m}})^{t}$ }\DIFdelend \DIFaddbegin \DIFadd{$(1-r_{ij})^{t+1}\frac{1}{N_{e_m}}(1-\frac{1}{2N_{e_m}})^{t}$ }\DIFaddend with constant population size and $N_e=N_E$. \DIFaddbegin \DIFadd{$\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ is denoted as $\boldsymbol{\mathcal{D}}_m$ in the main text. }\DIFaddend It is not clear how large the evolutionary variance in $VAR\left(\underset{D}\Delta {\bf p}_{m}\right)$ is, and whether this would need to be accommodated.\DIFaddbegin \\
\DIFaddend 

\DIFdelbegin \section{\DIFdel{Appendix 3: Treating $\boldsymbol{\alpha}$ as random}}
%DIFAUXCMD
\addtocounter{section}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{When the vector of average effects, ${\boldsymbol \alpha}$, is constant in time and across replicates, $V_A(0) = {\boldsymbol \alpha}{\bf L}_0{\boldsymbol \alpha}^{\top} = \bar{\boldsymbol \alpha}{\bf L}_0\bar{\boldsymbol \alpha}^{\top}$. However, when they do vary, this equality does not hold and so we use the notation $V_{\bar A}(0)$ to distinguish $\bar{\boldsymbol \alpha}{\bf L}_0\bar{\boldsymbol \alpha}^{\top}$ from $V_A(0)$. We claim that $V_{\bar A}(0)$ can be interpreted as the genetic covariance in fitness between time-replicate combinations for a population with a genotypic composition identical to the base population: it is the expected covariance in breeding value of an individual taken from the base population and (hypothetically) raised in two different replicates at two different times.
}

\DIFadd{To see this, we switch from our original definition of ${\boldsymbol \alpha}_{t,m}$ as being equal to $\bar{\boldsymbol \alpha}+\Delta{\boldsymbol \alpha}_{t,m}$ and with some abuse of notation use the form $\bar{\boldsymbol \alpha}+\Delta{\boldsymbol \alpha}_t+\Delta{\boldsymbol \alpha}_m+\Delta{\boldsymbol \alpha}_{t,m}$ where $\Delta{\boldsymbol \alpha}_t$ is the deviation of the average effects (averaged over replicates) at time $t$ and $\Delta{\boldsymbol \alpha}_m$ is the deviation of the average effects (averaged over time) in replicate $m$, leaving $\Delta{\boldsymbol \alpha}_{t,m}$ as the `residual' deviation in ${\boldsymbol \alpha}$. By definition, the terms
 $\Delta{\boldsymbol \alpha}_t$, $\Delta{\boldsymbol \alpha}_m$ and $\Delta{\boldsymbol \alpha}_{t,m}$ have expectation zero, where the expectations are taken over time, replicates and all time-replicate combinations respectively. $C_{\alpha_{t_m}, \alpha_{\tau_n}}={\boldsymbol \alpha}^{\top}_{t,m}{\bf L}_0{\boldsymbol \alpha}_{\tau,n}$ is the additive genetic covariance between replicate $m$ at time $t$ and replicate $n$ at time $\tau$ given the base population structure.
}


 \begin{equation}
\DIFadd{C_{\alpha_{t_m}, \alpha_{\tau_n}} = \left(\bar{\boldsymbol \alpha}^{\top}+\Delta{\boldsymbol \alpha}_t^{\top}+\Delta{\boldsymbol \alpha}_m^{\top}+\Delta{\boldsymbol \alpha}_{t,m}^{\top}\right)}{\DIFadd{\bf L}}\DIFadd{_0\left(\bar{\boldsymbol \alpha}+\Delta{\boldsymbol \alpha}_\tau+\Delta{\boldsymbol \alpha}_n+\Delta{\boldsymbol \alpha}_{\tau,n}\right)
 }\end{equation}

\DIFadd{If we take the expectation of this over pairs of replicates we get:
}

\begin{equation}
\DIFadd{C_{\alpha_t, \alpha_\tau} = \left(\bar{\boldsymbol \alpha}^{\top}+\Delta{\boldsymbol \alpha}_t^{\top}\right)}{\DIFadd{\bf L}}\DIFadd{_0\left(\bar{\boldsymbol \alpha}+\Delta{\boldsymbol \alpha}_\tau\right)
}\end{equation}

\DIFadd{since the $\Delta$ terms, and the product of pairs of $\Delta$ terms when $n\neq m$, have zero expectation. Here, $C_{\alpha_t, \alpha_\tau}$ is the between-replicate covariance at time $t$ and $\tau$, and has expectation (with respect to time) $\bar{\boldsymbol \alpha}^{\top}{\bf L}_0\bar{\boldsymbol \alpha}$ when $t\neq\tau$ and $\bar{\boldsymbol \alpha}^{\top}{\bf L}_0\bar{\boldsymbol \alpha}+Tr({\bf L}_0VAR(\Delta{\boldsymbol \alpha}_t))$ when $t=\tau$ where $VAR(\Delta{\boldsymbol \alpha}_t)$ are the (co)variances of $\boldsymbol{\alpha}$ over time.
}




\section{\DIFadd{Treating $\boldsymbol{\alpha}$ as random}}
\DIFaddend \label{App:alpha_random}

%DIF < \addcontentsline{toc}{subsection}{Appendix 1: Treating $\boldsymbol{\alpha}$ as random}
\DIFaddbegin \DIFadd{In standard quantitative genetic theory, $\boldsymbol{\alpha}$ is considered fixed and the genotypes of individuals in the population are considered random, leading to a distribution of breeding values with variance $V_A$. More recently, however, dense molecular markers have been used as covariates for predicting genetic values, and the associated coefficients have been treated as random \mbox{%DIFAUXCMD
\citep{meuwissen2001prediction}}\hskip0pt%DIFAUXCMD
. As noted by \mbox{%DIFAUXCMD
\citet{gianola2009additive}}\hskip0pt%DIFAUXCMD
, this raises interpretational problems when trying to relate the variance parameters associated with the coefficients to the concept of $V_A$.}\\ 
\DIFaddend 

\DIFdelbegin \DIFdel{Before we consider }\DIFdelend \DIFaddbegin \DIFadd{In our inference section we show that
}

\begin{equation}
\DIFadd{\begin{array}{rl}
E[V_A(0)] &= E[\boldsymbol{\alpha}^{\top}\textbf{L}_0{\boldsymbol{\alpha}}]\\
&= Tr(\textbf{L}_0{\bf V}_{\alpha}) + \boldsymbol{\mu}_{{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{{\alpha}}\\
\end{array}
}\end{equation}

\DIFadd{where here we assume the average effects are constant across time/replicates for ease and $\boldsymbol{\mu}_{{\alpha}}$ and ${\bf V}_{{\alpha}}$ are the mean vector and covariance matrix for the average effects (see the Appendix in \mbox{%DIFAUXCMD
\citet{gianola2009additive} }\hskip0pt%DIFAUXCMD
also). Critically, we interpret this expectation as an average over the epistemic uncertainty in  }\DIFaddend $\boldsymbol{\alpha}$\DIFdelbegin \DIFdel{as random rather than fixed , }\DIFdelend \DIFaddbegin \DIFadd{: it is a posterior mean after marginalising the distribution of $\boldsymbol{\alpha}$ (but conditioning on $\boldsymbol{\mu}_{\alpha}$ and ${\bf V}_{\alpha}$):
}

\begin{equation}
\DIFadd{E}[\DIFadd{V_{A}(0) | \boldsymbol{\mu}_{{\alpha}}, \textbf{V}_{{\alpha}}, }{\DIFadd{\bf L}}\DIFadd{_0}]\DIFadd{\propto \int_{{\boldsymbol{\alpha}}} }{\DIFadd{\boldsymbol{\alpha}}}\DIFadd{^{\top}{\bf L}_0{\boldsymbol{\alpha}}\cdot|}{\DIFadd{\bf J}}\DIFadd{| \cdot Pr(}{\DIFadd{\boldsymbol{\alpha}}} \DIFadd{|\boldsymbol{\mu}_{{\alpha}}, \textbf{V}_{{\alpha}}, }{\DIFadd{\bf L}}\DIFadd{_0)d}{\DIFadd{\boldsymbol{\alpha}}}
\DIFadd{}\end{equation}

\DIFadd{where ${\bf J}$ is the Jacobian of the transform from $\boldsymbol{\alpha}$ to $V_A$ and depends on ${\bf L}_0$.}\\ 

\DIFadd{For an inferential method we see no contradiction between treating $\boldsymbol{\alpha}$ as fixed when }\emph{\DIFadd{defining}} \DIFadd{$V_A$ but treating it as random when }\emph{\DIFadd{estimating}} \DIFadd{$V_A$. However, when treating $\bar{\boldsymbol{\alpha}}$ as random }\DIFaddend it is important to \DIFdelbegin \DIFdel{understand that quantities }\DIFdelend \DIFaddbegin \DIFadd{ensure that the underlying model is invariant with respect to which allele is chosen as the reference.  Quantities }\DIFaddend such as $V_A$ and genomic best linear unbiased predictors (gBLUP) are insensitive to which allele at a locus \DIFdelbegin \DIFdel{we consider }\DIFdelend \DIFaddbegin \DIFadd{is chosen as }\DIFaddend the reference allele and which allele we \DIFdelbegin \DIFdel{consider }\DIFdelend \DIFaddbegin \DIFadd{chosen as }\DIFaddend the alternate allele. To make this explicit, consider the diagonal `assignment' matrix ${\bf A}$ for which the diagonal elements are either 1 (the fittest allele is the reference allele) or -1 (the fittest allele is the alternate allele). Under a particular assignment, $\boldsymbol{\alpha}={\bf A}\boldsymbol{\alpha}_{+}$ and ${\bf L}={\bf A}{\bf L}_{+}{\bf A}$, where the subscript $+$ indicates the quantity had the fitter of the two alleles been the reference allele at all loci. If we consider $V_A$ conditional on a particular assignment we get (since ${\bf A}{\bf A}={\bf I}$):


\begin{equation}
\begin{array}{rl}
V_A =& \boldsymbol{\alpha}^{\top}{\bf L}\boldsymbol{\alpha}\\
    =& ({\bf A}\boldsymbol{\alpha}_{+})^{\top}{\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& \boldsymbol{\alpha}_{+}^{\top}{\bf A}{\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& \boldsymbol{\alpha}_{+}^{\top}{\bf L}_{+}\boldsymbol{\alpha}_{+}\\
\end{array}
\end{equation}
showing we get the same value of $V_A$ irrespective of the assignment we choose.  In contrast, quantities such as $E[{\bf L}\boldsymbol{\alpha}]$ are sensitive to the assignment, since they undergo a sign reversal under a different choice: 

\begin{equation}
\begin{array}{rl}
{\bf L}\boldsymbol{\alpha} =& {\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& {\bf A}{\bf L}_{+}\boldsymbol{\alpha}_{+}\\
\end{array}
\label{Eq:Lalpha}
\end{equation}

It is tempting to use the argument that $E[{\bf L}\boldsymbol{\alpha}]={\bf 0}$ when the reference allele is chosen at random, since $\alpha$ is equally likely to be positive as negative. The logic behind this argument can be expressed mathematically as $E[\boldsymbol{\alpha}]=E[{\bf A}]E[\boldsymbol{\alpha}_{+}]$ since the reference allele is chosen at random and so ${\bf A}$ must be independent of $\boldsymbol{\alpha}_{+}$. Under this same assumption $E[{\bf A}]={\bf 0}$, since any diagonal element has an equal chance of being -1 or 1, such that $E[{\bf L}\boldsymbol{\alpha}]=0$. However, this logic is incorrect. The argument envisages ${\bf A}$ as random, yet for any particular analysis ${\bf A}$ is no longer a random variable but fixed - a choice has been made as to which allele is the reference allele - even if there remains epistemic uncertainty as to whether the reference allele is the fitter of the two alleles.\\

 \DIFdelbegin \DIFdel{In our inference section we show that
}%DIFDELCMD < 

%DIFDELCMD < %%%
\begin{displaymath}
\DIFdel{\begin{array}{rl}
E_{\textbf{L}_0}({V_A}) &= E_{\textbf{L}_0}[\boldsymbol{\bar \alpha}^{\top}\textbf{L}_0\bar{\boldsymbol{\alpha}}]\\
&= Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}
}\end{displaymath}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{where $\boldsymbol{\mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}}$ are the mean vector and covariance matrix of the expected average effects. }\DIFdelend When the reference allele is chosen arbitrarily, any sensible distribution for \DIFdelbegin \DIFdel{the $\bar{\alpha}$'s }\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\alpha}$ }\DIFaddend must induce the same distribution on \DIFdelbegin \DIFdel{the $\bar{\alpha}_{+}$'s }\DIFdelend \DIFaddbegin \DIFadd{$\boldsymbol{\alpha}_{+}$ }\DIFaddend regardless of the assignment. If \DIFdelbegin \DIFdel{${\boldsymbol \mu}_{\bar{\alpha}_{+}}$ and ${\bf V}_{\bar{\alpha}_{+}}$ }\DIFdelend \DIFaddbegin \DIFadd{${\boldsymbol \mu}_{{\alpha}_{+}}$ and ${\bf V}_{{\alpha}_{+}}$ }\DIFaddend are the means and (co)variances of the \DIFdelbegin \DIFdel{expected }\DIFdelend average effects had all reference alleles been the fitter allele, then the distribution for a particular assignment becomes \DIFdelbegin \DIFdel{${\boldsymbol \mu}_{\bar{\alpha}}={\bf A}{\boldsymbol \mu}_{\bar{\alpha}_{+}}$ and ${\bf V}_{\bar{\alpha}} = {\bf A}{\bf V}_{\bar{\alpha}_{+}}{\bf A}$}\DIFdelend \DIFaddbegin \DIFadd{${\boldsymbol \mu}_{{\alpha}}={\bf A}{\boldsymbol \mu}_{{\alpha}_{+}}$ and ${\bf V}_{{\alpha}} = {\bf A}{\bf V}_{{\alpha}_{+}}{\bf A}$}\DIFaddend . Given ${\bf A}^{-1}={\bf A}$ this implies  \DIFdelbegin \DIFdel{${\boldsymbol \mu}_{\bar{\alpha}_{+}}={\bf A}{\boldsymbol \mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}_{+}}={\bf A}{\bf V}_{\bar{\alpha}}{\bf A}$}\DIFdelend \DIFaddbegin \DIFadd{${\boldsymbol \mu}_{{\alpha}_{+}}={\bf A}{\boldsymbol \mu}_{{\alpha}}$ and ${\bf V}_{{\alpha}_{+}}={\bf A}{\bf V}_{{\alpha}}{\bf A}$}\DIFaddend . For, ${\boldsymbol \mu}_{\alpha}$ this implies that suitable models should be (weighted) sums of differences between invariant properties of the alleles such that the difference reverses sign when the reference and alternate allele are switched. This might be their (log) frequency, such that the model is $\beta(p-q)$, with $\beta$ a parameter, or it might be the difference in derived vs ancestral coded as 1 vs -1, such that the model is $2\beta$ or $-2\beta$ depending on whether the reference allele is derived or ancestral, respectively. 

If ${\bf V}_{\bar{\alpha}}$ is assumed to be diagonal, all models are permissible since the square removes any sign. Since the multiplication of diagonal matrices is not affected by order we can see this directly:

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf V}_{\bar{\alpha}}{\bf A}\\
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf A}{\bf V}_{\bar{\alpha}}\\
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} =& {\bf V}_{\bar{\alpha}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
{\bf V}_{{\alpha}_{+}} =& {\bf A}{\bf V}_{{\alpha}}{\bf A}\\
{\bf V}_{{\alpha}_{+}} =& {\bf A}{\bf A}{\bf V}_{{\alpha}}\\
{\bf V}_{{\alpha}_{+}} =& {\bf V}_{{\alpha}}\\
\end{array}\DIFaddend 
\end{equation}

However, for non-diagonal matrices a suitable distribution must result in a sign reversal of all covariances at a locus when the reference and alternate alleles are switched. The most obvious way to achieve this is to allow \DIFdelbegin \DIFdel{${\bf V}_{\bar{\alpha}}$ }\DIFdelend \DIFaddbegin \DIFadd{${\bf V}_{{\alpha}}$ }\DIFaddend to be proportional to ${\bf L}^{p}$ since

\begin{equation}
\begin{array}{rl}
{\bf L}^{p}=&({\bf A}{\bf L}_{+}{\bf A})^{p}\\
         =&{\bf A}{\bf L}_{+}{\bf A}...{\bf A}{\bf L}_{+}{\bf A}\\
         =&{\bf A}{\bf L}_{+}^p{\bf A}\\
\end{array}
\end{equation}

where ${\bf L}_{+}$ is the linkage-disequilibrium matrix had the fittest allele been the reference allele at all loci. Under this assumption

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf V}_{\bar{\alpha}}{\bf A}\\
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} \propto& {\bf A}{\bf L}^{p}{\bf A}\\
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} \propto& {\bf A}{\bf A}{\bf L}_{+}^p{\bf A}{\bf A}\\
%DIFDELCMD < {\bf V}_{\bar{\alpha}_{+}} \propto&{\bf L}_{+}^p\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
{\bf V}_{{\alpha}_{+}} =& {\bf A}{\bf V}_{{\alpha}}{\bf A}\\
{\bf V}_{{\alpha}_{+}} \propto& {\bf A}{\bf L}^{p}{\bf A}\\
{\bf V}_{{\alpha}_{+}} \propto& {\bf A}{\bf A}{\bf L}_{+}^p{\bf A}{\bf A}\\
{\bf V}_{{\alpha}_{+}} \propto&{\bf L}_{+}^p\\
\end{array}\DIFaddend 
\end{equation}

A similar model was proposed by \citet{zeng2018signatures}, although there, ${\bf L}$ was treated as diagonal such that the variance of the average effects are assumed to be proportional to the genetic diversities to some power. 

\section{\DIFdelbegin \DIFdel{Appendix 4: }\DIFdelend Projection matrices}
\label{App:projection}

\DIFaddbegin \DIFadd{Rather than working with original allele frequencies, we project them into a new reduced subspace defined by ${\bf L}_0$ and claim that $V_A(0)$ does not depend on allele frequency changes outside of this space.  \mbox{%DIFAUXCMD
\citet{de2015genomic} }\hskip0pt%DIFAUXCMD
(in Supplementary Methods I) show that additive genetic variances are rotationally invariant: they are invariant to arbitrary linear transformations of the genotypes. Have ${\bf U}$ be }\emph{\DIFadd{all}} \DIFadd{eigenvectors of ${\bf L}_0$ and ${\bf D}$ a diagonal matrix with the eigenvalues of ${\bf L}_0$ square-rooted along the diagonal.  If we use the transformation ${\bf U}^{\top}$, \mbox{%DIFAUXCMD
\citet{de2015genomic} }\hskip0pt%DIFAUXCMD
show that the average effects in the projected space are ${\bf U}^{-\top}\boldsymbol{\alpha}$ and the covariance of the projected genotypes is ${\bf U}^{\top}{\bf L}_0{\bf U}$, and:
}

\begin{equation}
\DIFadd{V_A(0)=\boldsymbol{\alpha}^{\top}{\bf U}^{-\top}{\bf U}^{\top}{\bf L}_0{\bf U}{\bf U}^{-1}\boldsymbol{\alpha}=\boldsymbol{\alpha}^{\top}{\bf L}_0\boldsymbol{\alpha}
}\end{equation}

\DIFadd{Since ${\bf L}_0={\bf U}{\bf D}{\bf D}{\bf U}^{\top}$, 
}

\begin{equation}
\DIFadd{V_A(0)=\boldsymbol{\alpha}^{\top}{\bf U}^{-\top}{\bf U}^{\top}{\bf U}{\bf D}{\bf D}{\bf U}^{\top}{\bf U}{\bf U}^{-1}\boldsymbol{\alpha}
}\end{equation}

\DIFadd{which reduces to 
}

\begin{equation}
\DIFadd{V_A(0)=\boldsymbol{\alpha}^{\top}{\bf U}^{-\top}{\bf D}{\bf D}{\bf U}^{-1}\boldsymbol{\alpha}
}\end{equation}

\DIFadd{since eigenvectors are unitary ${\bf U}^{-1}={\bf U}^{\top}$ and so ${\bf U}{\bf U}^{\top}={\bf I}$. The maximum rank of ${\bf L}_0$ will generally be the number of individuals in the base population and will be substantially less then the number of loci. Consequently some diagonal elements of ${\bf D}$ will be zero which will set all elements in the corresponding column of ${\bf U}^{-\top}{\bf D}$ to zero. Consequently we can simply define the projection matrix ${\bf U}_{\bf L}$ with all columns associated with zero eigenvalues dropped without loss of information. 
}

\DIFaddend To show that our chosen projection (${\bf P} = {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$) results in identical and independently distributed residuals, we need to show that the drift covariance matrix is an identity matrix under this projection. \DIFdelbegin \DIFdel{First, we note that both ${\bf U}_{\bf L}$ and ${\bf U}_2$ are (semi-)unitary such that ${\bf U}{\bf U}^{\top}={\bf U}^{\top}{\bf U}={\bf I}$. Next we }\DIFdelend \DIFaddbegin \DIFadd{If we }\DIFaddend write down the eigendecomposition of ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L} = {\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}$, and use the unitary property of ${\bf U}_{\bf L}$ to note that $\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ can be expressed as ${\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$. The drift covariance matrix under the projection is then:

\begin{equation} 
\begin{array}{rl}
VAR(\underset{D}\Delta \overrightarrow{\bf p}_m) &= {\bf P}VAR(\underset{D}\Delta {\bf p}_m){\bf P}^{\top}\\
&= {\bf P}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf P}^{\top}\\
&= {\bf P}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf P}^{\top}\\
&= {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2^{-1}\\
&= {\bf I}\\
\end{array}
\end{equation}

\section{\DIFdelbegin \DIFdel{Appendix 5: }\DIFdelend Bias correction for $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$}
\label{App:bias_correction}

\DIFdelbegin \DIFdel{Using $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$ as an estimator of }\DIFdelend \DIFaddbegin \DIFadd{The expression for $E[V_{\bar A}(0)]$ involves a quadratic in the vector of expected average effects, $\boldsymbol{\mu}_{\bar{\alpha}}$: }\DIFaddend $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$\DIFdelbegin \DIFdel{results in upward bias}\DIFdelend \DIFaddbegin \DIFadd{. Replacing $\boldsymbol{\mu}_{\bar{\alpha}}$ with an estimate of it, $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$, will generally result in the estimate of $V_{\bar A}(0)$ being upwardly biased even if $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$ is an unbiased estimate of $\boldsymbol{\mu}_{\bar{\alpha}}$}\DIFaddend . To understand this, and correct for it, have \DIFaddbegin \DIFadd{the linear model
}

\begin{equation} 
\DIFadd{\boldsymbol{\mu}_{\bar{\alpha}} = }{\DIFadd{\bf X}}{\DIFadd{\boldsymbol \beta}}\DIFadd{_{\bar{\alpha}}
}\end{equation} 

\DIFadd{where ${\bf X}$ is the fixed-effect design matrix and ${\boldsymbol \beta}_{\bar{\alpha}}$ an associated parameter vector. In our analyses of simulated data, ${\bf X}$ only has one column, ${\bf p}_{0}-{\bf q}_{0}$, and ${\boldsymbol \beta}_{\bar{\alpha}}$ is a scalar: $\beta^{(1)}_{\bar{\alpha}}$. We can have
}

\DIFaddend \begin{equation} 
\widehat{{\boldsymbol \beta}_{\bar{\alpha}}} = {\boldsymbol \beta}_{\bar{\alpha}}+{\bf m}_{\bar{\alpha}}
\end{equation}

where  ${\bf m}_{\bar{\alpha}}$ is the vector of deviations of the estimates from their true value.  The expected estimate of $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$ is then

\begin{equation}
\begin{array}{rl}
E[\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}]=& {\boldsymbol \beta}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\boldsymbol \beta}_{\bar{\alpha}}+E[{\bf m}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\bf m}_{\bar{\alpha}}]\\
=& \boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}+E[{\bf m}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\bf m}_{\bar{\alpha}}]\\

\end{array}
\end{equation} 

\DIFdelbegin \DIFdel{where ${\bf X}$ is the design matrix with the first column all ones, and the second ${\bf p}_{0}-{\bf q}_{0}$. }\DIFdelend Here, the expectation is taken over the distribution of estimates, and it is assumed the estimates are unbiased (since then, $E[{\bf m}_{\bar{\alpha}}]={\bf 0}$, and so $E[{\bf m}_{\bar{\alpha}}{\boldsymbol \beta}_{\bar{\alpha}}^{\top}]={\bf 0}$). This same assumption implies


\begin{equation}
\begin{array}{rl}
E[\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}]=& \boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}+Tr\left({\bf X}^{\top}{\bf L}_0{\bf X}E[{\bf m}_{\bar{\alpha}}^{\top}{\bf m}_{\bar{\alpha}}]\right)\\
\end{array}
\end{equation} 

Since $E[{\bf m}_{\bar{\alpha}}^{\top}{\bf m}_{\bar{\alpha}}]$ is a matrix of sampling (co)variances for the parameters, to get an improved estimate we can use the inverse Hessian to get an approximate \DIFdelbegin \DIFdel{${\bf S}_{\bar{\alpha}}$ }\DIFdelend \DIFaddbegin \DIFadd{${\bf S}_{\bar{\alpha}}=E[{\bf m}_{\bar{\alpha}}^{\top}{\bf m}_{\bar{\alpha}}]$ }\DIFaddend :

\begin{equation} 
\widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}}= \widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}-Tr\left({\bf X}^{\top}{\bf L}_0{\bf X}{\bf S}_{\bar{\alpha}}\right)
\end{equation} 

In addition, $Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})$ is most likely an upwardly biased estimator of $Tr({\bf L}_0{\bf V}_{\bar \alpha})$. However, we found no easy way to determine or correct for the degree of bias, and the simulation results suggest that the bias is likely to be small, at least when the number of replicates or generations is moderately large.\\

% We can express the estimate of the trace as

% \begin{equation}
% \begin{array}{rl}
% Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}}) =& Tr({\bf L}_0\widehat{\sigma^2_{\bar \alpha}}{\bf L}_0^{\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}Tr({\bf L}_0^{1+\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}Tr({\bf D}_L^{2+2\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}\left(\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)\\
% \end{array}
% \end{equation}

% such that

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})] =& 
% COV\left(\widehat{\sigma^2_{\bar \alpha}}, \sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)+E[\widehat{\sigma^2_{\bar \alpha}}]E[\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}]\\
% \end{array}
% \label{Eq:ETrLV}
% \end{equation}

% Assuming estimates of $\sigma^2_{\bar \alpha}$ and $p_{\bar{\alpha}}$ are unbiased and their sampling distribution is multivariate normal then

% \begin{equation}
% \begin{array}{rl}
% E[d_i^{2+2\widehat{p_{\bar{\alpha}}}}]=&E[exp(2log(d_i)+2\widehat{p_{\bar{\alpha}}}log(d_i))]\\
% =&exp(2log(d_i)+2p_{\bar{\alpha}} log(d_i)+2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\   =&d_i^{2+2p_{\bar{\alpha}}}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\

% \end{array}
% \end{equation}

% following results for the log-normal distribution. 

% Consequently, the final product in Equation \ref{Eq:ETrLV} is upwardly biased. However, this might be offset by the covariance term which is likely to be negative given the sampling distribution of the two parameters will in general have a negative correlation. The covariance does not have an analytical form but can be approximated using the Delta method:

% \begin{equation}
% \begin{array}{rl}
% COV\left(\widehat{\sigma^2_{\bar \alpha}}, \sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)\approx&
% COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\frac{\partial \left(\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)}{\partial \widehat{p_{\bar{\alpha}}}}\Big|_{p_{\bar{\alpha}}}\\
% \approx&
% COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\sum_i log(2d_i)d_i^{2+2p_{\bar{\alpha}}}\\
% \end{array}
% \end{equation}

% This gives

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})]  =& COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\sum_i log(2d_i)d_i^{2+2p_{\bar{\alpha}}}+\sigma^2_{\bar \alpha}\sum_id_i^{2+2p_{\bar{\alpha}}}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\
% =& \sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\right]\\
% \end{array}
% \end{equation}

% If $VAR(\widehat{p_{\bar{\alpha}}})$ is small then

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})] 
% =& \sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}+\sigma^2_{\bar \alpha}2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}})\right]\\
% =& Tr({\bf L}_0{\bf V}_{\bar \alpha})+\sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}})\right]\\ 
% \end{array}
% \end{equation}

% Note that if we model ${\bf V}_{\bar \alpha}$ using only the diagonal elements of ${\bf L}_{0}$ then

% \begin{equation}
% \begin{array}{rl}
% Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})                                      =& \widehat{\sigma^2_{\bar \alpha}}\left(\sum_i l_{0_{ii}}^{1+\widehat{p_{\bar{\alpha}}}}\right)\\
% \end{array}
% \end{equation}

% and so the above equations can be used by replacing $d_i$ with $\sqrt{l_{0_i}}$.


\section{\DIFdelbegin \DIFdel{Appendix 6: Comparison with the method of \mbox{%DIFAUXCMD
\citet{buffalo2019linked}}\hskip0pt%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{Analysing allele frequency data from pool-seq}\DIFaddend }
\DIFaddbegin \label{App:pool-seq}

\DIFadd{The main derivation of our method assumes allele frequency changes in each replicate are known without error, and the majority of our simulations were analysed with this being true. However, this assumption is unlikely to be met in reality and here we develop a method for incorporating uncertainty in allele frequencies estimated using pool-seq.
}

\DIFadd{Assuming that all individuals have the same probability of being sampled, the covariance in reference allele number at locus $i$ and $j$ is equal to the number of reads that span both sites, $O_{ij}$, multiplied by the covariance in allele number across haplotypes $2L^{'}_{i,j}$. To get the covariance in reference allele frequency we must divide this by the number of reads spanning site $i$ ($O_{ii}$) and the number of reads spanning site $j$ to get $2L^{'}_{i,j}O_{ij}/(O_{ii}O_{jj})$. When $i=j$ this reduces to the familiar binomial variance for  allele frequency at a single site $2L^{'}_{i,i}O_{ii}/(O_{ii}O_{ii})=pq/O_{ii}$. When analysing binomial data the variance often exceeds its expectation - a phenomenon known as overdisperion. In the context of pool-seq this will be mostly driven by individuals, rather than gametic contributions, varying in their probability of being sampled. In this instance, the exact form of the sampling (co)variances will depend in a complicated way on both ${\bf L}^{'}$ and ${\bf L}^{''}$, but here we assume that for sites close enough to be spanned by the same read ${\bf L}^{'}$ dominates over ${\bf L}^{''}$ and at a site $pq$ dominates over ${\bf L}^{''}$. We then simply accommodate any overdispersion using a parameter that scales the sampling (co)variances, $\sigma^2_o$, which is constant over loci. This approach is widely used when analysing binomial data (the qausibinomial approach - \mbox{%DIFAUXCMD
\citep{McCullagh.1989}}\hskip0pt%DIFAUXCMD
) and values greater than one indicate overdispersion. In what follows we also assume $\sigma^2_o$ is constant across replicate/time-points although this could be relaxed.
}

\DIFadd{Having the matrix ${\bf Q}$ with the $ij^{th}$ element equal to $O_{ij}/(O_{ii}O_{jj})$ the sampling covariance in allele frequency in replicate $m$ at time $t_m$ is equal to $2\sigma^2_o(\boldsymbol{\mathcal L}^{'}_{t_m,m}\circ{\bf Q}_{t_m,m})$. Since errors in allele frequency estimates are independent at different time points the expected sampling covariance in allele frequency change is proportional to: 
}

\begin{equation}
\DIFadd{\begin{array}{rl}
\boldsymbol{\mathcal{E}}_m =& 2\sigma^2_oE\left[\boldsymbol{L}^{'}_{t_m,m}\circ{\bf Q}_{t_m,m}+\boldsymbol{L}^{'}_{\tau_m,m}\circ{\bf Q}_{\tau_m,m}\right]\\
                  =& 2\sigma^2_oE\left[(\boldsymbol{\mathcal L}_{t_m,m}+\Delta\boldsymbol{L}^{'}_{t_m,m})\circ{\bf Q}_{t_m,m}+(\boldsymbol{\mathcal L}_{\tau_m,m}+\Delta\boldsymbol{L}^{'}_{\tau_m,m})\circ{\bf Q}_{\tau_m,m}\right]\\
                  =& 2\sigma^2_o\left(\boldsymbol{\mathcal L}_{t_m,m}\circ{\bf Q}_{t_m,m}+\boldsymbol{\mathcal L}_{\tau_m,m}\circ{\bf Q}_{\tau_m,m}\right)\\
\end{array}
}\end{equation}

\DIFadd{where the expectation is taken over evolutionary realisations of ${\bf L}^{'}$ and depends on $E[\Delta\boldsymbol{L}^{'}_{t,m}]=0$. The expected sampling covariance in projected allele frequency change is therefore:
}\begin{equation}
\DIFadd{\overrightarrow{\boldsymbol{\mathcal{E}}}_m = 2\sigma^2_o{\bf P}\left(\boldsymbol{\mathcal L}_{t_m,m}\circ{\bf Q}_{t_m,m}+\boldsymbol{\mathcal L}_{\tau_m,m}\circ{\bf Q}_{\tau_m,m}\right)}{\DIFadd{\bf P}}\DIFadd{^{\top}
}\end{equation}


\DIFadd{$\overrightarrow{\boldsymbol{\mathcal{E}}}$ is a square dense matrix equal in dimension to the number of projected loci. Moreover, it will vary over replicates such that the complete covariance structure across all replicates is a large block-diagonal matrix with large blocks. Given the computational burden this entails we fitted approximate models to the simulated data where $\overrightarrow{\boldsymbol{\mathcal{E}}}$ was diagonalised. For the same reason, we also used a diagonalised ${\bf Q}$ matrix which only contains information on coverage rather than complete information on the number of reads overlapping pairs of sites. In addition we also assumed $\boldsymbol{\mathcal L}_{t_m,m}=\boldsymbol{\mathcal L}_{\tau_m,m}={\bf L}^{'}_0$ for all $m$. For real data we advocate not using these approximations.
}

\DIFadd{Estimation error in allele frequency at a single-site is comparable to drift, with coverage $O_{ii}$, or effective coverage $\sigma^2_oO_{ii}$, equivalent to $N_E$. Because of this it might be tempting to think that estimates of $V_{\bar A}(0)$ would remain unbiased if estimation error was ignored since the residual variance will soak up the excess variance when model fitting. The only advantage, then, of including $\overrightarrow{\boldsymbol{\mathcal{E}}}$ is to increase precision when there is heterogeneity in coverage across sites. However, this is not the case - estimates of $V_{\bar A}(0)$ will be downwardly biased if estimation error is ignored and this bias can be substantial unless reads are very long and/or coverage is high.  The reason for this is that a major source of information on $V_{\bar A}(0)$ comes from correlated changes in allele frequency at loci that are in LD, and in particular correlations that are tighter than expected under drift. If reads only span single sites then the error covariance in allele frequency is zero since $O_{ij}=0$ resulting in correlations that are weaker than under drift which partly destroys the signal of selection. If reads are longer, then the error covariance in allele frequency will come to resemble that caused by drift and any bias when ignoring the errors should be reduced. However, at very long read lengths the bias may even become positive as the sampling correlations between distant sites on the same chromosome will be higher than that under drift where it will be broken down by a round of recombination (Equation \ref{eq:drift_var}). 
}

\section{\DIFadd{Comparison with the method of \mbox{%DIFAUXCMD
\citet{buffalo2019linked}}\hskip0pt%DIFAUXCMD
}}
\DIFaddend \label{App:BandC}

To make clearer the distinction between the approach of B\&C and our approach, here we explicitly express the expectations and covariances appearing in B\&C as conditional on ${\bf B}$ and $\boldsymbol{\alpha}$. In the sections dealing with our theory and inference, the conditioning (on ${\bf L}_0$) is left implicit. B\&C work with the quantity

\begin{equation}
COV(\Delta {\bf p}_t, \Delta {\bf p}_{\tau}^{\top} | {\bf B}, \boldsymbol{\alpha})
\end{equation}

where $\tau$ is some generation after $t$ (B\&C actually only work with the diagonal elements of this matrix, but we retain the full multi-locus model here for generality). Importantly, when B\&C estimate the additive genetic variance in fitness they assume that both $\Delta {\bf p}_t$ and $\Delta {\bf p}_{\tau}$ both represent allele frequency change over a single generation (Assumption A). As the change due to drift will be independent in different generations, we can rewrite B\&C's covariance: 

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_t, \Delta {\bf p}_{\tau}^\top  | {\bf B}, \boldsymbol{\alpha}) 
=& COV({\bf L}_t\boldsymbol{\alpha}_t,  \boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau}  | {\bf B}, \boldsymbol{\alpha})\\
%=& E\left[{\bf L}_t\boldsymbol{\alpha}_t\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau}  | {\bf B}, \boldsymbol{\alpha}\right]-\left[{\bf L}_t\boldsymbol{\alpha}_t  | {\bf B}, \boldsymbol{\alpha}\right] E\left[\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
=& E\left[{\bf L}_t\boldsymbol{\alpha}_t\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]-E\left[{\bf L}_t | {\bf B}, \boldsymbol{\alpha}\right]\boldsymbol{\alpha}_t \boldsymbol{\alpha}_{\tau}^{\top}E\left[{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov1}
\end{equation}

Since the diagonal elements of ${\bf L}$ have to be positive, a sufficient, but not necessary, condition for the final term to be zero is that there is no direct selection on the loci (i.e. $\boldsymbol{\alpha}={\bf 0}$). It is not a necessary condition because the change caused by direct selection at all loci could be exactly balanced by the change caused by indirect selection at other loci, although we ignore this unlikely scenario. The assumption that $\boldsymbol{\alpha}={\bf 0}$ is achieved in B\&C by assuming that sites can be partitioned into neutral and selected sites and that allele frequency change is only tracked at the neutral sites (Assumption B). To understand the consequences of this assumption we consider all loci are being followed, both a selected set (${\mathcal S}$) and a neutral set (${\mathcal N}$). Consequently,

\begin{equation}
\boldsymbol{\alpha}=
\left[
\begin{array}{c}
{\bf 0}\\
\boldsymbol{\alpha}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

and so

\begin{equation}
\boldsymbol{\alpha}\boldsymbol{\alpha}^{\top}=
\left[
\begin{array}{cc}
{\bf 0}&{\bf 0}\\
{\bf 0}&\boldsymbol{\alpha}_{\mathcal S}\boldsymbol{\alpha}^{\top}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

We can also partition ${\bf L}$

\begin{equation}
{\bf L}=
\left[
\begin{array}{cc}
{\bf L}_{\mathcal N}&{\bf L}_{{\mathcal N}, {\mathcal S}}\\
{\bf L}_{{\mathcal S}, {\mathcal N}}&{\bf L}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

and writing ${\bf L}_{{\mathcal N}, {\mathcal S}} = {\bf B}_{{\mathcal N}}{\bf R}_{{\mathcal N}, {\mathcal S}}{\bf B}_{{\mathcal S}}$, Equation \ref{Eq:BCcov1} for neutral sites becomes

\begin{footnotesize}
\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_{{\mathcal N}_t}, \Delta {\bf p}_{{\mathcal N}_{\tau}}^\top  | {\bf B}, \boldsymbol{\alpha}) 
%=& E\left[{\bf L}_{{\mathcal N}_t, {\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf L}_{{\mathcal S}_\tau, {\mathcal N}_\tau} | {\bf B}, \boldsymbol{\alpha}\right]+E\left[{\bf L}_{{\mathcal N}_t, {\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]E\left[\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf L}_{{\mathcal S}_\tau, {\mathcal N}_\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
%=& E\left[{\bf B}_{{\mathcal N}_t}{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
%&+E\left[{\bf B}_{{\mathcal N}_t}{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]E\left[\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
=& {\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
&+{\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}E\left[{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\ 
\end{array}
\label{Eq:BCcov3}
\end{equation}
\end{footnotesize}
Under the conditioning of B\&C, ${\bf R}_{{\mathcal S}, {\mathcal N}_\tau}$ is a random variable. If we assume that the linkage-disequilibrium between the neutral alleles and the selected alleles has arbitrary sign, then $E[{\bf R}_{{\mathcal S}, {\mathcal N}_\tau} |  {\bf B}, \boldsymbol{\alpha}]={\bf 0}$, which will be met if the reference allele is chosen arbitrarily (e.g. not based on minor allele frequency \citep{good2022linkage}). Under this assumption (Assumption C) the final term in Equation \ref{Eq:BCcov3} disappears to give: 

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_{{\mathcal N}_t}, \Delta {\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})
=& {\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
\end{array}
\label{Eq:BCcov4}
\end{equation}

As in our inference section, the vector of allele frequency changes could be transformed using matrix ${\bf P}$ ($\Delta \overrightarrow{\bf p} = {\bf P}\Delta {\bf p}$) and B\&C use the projection ${\bf P}={\bf B}_{{\mathcal N}_t}^{-1}$ (they actually multiply this by $\sqrt{2}$ - see Equation \ref{Eq:BCcov10}) which results in

\begin{equation}
\begin{array}{rl}
COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) 
=& E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_t}^{-1}\\
=& {\bf B}_{{\mathcal N}_t}^{-1}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
\end{array}
\label{Eq:BCcov5}
\end{equation}

Further derivation in B\&C considers the expected value of a diagonal element of this matrix: the average (over neutral loci) covariance in projected allele frequency change. However, it is perhaps easier to note that the trace of this matrix is equal to this average multiplied by the number of neutral loci, $n_{L_\mathcal{N}}$ (see below). Since the trace of an outer product is equal to the inner product we get:

\begin{footnotesize}
\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top  | {\bf B}, \boldsymbol{\alpha})\right)&=
E\left[\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{{\mathcal S}_t}{\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov6}
\end{equation}
\end{footnotesize}

The diagonal element $j$ of ${\bf W}_{t\tau}={\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}}$ is equal to the sum of selected locus $j$'s \DIFdelbegin \DIFdel{$R_{j_t,i_t}R_{j_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$ }\DIFdelend \DIFaddbegin \DIFadd{$R_{t,ji}R_{{\tau},ji}(b_{\tau,i}/b_{t,i})$ }\DIFaddend across all neutral loci $i$. The $jk^{th}$ off-diagonal element is the sum of \DIFdelbegin \DIFdel{$R_{j_t,i_t}R_{k_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$ }\DIFdelend \DIFaddbegin \DIFadd{$R_{t,ji}R_{{\tau},ki}(b_{\tau,i}/b_{t,i})$ }\DIFaddend for selected loci $j$ and $k$ across all neutral loci $i$. If we write  ${\bf W}_{t\tau} = {\bf H}_{t\tau}+({\bf W}_{t\tau}-{\bf H}_{t\tau})$ where ${\bf H}_{t\tau}$ and ${\bf W}_{t\tau}-{\bf H}_{t\tau}$ are zero but for the diagonal and off-diagonal elements respectively, then Equation \ref{Eq:BCcov6} becomes


\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&\quad+\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf W}_{t\tau}-{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov7}
\end{equation}

If we focus on a system with two selected loci, $j$ and $k$, then the final term in Equation \ref{Eq:BCcov7} is equal to:
\begin{tiny}
\begin{equation}
\sum_j\sum_k\left(\alpha\DIFdelbegin \DIFdel{_{j_t}}\DIFdelend \DIFaddbegin \DIFadd{_{t,j}}\DIFaddend \alpha\DIFdelbegin \DIFdel{_{k_{\tau}}}\DIFdelend \DIFaddbegin \DIFadd{_{{\tau,k}}}\DIFaddend b_{j_t,j_t}b_{k_{\tau},k_{\tau}}\sum _i \left(E\left[R\DIFdelbegin \DIFdel{_{i_t,j_t}}\DIFdelend \DIFaddbegin \DIFadd{_{t,ij}}\DIFaddend R\DIFdelbegin \DIFdel{_{i_{\tau},k_{\tau}} }\DIFdelend \DIFaddbegin \DIFadd{_{{\tau},ik} }\DIFaddend | {\bf B}, \boldsymbol{\alpha}\right]b_{i_\tau}/b_{i_t}\right)+\alpha_{j_{\tau}}\alpha_{k_t}b_{j_{\tau},j_{\tau}}b_{k_t,k_t}\sum _i \left(E\left[R\DIFdelbegin \DIFdel{_{i_{\tau},j_{\tau}}}\DIFdelend \DIFaddbegin \DIFadd{_{{\tau},ij}}\DIFaddend R\DIFdelbegin \DIFdel{_{i_t,k} }\DIFdelend \DIFaddbegin \DIFadd{_{t,ik} }\DIFaddend | {\bf B}, \boldsymbol{\alpha}\right]b_{i_\tau}/b_{i_t}\right)\right).
\label{eq:AssumpE}
\end{equation}
\end{tiny}

Under Hill-Robertson interference, if $\alpha_j$ and $\alpha_k$ have the same sign we expect them to be in negative LD with each other, and as a consequence have opposing patterns of LD with the neutral loci (i.e. if $\alpha_j\alpha_k>0$ then we expect $E[R_{i,j}R_{i,k}]<0$ and vice versa). Although the terms of these products are evaluated at different generations in Equation \ref{eq:AssumpE} ($t$ and $\tau$) we expect the terms to share sign in the same way, generating a negative expectation for the second term in Equation \ref{Eq:BCcov7}.  However, assuming an absence of Hill-Robertson interference, or signed linkage-disequilibrium more generally (Assumption D), then the final term in Equation \ref{Eq:BCcov7} can be dropped:

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top) | {\bf B}, \boldsymbol{\alpha}\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}
\end{array}
\label{Eq:BCcov8}
\end{equation}

Based on a deterministic model for changes in linkage-disequilibrium (Assumption E) and assuming nongametic-phase linkage-disequilibrium is absent (Assumption F), Equations 40-44 in B\&C derive an expression from which $E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]$ can be computed. Under the assumption that drift (or selection) does not alter the dynamics of ${\bf R}$ then (Equation 42 in B\&C):

\begin{equation}
\begin{array}{rl}
L_{j_{\tau},i_{\tau}} =& L_{j_t,i_t}\frac{b_{j_\tau}^2}{b_{j_t}^2}(1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}

which implies

\begin{equation}
\begin{array}{rl}
R_{j_{\tau},i_{\tau}} =&R_{j_t,i_t}\frac{b_{j_\tau}b_{i_t}}{b_{j_t}b_{i_\tau}}(1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}

and so

\begin{equation}
\begin{array}{rl}
E\left[H_{j_t, j_\tau} | {\bf B}, \boldsymbol{\alpha}\right]
&=\sum_i E\left[R_{j_t,i_t}R_{j_{\tau},i_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{i_\tau}}{b_{i_t}}\\
%&=\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{i_\tau}}{b_{i_t}}\frac{b_{j_\tau}b_{i_t}}{b_{j_t}b_{i_\tau}}(1-r(g_{j,i}))^{\tau-t}\\
%&=\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{j_\tau}}{b_{j_t}}(1-r(g_{j,i}))^{\tau-t}\\
&=\frac{b_{j_\tau}}{b_{j_t}}\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}


where $r(g_{j,i})$ is the recombination rate as a function of the distance $g_{i,j}$ between the two loci. Writing ${\bf F}_{t\tau}$ a diagonal matrix with the $j^{th}$ element equal to
$\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}$, then $E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]= E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{\mathcal{S}_t}^{-1}$ and so

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{\mathcal{S}_t}^{-1}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}^2\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov9}
\end{equation}

where (under random mating) ${\bf B}_{\mathcal{S}_\tau}^2$ is a diagonal matrix with elements proportional to the genetic diversities in generation $\tau$. However, this is still hard to evaluate since $E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]$ will vary over loci in a way that may depend on ${\bf B}$ and hence ${\bf B}_{{\mathcal S}_t}^2$. 
The method of B\&C assumes that the sample correlation between the diagonal elements of $E\left[{\bf F}_{t\tau} | {\bf B},\boldsymbol{\alpha}\right]$ and the elements $\alpha_{j_t}\alpha_{j_\tau}b^2_{j_\tau}$ is zero (Assumption G). Under this assumption:

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)&=\frac{1}{n_{L_\mathcal{S}}}
\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{\mathcal{S}_\tau}^2\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
&=
\frac{1}{n_{L_\mathcal{S}}}C_a(t\rightarrow\tau)E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov10}
\end{equation}

where $n_{L_\mathcal{S}}$ is the number of selected loci (note that in B\&C  the leading term is $\frac{1}{2n_{L_\mathcal{S}}}$ not $\frac{1}{n_{L_\mathcal{S}}}$ and this is because our projection matrices are only proportional by a factor $\sqrt{2}$ -  see Equation \ref{Eq:BCcov5}). The method of B\&C further assumes (Assumption H) that the average effects are constant in time such that $\boldsymbol{\alpha}_t=\boldsymbol{\alpha}_\tau$ then this reduces to

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)&=
\frac{V_a(\tau)}{n_{L_\mathcal{S}}}E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov11}
\end{equation}

Under Assumption H, Assumption G implies that the additive genic variance contributed by a selected locus is independent of its associations with neutral loci as measured by $R_{i_t,j_t}^2$. 
However, allele frequencies at selected loci enter the expression for the additive genic variance, and they also dictate the range of $R_{i_t,j_t}$ and therefore the magnitude of $R_{i_t,j_t}^2$: when selected allele frequencies are  small compared to frequencies at neutral alleles,  $R_{i_t,j_t}$ cannot cover the full range of -1 to 1 \citep{sved2018one}. 

B\&C approximate ${\bf R}_t$, and therefore ${\bf F}_{t\tau}$ under the assumption of mutation-drift-recombination equilibrium (Assumption I). \citet{Ohta.1971} derived the expectation of $L_{j_t, i_t}L_{j_t, i_t}=L^2_{j_t, i_t}$ under this assumption, although the expectation of $R^2_{j_t, i_t}$ can only be approximated as the expectation of $L^2_{j_t, i_t}$ divided by the expectation of the genetic diversities at the two loci, and is only accurate when the minor allele frequencies are greater than 10\%  \citep{McVean.2002} -- and can be out by orders of magnitude when allele frequencies are extreme \citep{Song.2007}, as can be expected at loci under selection.  Moreover,  \citet{Ohta.1971} derived the expectation $E[L^2_{j_t, i_t}]$ yet the B\&C approach actually requires $E\left[L^2_{j_t, i_t} | {\bf B}, \boldsymbol{\alpha}\right]$ which is considerably more challenging to compute \citep{good2022linkage}. In the Appendix B\&C also relax, to some extent, Assumption I, where $Tr({\bf F}_{t\tau})$ is calculated empirically using all loci, neutral and selected (Equation 55). In both cases - using the neutral expectation (Assumption I) or empirical LD (Assumption I-b) - the expected LD between selected and neutral loci will be overestimated since in reality selected alleles will be rarer than neutral alleles and so their LD, even measured as a correlation, will be reduced compared to that between neutral loci \citep{sved2018one}.

Equation \ref{Eq:BCcov11} allows $V_a(\tau)$ to be estimated, but B\&C aim to estimate $V_a(t)$.  Under Assumption H, and assuming that the proportional change in genetic diversity at selected loci between generation $t$ and $\tau$ is constant across loci (Assumption J: ${\bf B}_{\mathcal{S}_t}^2{\bf B}_{\mathcal{S}_\tau}^{-2} = \phi_{t,\tau}{\bf I}$), $V_a(t)=\phi_{t,\tau} V_a(\tau)$.\\ 

The above derivation assumes that the sites can be partitioned into selected and neutral sites and that the map positions of all sites are known.  In practice, this will often be infeasible and so a number of additional assumptions are required. In the absence of map positions, Haldane's \citeyearpar{haldane1919map} mapping function is assumed for $r(g)$ (Assumption K) but, since the selected loci and their physical position, $g$, are assumed unknown, a model is also required for $g$. B\&C assume that selected and neutral loci are distributed uniformly and independently such that $g_{j,i}$ has a triangular distribution (Assumption L). Also, since the selected sites are unobserved, $\phi_{t,\tau}$ cannot be computed and so it is assumed that that $\phi_{t,\tau}$ is equal to the ratio of genetic diversity at generation $\tau$ to genetic diversity at generation $t$ across all neutral loci (Assumption M). \\ 

In addition to the assumptions/approximations made when developing the theory, additional assumptions/approximations are made when making inferences from data.  Rather than taking the average (over loci) covariance (over evolutionary replicates) the covariance over loci is taken. However, from the law of total covariance this is expected to yield the correct result under Assumptions B and C. In addition, rather than calculating the (co)variances in projected allele frequency change, it is assumed (Assumption N) that the (co)variances in actual allele frequency divided through by the average projection is a good approximation: $COV_{L}(\Delta p_{t}, \Delta p_{\tau})/E[b_t^2]$ is a good approximation of $COV_{L}(\Delta p_{t}/b_{t}, \Delta p_{\tau}/b_{t})$ where $ COV_L$ designates a covariance over loci (Equation 16 B\&C). The two quantities are only expected to agree under restrictive conditions \citep{Bohrnstedt.1969}. However, it is not necessary to make Assumption N and relaxing it can reduce the bias in the estimator considerably. Finally, if there is measurement error in allele frequencies and the same allele frequency measurements are used to calculate change over adjacent intervals then this will generate downward bias in the estimated covariances. This is corrected for in B\&C by assuming the sampling error in allele frequencies is binomial around the true value (Assumption O), although in practice non-binomial causes of overdispersion are likely.\DIFdelbegin \DIFdel{While we have tested our method assuming allele frequencies are known without error, any error in the allele frequencies will look like drift if allele frequencies are measured independently in each time/replicate. Consequently, the sampling noise will be incorporated into the estimate of the residual variance. }\DIFdelend \\ 

To connect Equation \ref{Eq:BCcov11} with the derivation in B\&C more clearly, we can write 

\begin{equation}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)=n_{L_\mathcal{N}}\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}
\end{equation}

where the overline denotes the sample mean for the $n_{L_\mathcal{N}}$ neutral loci. Similarly, 

\begin{equation}
\begin{array}{rl}
Tr({\bf F}_{t\tau}) =& \sum_j\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}\\
=&n_{L_\mathcal{N}}\overline{\sum_jE\left[R_{j_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,{\mathcal N}}))^{\tau-t}}\\
\end{array}
\end{equation}

Equation \ref{Eq:BCcov11} can then be written as

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}&=
\frac{V_a(\tau)}{n_{L_\mathcal{S}}}\overline{\sum_jE\left[R_{j_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,{\mathcal N}}))^{\tau-t}}\\
\end{array}
\label{Eq:BCcov12}
\end{equation}

which is Equation 8 in B\&C averaged over neutral loci and can be further simplified to

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}&=
V_a(\tau)\overline{E\left[R_{{\mathcal S}_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{{\mathcal S},{\mathcal N}}))^{\tau-t}}\\
\end{array}
\label{Eq:BCcov13}
\end{equation}

where the overline indicates the sample average of all the $n_{L_\mathcal{S}}n_{L_\mathcal{N}}$ pairwise comparisons between selected loci and neutral loci. 

Extending this theory to allele frequency change measured in independent replicates, rather than at different time-points in a single population is straightforward \citep{Buffalo.2020}. If allele frequency change is measured in two populations, $m$ and $n$,  both of which have been derived independently from the base population $t$ generation  in the past, Equation  \ref{Eq:BCcov13} can be expressed as:

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_m}, \Delta \overrightarrow{p}_{{\mathcal N}_n}^\top | {\bf B}, \boldsymbol{\alpha})}&=
V_a(m,n)\overline{E\left[R_{{\mathcal S}_0,{\mathcal N}_0}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{{\mathcal S},{\mathcal N}}))^{2t}}\\
\end{array}
\label{Eq:BCcov14}
\end{equation}

assuming the average effects have stayed constant.


\DIFdelbegin \subsection[Appendix 7]{\DIFdel{Appendix 7: $N_E$ and average effects under a log-linear model}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \section{\DIFadd{$N_E$ and average effects under a log-linear model}}
\DIFaddend \label{App:loglinear}

In \DIFdelbegin \DIFdel{the simulationswe simulate for }\DIFdelend \DIFaddbegin \DIFadd{our simulations, we model the logarithm of absolute fitness of an }\DIFaddend individual $k$ \DIFaddbegin \DIFadd{using an additive model across loci:
}\DIFaddend 

$$\DIFdelbegin \DIFdel{y}\DIFdelend \DIFaddbegin \DIFadd{log(W}\DIFaddend _k\DIFaddbegin \DIFadd{) }\DIFaddend = \DIFdelbegin %DIFDELCMD < {\bf %%%
\DIFdel{c}%DIFDELCMD < }%%%
\DIFdel{^{\top}}\DIFdelend \DIFaddbegin \DIFadd{Y}\DIFaddend _k \DIFdelbegin %DIFDELCMD < \boldsymbol{\eta}%%%
\DIFdelend \DIFaddbegin \DIFadd{= \sum_{i=1}^{n_L} y_{k,i} }\DIFaddend + e_k$$
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{where the }\DIFdelend \DIFaddbegin \DIFadd{where $y_{k,i}$ is the genotypic contribution of locus $i$ to the log absolute fitness of individual $k$, and the }\DIFaddend environmental deviations, $e$, have zero mean and standard deviation $\sigma_e$. We \DIFaddbegin \DIFadd{allow within-locus deviations from additivity using a fitness-scheme equivalent to the one employed by \mbox{%DIFAUXCMD
\citet{lynch1998} }\hskip0pt%DIFAUXCMD
(pp. 67) adapted for }\emph{\DIFadd{proportions}} \DIFadd{of reference alleles as opposed to counts:
}

\begin{equation}
\DIFadd{\begin{array}{rl}

y_{k,i} =

\begin{cases}
    0 & \text{if } c_{k,i} = 0 \\
    (1 + \kappa_i)\eta_i/2 & \text{if } c_{k,i} = 0.5 \\
    \eta_i & \text{if } c_{k,i} = 1
\end{cases}

\end{array} 
}\end{equation}

\DIFadd{Note that in the parameterisation of \mbox{%DIFAUXCMD
\citet{falconer1996}}\hskip0pt%DIFAUXCMD
, the genotypic value of the heterozygotes is $(\eta_i + d_i)/2$ such that $d_i = \kappa_i \eta_i$.
}

 \DIFadd{We }\DIFaddend then draw $2N_{t+1}$ parents with replacement from a multinomial with the   \DIFdelbegin \DIFdel{unnormalised  }\DIFdelend probability of $k$ being a parent of an offspring \DIFdelbegin \DIFdel{equal to $P_k=exp(y_k)$ and the normalised probability being $p_k=P_k/\sum_{j}^{N_t}P_j$. Absolute fitness is therefore $2N_{t+1}p_k = 2\frac{N_{t+1}}{N_tE[P]}P_k$. Having $m = 2\frac{N_{t+1}}{N_tE[P]}$, then absolute fitness  is $P_km=exp(y_k)m$}\DIFdelend \DIFaddbegin \DIFadd{proportional to its absolute fitness  $W_k=exp(Y_k)$}\DIFaddend .  Following \citet{Kojima.1959} we can define Fisher's average effect for relative fitness in terms of the partial derivative of \DIFdelbegin \DIFdel{each $E[c]=p_0$ }\DIFdelend \DIFaddbegin \DIFadd{mean fitness }\DIFaddend with respect to \DIFdelbegin \DIFdel{mean fitness }\DIFdelend \DIFaddbegin \DIFadd{each $E[c]=p_0$ }\DIFaddend and then rescale by mean fitness:

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \alpha_i =& \frac{1}{\bar W}\frac{\partial{\bar W}}{\partial{p_{0_i}}}\\
%DIFDELCMD <  =& \frac{1}{E[exp(y)m]}\frac{\partial{E[exp(y)m]}}{\partial{p_{0_i}}}\\
%DIFDELCMD <  =&  \frac{1}{E[exp(y)]}\frac{\partial{E[exp(y)]}}{\partial{p_{0_i}}}\\
%DIFDELCMD <   =&  \frac{\partial{log(E[exp(y)])}}{\partial{p_{0_i}}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\alpha_i =& \frac{1}{\bar W}\frac{\partial{\bar W}}{\partial{p_{0_i}}}\\
 =&  \frac{1}{E[exp(Y)]}\frac{\partial{E[exp(Y)]}}{\partial{p_{0_i}}}\\
  =&  \frac{\partial{log(E[exp(Y)])}}{\partial{p_{0_i}}}\\
\end{array}\DIFaddend 
\end{equation}

Assuming \DIFdelbegin \DIFdel{that $y$ }\DIFdelend \DIFaddbegin \DIFadd{$Y$ }\DIFaddend to be normally distributed with mean \DIFdelbegin \DIFdel{${\mu_y}$ and variance $V_y$ then }\DIFdelend \DIFaddbegin \DIFadd{${\mu_Y}$ and variance $V_Y$ }\DIFaddend allows us to use the expression for the expectation of a log-normal distribution to write:

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \alpha_i&= \frac{\partial log(exp(\mu_y + {V_y}/2 ))}{\partial p_i} \\
%DIFDELCMD < &= \frac{\partial (\mu_y + {V_y}/2 )}{\partial p_{0_i}}
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\alpha_i&= \frac{\partial log(exp(\mu_Y + {V_Y}/2 ))}{\partial p_i} \\
&= \frac{\partial (\mu_Y + {V_Y}/2 )}{\partial p_{i}}
\end{array}\DIFaddend 
\end{equation}

It is worth highlighting that, so far, we have made no assumptions about the distribution of the contributions (\DIFdelbegin \DIFdel{$c_{i}\eta_{i}$}\DIFdelend \DIFaddbegin \DIFadd{$y_i$}\DIFaddend ) made by individual loci to \DIFdelbegin \DIFdel{$y$. 
}\DIFdelend \DIFaddbegin \DIFadd{$Y$. 
}

\DIFaddend Next, we \DIFdelbegin \DIFdel{split up $\mu_y$ and $V_y$ into the contributions of individual loci.
}\DIFdelend \DIFaddbegin \DIFadd{assume Hardy-Weinberg genotypic frequencies to write:
}\DIFaddend 


\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \mu_y &= \sum_{i=1}^{n_L} E[c_i \eta_i] \\
%DIFDELCMD < &= \sum_{i=1}^{n_L} p_{0_i} \eta_i
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\mu_Y &= \sum_{i=1}^{n_L} E[y_{i}] \\
&=  \sum_{i=1}^{n_L} [p_i^2\eta_i + 2{p_i}{q_i}(1 + \kappa_i)\eta_i/2] \\
&= \sum_{i=1}^{n_L} [{p_i}{\eta_i} + p_iq_i\kappa_i \eta_i]\\
&= \sum_{i=1}^{n_L} \eta_i[{p_i} + p_iq_i\kappa_i]
\end{array}\DIFaddend 
\end{equation}

\DIFaddbegin \DIFadd{Differentiating with respect to $p_i$ yields:
}

\DIFaddend \begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < V_y &= {\bf \eta}^{\top}{\bf L}_{0}{\bf \eta} + \sigma^2_e\\
%DIFDELCMD < &= \sum_{i=1}^{n_L} l_{0_{ii}}\eta^2_{i} + 2\sum\limits_{j \neq i}^{n_L} l_{0_{ij}} \eta_i \eta_j  + \sigma^2_e\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\frac{\partial \mu_y}{\partial p_i} 
&= \eta_i[1 + \kappa_i(q_i - p_i)]
\end{array}\DIFaddend 
\end{equation}


Assuming \DIFaddbegin \DIFadd{that }\DIFaddend all additive genetic variance is genic\DIFdelbegin \DIFdel{, $V_y$  simplifies to }\DIFdelend \DIFaddbegin \DIFadd{:
}\DIFaddend 

\DIFaddbegin \begin{equation}
\DIFadd{\begin{array}{rl}
V_Y &= \sum_{i=1}^{n_L} VAR(y_i) + \sigma^2_e\\
&= \sum_{i=1}^{n_L} (E[y_i^2] - E[y_i]^2) + \sigma^2_e\\
&= \sum_{i=1}^{n_L} [p_i^2\eta_i^2 + 2p_iq_i(1 + \kappa_i)^2 \eta_i^2/4 - \eta_i^2(p_i + p_iq_i\kappa_i)^2] + \sigma^2_e\\
&= \sum_{i=1}^{n_L} [p_iq_i(1 + \kappa_i)^2\eta_i^2/2 - \eta_i^2(2p_i^2q_i\kappa_i + p_i^2q_i^2\kappa_i^2)] + \sigma^2_e\\
&= \sum_{i=1}^{n_L} [\frac{p_iq_i}{2}(1 + \kappa_i)^2\eta_i^2 - \eta_i^2p_i^2q_i\kappa_i(2 + q_i\kappa_i)] + \sigma^2_e
\end{array}
}\end{equation}

\DIFadd{Differentiating with respect to $p_i$:
}

\DIFaddend \begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < V_y
%DIFDELCMD < &= \sum_{i=1}^{n_L} l_{0_{ii}}\eta^2_{i} + \sigma^2_e\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\frac{\partial V_y}{\partial p_i} &= \frac{q_i-p_i}{2}(1 + \kappa_i)^2\eta_i^2 - \\
&\quad \eta_i^2\kappa_i[(2p_iq_i -p_i^2)(2 + \kappa_iq_i) -p_i^2q_i\kappa_i] \\
&= \frac{q_i-p_i}{2}(1 + \kappa_i)^2\eta_i^2 - \\
&\quad p_i\eta_i^2\kappa_i[(2q_i -p_i)(2 + \kappa_iq_i) -p_iq_i\kappa_i] 
\end{array}\DIFaddend 
\end{equation}

\DIFdelbegin \DIFdel{and substituting these expressions for $\mu_y$ and $V_y$ }\DIFdelend \DIFaddbegin \DIFadd{Substituting expressions for $\frac{\partial \mu_y}{\partial p_i}$ and $\frac{\partial V_y}{\partial p_i}$ }\DIFaddend yields:

\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \alpha_i&=\frac{\partial \left(\sum_{i=1}^{n_L}(p_{0_i} \eta_i+l_{0_{ii}}\eta^2_{i}/2) + \sigma^2_e\right)}{\partial p_{0_i}}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\alpha_i&= \eta_i[1 + \kappa_i(q_i - p_i)]  + \\
&\quad \frac{q_i-p_i}{4}(1 + \kappa_i)^2\eta_i^2 - \\
&\quad \frac{p_i\eta_i^2\kappa_i}{2}[(2q_i -p_i)(2 + \kappa_iq_i) -p_iq_i\kappa_i] \\

\end{array}\DIFaddend 
\DIFaddbegin \label{eq:alpha_eta_dominance_LW}
\DIFaddend \end{equation}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Under Hardy-Weinberg Equilibrium $l_{0_{ii}}=p_i(1 - p_i)/2$ and this simplifies to}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{In the parameterisation of \mbox{%DIFAUXCMD
\citet{falconer1996}}\hskip0pt%DIFAUXCMD
, this translates to:
}\DIFaddend \begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{array}{rl}
%DIFDELCMD < \alpha_i&=\frac{\partial \left(\sum_{i=1}^{n_L}(p_{0_i} \eta_i+p_{0_i}(1-p_{0_i})\eta^2_{i}/2) + \sigma^2_e\right)}{\partial p_{0_i}}\\
%DIFDELCMD < &= \eta_i + \frac{1}{4}(1 - 2p_{0_i} )\eta^2_{i}\\
%DIFDELCMD < &= \eta_i - \frac{1}{4}(p_{0_i}-q_{0_i})\eta^2_{i}\\
%DIFDELCMD < \end{array}%%%
\DIFdelend \DIFaddbegin \begin{array}{rl}
\alpha_i&=  \eta_i + d_i(q_i-p_i) + \\
&\quad \frac{q_i-p_i}{4}(\eta_i + d_i)^2 - \\
&\quad \frac{d_ip_i}{2}[(2q_i - p_i)(2\eta_i + q_id_i) -  p_iq_id_i] \\

\end{array}\DIFaddend 
\DIFaddbegin \label{eq:alpha_eta_dominance_FM}
\DIFaddend \end{equation}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Note $\frac{1}{4}\eta^2$ is the quantitative genetic dominance deviation, often denoted $d$}\DIFdelend \DIFaddbegin \DIFadd{Note that as a first approximation Equations \ref{eq:alpha_eta_dominance_FM}  and \ref{eq:alpha_eta_dominance_LW} reduce to the classical quantitative genetic expressions for the average effect of gene substitution (Equation 7.5 in \mbox{%DIFAUXCMD
\citet{falconer1996} }\hskip0pt%DIFAUXCMD
and Equation 4.10b in \mbox{%DIFAUXCMD
\citet{lynch1998}}\hskip0pt%DIFAUXCMD
)}\DIFaddend . 

In order to calculate $N_E$ under this multinomial log-linear model we need to know the variance in offspring number $V_o$ \DIFdelbegin \DIFdel{in the presence of environmental variance in fitness only}\DIFdelend \DIFaddbegin \DIFadd{caused by any environmental or non-additive genetic variance}\DIFaddend .  Then $N_E=4N/(2+V_o)$ where $N$ is the census population size \citep{Wright.1938}. The expected number of offspring for parent $k$ is $2N_{t+1}p_k$, as given above, and  the variance in the number offspring is $2N_{t+1}p_k(1-p_k)$. From the the law of total variance $V_o = 4N^2_{t+1}Var(p)+2N_{t+1}E[p(1-p)]$.  Since $E[p(1-p)]=E[p]-E[p^2]$ and $Var(p)=E[p^2]-E[p]^2$ then $E[p(1-p)]=E[p]-Var(p)+E[p]^2$. Since $E[p] = 1/N_{t}$ by definition, 


\begin{equation}
\begin{array}{rl}
V_o =& 4N^2_{t+1}Var(p)+2N_{t+1}E[p(1-p)]\\
       =& 4N^2_{t+1}Var(p)+\frac{2N_{t+1}}{N_t}-2N_{t+1}Var(p)+\frac{2N_{t+1}}{N^2_t}\\
       =& (4N^2_{t+1}-2N_{t+1})Var(p)+\frac{2N_{t+1}}{N_t}+\frac{2N_{t+1}}{N^2_t}\\
\end{array}
\label{Eq:vo}
\end{equation}

From the properties of the log-normal (with zero mean) we know $E[P] = exp(\sigma_e^2/2)$ and $Var(P) = (exp(\sigma_e^2)-1)exp(\sigma_e^2)$. Since $p = P/(N_tE[P])$

\begin{equation}
\begin{array}{rl}
Var(p) =& Var(P)/(N_tE[P])^2\\
=&(exp(\sigma_e^2)-1)exp(\sigma_e^2)/(N_texp((\sigma_e^2)/2))^2\\
       =& (exp(\sigma_e^2)-1)exp(\sigma_e^2)/(N_t^2exp(\sigma_e^2))\\
       =& (exp(\sigma_e^2)-1)/N_t^2\\
\end{array}
\end{equation}

If $N_{t+1}$ and $N_t$ are large then Equation \ref{Eq:vo} simplifies to

\begin{equation}
V_o = 4N^2_{t+1}Var(p)+2N_{t+1}/N_t
\end{equation}

such that 

\begin{equation}
V_o = (4N^2_{t+1}/N^2_t)(exp(\sigma^2_e)-1)+2N_{t+1}/N_t
\end{equation}

If the population size is constant then this simplifies to $V_o = 4exp(\sigma^2_e)-2$ and the variance effective population size, $N_{E_t}$, is $4N_t/(2+V_o)=N_t/exp(\sigma^2_e)$. \DIFaddbegin \DIFadd{Note however, that in these expressions using $\sigma^2_e$ only assumes the non-additive genetic variance is zero. When non-additive genetic variance is present (which there will be to a small degree even with additivity on the log-scale) $V_o$ will be greater than predicted here and $N_E$ will be consequently smaller.
}\DIFaddend 


\section{\DIFdelbegin \DIFdel{Supplementary Figures}\DIFdelend \DIFaddbegin \DIFadd{Workflow for implementing the method}\DIFaddend }
\DIFaddbegin \label{App:workflow}
\DIFaddend 

\DIFaddbegin \begin{longtable}{|p{15cm}|}
\hline
\textbf{\DIFadd{Box 1. General workflow of the method}}\\
\hline
\DIFadd{We use genome-wide allele frequency change data ($\Delta {\bf p}$) from independent evolutionary replicates derived from the same ancestral base population with a known linkage structure ($\textbf{L}_0$) to infer the mean ($\boldsymbol{\mu}_{\bar{\alpha}}$) and the variance (${\bf V}_{\bar{\alpha}}$) of the distribution of average effects for fitness. Our goal is to then estimate an expectation for the additive genetic variance for relative fitness by averaging over the distribution of average effects; i.e. $E[V_{\bar A}(0)] = Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}$. We use simple, yet biologically sensible models, $\boldsymbol{\mu}_{\bar{\alpha}} = \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})$ and ${\bf V}_{\bar{\alpha}}=\sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}$, which essentially allows the average effect for fitness at a site to depend on allele frequency and genetic diversity. This model can be readily implemented as a linear mixed model for suitably projected allele frequency change treating locus effects as random (see below). This, effectively, allows us to partition the total allele frequency change into a component caused by predictable responses to direct and indirect selection (modelled using the random effects of locus) and a component caused by unpredictable responses to selection as well as genetic drift (absorbed by the model residuals).}\\
\hline
\textbf{\DIFadd{Experimental design and data}}\DIFadd{:}\\
\DIFadd{A typical experimental design permitting the implementation of our method would involve a base populations of $N_0$ individuals which are sequenced individually. A number of independent evolutionary replicate populations derived from the base populations are then allowed to evolve between generations $t$ and $\tau$ after the base population. If the replicate populations are derived from the base population after just a single round of reproduction $t$ would be 1. }\\
\DIFadd{The following data are compiled from the experiment: }\\ 
\DIFadd{$\bf{C}_{g,0}$: A matrix with $2N_0$ rows and $n_L$ columns indicating the presence or absence (1 or 0) at each of the $n_L$ segregating sites in each of the $2N_0$ gametic contributions in the base population. If phased genomes are unavailable, the $N_0 \times n_L$ matrix of the proportions of the copies of the (arbitrarily chosen) reference allele at each locus in each individual ($\bf{C}_0$) may be used. }\\
\DIFadd{$\Delta {\bf p}_{m}$: For each replicate $m$, a vector representing allele frequency change at each segregating locus between generations $t$ and $\tau$ after the base populations. $t$ and $\tau$ must be known. }\\
\DIFadd{${\bf R}_{-}$: An $n_L \times n_L$ matrix with 1's on the diagonal and the probabilities of non-recombination between pairs of sites as off-diagonal elements. A recombination map, if available, may be used to construct this matrix.}\\
\hline
\textbf{\DIFadd{Step 1: Compute}} \DIFadd{${\bf L}_0$, ${\bf L}_0^{'}$, ${\bf L}_0^{''}$, and $\tilde{\bf L}_{0}$  }\\
\DIFadd{First, we compute the covariance of $\bf{C_0}$ over individuals to obtain ${\bf L}_0$, and the covariance of $\bf{C_{g,0}}$ over gametic contributions to obtain the matrix of gametic phase disequilibria (${\bf L}_0^{'}$).  The matrix of the non-gametic phase disequilibria (${\bf L}_0^{''}$) is then given by ${\bf L}_0 - {\bf L}_0^{'}$ allowing us to compute $\tilde{\bf L}_{0}$ as a weighted sum of ${\bf L}^{'}_{0}$ and ${\bf L}_0^{''}$, with the the $ij^{th}$ element of the latter being weighted by $r_{ij}/(1-r_{ij})$, where $r_{ij}$ is the probability of recombination  between the two loci. If phased genomes are unavailable, $\tilde{\bf L}_{0}$ may be set to ${\bf L}_0$ which assumes that the non-gametic phase disequilibria are negligible. }\\
\hline
\textbf{\DIFadd{Step 2: Compute the predicted}} \DIFadd{${\bf L}$ }\textbf{\DIFadd{in generation $t$ in replicate $m$}} \DIFadd{($\boldsymbol{\mathcal{L}}_{t,m}$) }\\
\DIFadd{Given $\tilde{\bf L}_{0}$ in the base population, the expected ${\bf L}$ in generation $t$ in replicate $m$ under the action of drift and recombination is given by $\boldsymbol{\mathcal{L}}_{t,m} = {\bf N}_{t,m}\circ\tilde{\bf L}_0$, where the $ij^{th}$ element of ${\bf N}_{t,m}$ is $(1-r_{i,j})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$, and  $\circ$ indicates Hadamard (i.e. element-wise) product. We then sum the $\boldsymbol{\mathcal{L}}_{t,m}$'s for all the generations over which $\Delta {\bf p}_{m}$ is measured to obtain $\boldsymbol{\mathcal{L}}_m=\sum_{t=t_m}^{\tau_m-1}\boldsymbol{\mathcal{L}}_{t,m}$. Note that the expected predicable change due to selection between generations $t$ and $\tau$ is $E\left[\Delta {\bf p}_m\right] = \boldsymbol{\mathcal{L}}_m\boldsymbol{\mu}_{\bar{\alpha}}$ and the among-replicate covariance in allele frequency change is $COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})=\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_n$. }\\
\hline
\textbf{\DIFadd{Step 3: Compute drift covariance and the projection matrix}}\\
\DIFadd{Instead of working with raw allele frequency changes, we  work with }\emph{\DIFadd{projected}} \DIFadd{allele frequency changes. The projection matrix ${\bf P}$ is chosen to be such that (1) the number of dimensions of the dataset are reduced to the minimum of $N_0$ and $n_L$ (typically $N_0 << n_L$), and (2) the allele frequency changes due to drift are independent and identically distributed. First, we perform eigen-decomposition of ${\bf L}_0$ (or, equivalently, singular-value decomposition of $\bf{C_0}$) and store the eigenvectors corresponding to non-zero eigenvalues (${\bf U}_{\bf L}$). The (co)variance in allele frequency change due to drift in replicate $m$ is $\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ where ${\bf M}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}$ and the $ij^{th}$ element of ${\bf M}_{t,m}$ is $(1-r_{i,j})/N_{E_{t,m}}$.  We then perform eigen-decomposition of the drift covariance expressed using the eigen-vectors of ${\bf L}_0$, i.e. ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L}$. Let ${\bf U}_2$ be a matrix having the eigenvectors of this ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L}$ as columns, and let ${\bf D}_2$ be a diagonal matrix of square-rooted eigenvalues of this ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L}$. We can then calculate the projection matrix ${\bf P} = {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$, and obtain the projected allele frequency change vector for replicate $m$ as $\Delta\overrightarrow{\bf p}_m = {\bf P}\Delta{\bf p}_m$. Note that the mean and covariance of the projected allele frequency changes due to predictable selection are $E[\Delta \overrightarrow{\bf p}_m] = 
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m
\boldsymbol{\mu}_{\bar{\alpha}}$ and $COV(\Delta \overrightarrow{\bf p}_m, \Delta \overrightarrow{\bf p}_n) = 
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}_{n}$.}\\
\hline
\textbf{\DIFadd{Step 4: Preparing data for model}}\\
\DIFadd{Next, using our models $\boldsymbol{\mu}_{\bar{\alpha}} = \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})$ and ${\bf V}_{\bar{\alpha}}=\sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}$ we calculate the fixed effect covariate ${\bf P}\boldsymbol{\mathcal{L}}_{m}({\bf p}_{0}-{\bf q}_{0})$, and the covariance structure of the locus effects as ${\bf V}_{m,n} \propto {\bf P}\boldsymbol{\mathcal{L}}_m{\bf L}_{0}^{p_{\bar{\alpha}}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}$.}\\
\hline
\textbf{\DIFadd{Step 5: Fit linear mixed models}}\\
\DIFadd{For a given $p_{\bar{\alpha}}$, our goals is to fit a linear mixed model with the projected allele frequency change in all replicates ($\Delta\overrightarrow{\bf p}$) as the response variable and a fixed effect predictor given by ${\bf P}\boldsymbol{\mathcal{L}}_{m}({\bf p}_{0}-{\bf q}_{0})$ with a coefficient $\beta^{(1)}$ to be estimated. We treat locus effects to be random with a covariance structure assumed proportional to ${\bf V}_{m,n} \propto {\bf P}\boldsymbol{\mathcal{L}}_m{\bf L}_{0}^{p_{\bar{\alpha}}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}$, with a proportionality constant $\sigma^2_{\bar{\alpha}}$ to be estimated. We use the R function }\emph{\DIFadd{`optim()'}} \DIFadd{to find $\widehat{p_{\bar{\alpha}}}$ that maximises the conditional likelihood of the above model. We then use $\widehat{p_{\bar{\alpha}}}$, fit the above model, and obtain $\widehat{\beta^{(1)}}$ and $\widehat{\sigma^2_{\bar{\alpha}}}$.}\\  
\hline
\textbf{\DIFadd{Step 6: Estimate}} \DIFadd{$E[V_{\bar A}(0)]$}\\
\DIFadd{The final step is to use the estimates obtained in the previous step ($\widehat{p_{\bar{\alpha}}}$, $\widehat{\beta^{(1)}}$, and $\widehat{\sigma^2_{\bar{\alpha}}}$) to obtain $\widehat{E[V_{\bar A}(0)]} = Tr(\widehat{\textbf{L}_0{\bf V}_{\bar{\alpha}}}) + \widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}}$. We obtain $Tr(\widehat{\textbf{L}_0{\bf V}_{\bar{\alpha}}})$ as $\widehat{\sigma^2_{\bar{\alpha}}}Tr(\textbf{L}_0{\bf L}_{0}^{\widehat{p_{\bar{\alpha}}}})$, and bias corrected $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}}$ as $\widehat{\beta^{(1)}}^2({\bf p}_{0}-{\bf q}_{0})^{\top}{\bf L}_0({\bf p}_{0}-{\bf q}_{0}) - VAR(\widehat{\beta^{(1)}})({\bf p}_{0}-{\bf q}_{0})^{\top}{\bf L}_0({\bf p}_{0}-{\bf q}_{0})$.  }\\

\hline
\end{longtable}


\section{\DIFadd{Supplementary figures}}

\DIFaddend \begin{figure}[H]
\centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.15]{Figures/FigS1.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.15]{Figures/full_ml_eta0.045.jpg}
\DIFaddendFL \caption{Results of full simulations with a burn-in phase of \DIFdelbeginFL \DIFdelFL{25000 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{25,000 }\DIFaddendFL generations (map length in the history phase = 2 morgans, number of replicate populations = 10, population size = \DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1}\DIFaddendFL ,\DIFaddbeginFL \DIFaddFL{000, }\DIFaddendFL number of generations = 3, \DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.045$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the mean of the gamma distribution from which effect sizes for log absolute fitness are sampled for non-neutral mutations ($E[|\eta|]$}\DIFaddendFL ) \DIFaddbeginFL \DIFaddFL{= 0.03, }\DIFaddendFL at different levels of the map length in the history phase (0.5 \DIFdelbeginFL \DIFdelFL{morgans}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{morgan}\DIFaddendFL : \DIFdelbeginFL \DIFdelFL{pink}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{green}\DIFaddendFL , 5 \DIFaddbeginFL \DIFaddFL{morgan: magenta, 50 }\DIFaddendFL morgans: blue, and \DIFdelbeginFL \DIFdelFL{50 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{250 }\DIFaddendFL morgans: grey). The coloured solid lines represent regression lines for estimates of $V_A$ vs true values of $V_A$.}
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure S1}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:full_ml_eta0.045}
\DIFaddendFL \end{figure}


\begin{figure}[p]
\begin{center}
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.11]{Figures/FigS2.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.11]{Figures/lost_va.jpg}
\DIFaddendFL \end{center}
\caption{(\DIFdelbeginFL \DIFdelFL{A}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{a}\DIFaddendFL ) Fraction of the total additive genic variance (\DIFdelbeginFL \DIFdelFL{$V_a(0)$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$V_{\bar a}(0)$}\DIFaddendFL ) lost during the experiment (averaged over all the replicate populations) plotted as a function of \DIFdelbeginFL \DIFdelFL{$\eta_{scale}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the mean of the gamma distribution from which effect sizes for log absolute fitness are sampled for non-neutral mutations ($E[|\eta|]$)}\DIFaddendFL . Each boxplot represents 100 independent simulations \DIFdelbeginFL \DIFdelFL{shown }\DIFdelendFL (for the corresponding level of \DIFdelbeginFL \DIFdelFL{$\eta_{scale}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|]$}\DIFaddendFL ) \DIFaddbeginFL \DIFaddFL{shown }\DIFaddendFL in \DIFdelbeginFL \DIFdelFL{Figure \ref{fig:Figure 4}}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\ref{fig:full_params}}\DIFaddendFL D. (\DIFdelbeginFL \DIFdelFL{B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{b}\DIFaddendFL ) The error on our estimates of $V_A$ plotted versus the total additive genic variance ($V_a$) lost during the experiment (averaged over all the replicate populations) for simulations where the \DIFdelbeginFL \DIFdelFL{non-neutral $\eta_{scale}$ }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|]$ }\DIFaddendFL was either \DIFdelbeginFL \DIFdelFL{0.033 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.02 }\DIFaddendFL (green), \DIFdelbeginFL \DIFdelFL{0.045 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.03 }\DIFaddendFL (blue), or \DIFdelbeginFL \DIFdelFL{0.1 }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.06 }\DIFaddendFL (grey). The solid line has an intercept of 0 and a slope of -1. (\DIFdelbeginFL \DIFdelFL{C}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{c}\DIFaddendFL ) The contribution of each non-neutral locus (averaged over all the replicate populations) to $V_a$ lost during the experiment plotted versus \DIFaddbeginFL \DIFaddFL{the absolute average effect for relative fitness (}\DIFaddendFL $|\alpha|$\DIFaddbeginFL \DIFaddFL{) }\DIFaddendFL for that locus for a simulation with \DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.1$ }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|] = 0.06$ }\DIFaddendFL that had the maximum $V_a$ loss (grey) and a simulation with \DIFdelbeginFL \DIFdelFL{$\eta_{scale} = 0.033$ }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$E[|\eta|] = 0.02$ }\DIFaddendFL that had a comparable true initial $V_A$ but the minimum $V_a$ loss (green) in the experiment. The solid curve represents the additive genic variance lost when a singleton goes extinct. (\DIFdelbeginFL \DIFdelFL{D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{d}\DIFaddendFL ) The total $V_a$ lost at groups of loci classified by dividing $|\alpha|$ into intervals of 0.01 for the simulation with the maximum $V_a$ loss (grey) and the simulation with the minimum $V_a$ loss (green) in the experiment. In the simulation with the maximum $V_A$ loss -- in which the mean $|\alpha|$ for non-neutral \DIFaddbeginFL \DIFaddFL{segregating }\DIFaddendFL loci was 0.0410 -- more than 50\% of the total loss in $V_a$ was driven by just 0.96\% loci whose $|\alpha|$ was greater than 0.3.}
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure S2}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:lost_va}
\DIFaddendFL \end{figure}

% max_va_loss_sim = "Set_15_a_bigwig_2025-03-25_16-11-05.569303_1.52828282828283e-07_0.5_2_1000_10_4_0_0"

% min_va_loss_sim = "Set_9_bigbird_2024-12-26_09-31-27.103756_5.10509090909091e-07_0.5_2_1000_10_4_0_0"

\newpage
\begin{figure}[H]
\centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[scale = 0.15]{Figures/FigS3.jpg}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale = 0.15]{Figures/residual_var_NE.jpg}
\DIFaddendFL \caption{Residual variance in the models analysing the results of full simulations shown in \DIFdelbeginFL \DIFdelFL{Figure \ref{fig:Figure 3} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\ref{fig:full_main} }\DIFaddendFL using either the number of individuals (\DIFdelbeginFL \DIFdelFL{1000}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1,000}\DIFaddendFL ) instead of the $N_E$ or the true $N_E$.}
  \DIFdelbeginFL %DIFDELCMD < \label{fig:Figure S3}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{fig:residual_var_NE}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/full_dominance_sprinkled.jpg}
\caption{\DIFaddFL{Results of full simulations  (map lengths in the history phase = 0.5 morgans and experiment phase = 2 morgans, number of replicate populations = 10, population size = 1,000, number of generations = 3, the mean of the gamma distribution from which effect sizes for log absolute fitness are sampled for non-neutral mutations ($E[|\eta|]$) = 0.03), in which dominance effects were switched on only in the experiment phase using different degrees of dominance: $|\kappa|$ = 0 (green), $|\kappa|$ = 0.5 (blue), and $|\kappa|$ = 0.9 (grey). (a) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. The inference of $V_A$ was obtained by modelling the mean and the (co)variance of the average effects for relative fitness as $\boldsymbol{\mu}_{\bar{\alpha}} = \beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})$ and ${\bf V}_{\bar{\alpha}}=\sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}$, respectively.   (b)-(d) Histograms of the estimates of $p_{\bar \alpha} $, $\beta^{(1)}_{\bar{\alpha}}$, and the residual variance, respectively. The horizontal dashed lines indicate null expectations (0 for $p_{\bar \alpha} $ and $\beta^{(1)}_{\bar{\alpha}}$, and 1 for the residual variance).}}
  \label{fig:full_dominance_sprinkled}
\end{figure}

\newpage

\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/full_dominance_vA_va.jpg}
\caption{\DIFaddFL{The true additive genetic variance for relative fitness ($V_A$) plotted versus the true additive genic variance for relative fitness ($V_a$) in full simulations with a burn-in phase of 25,000 generations performed using a map length in the history phase equal to either 0.5 morgan (a) or 5 morgans (b) with dominance effects switched on in the last 5,000 generations of the history phase. Three different degrees of dominance were used: $|\kappa| = 0$ (green), $\kappa = 0.5$ (blue), and $\kappa = 0.75$ (magenta). The mean of the gamma distribution from which effect sizes for log absolute fitness are sampled for non-neutral mutations ($E[|\eta|]$) was 0.03. The solid black lines indicates the 1:1 line. The coloured lines represent regression lines for true $V_A$ vs true true $V_a$. }}
  \label{fig:full_dominance_vA_va}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/poolseq_full.jpg}
\caption{\DIFaddFL{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for the full simulations with a burn-in phase of 25,000 generations (map length in the history phase = 0.5 morgan, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1,000, number of generations = 3, the mean of the gamma distribution from which effect sizes for log absolute fitness were sampled for non-neutral mutations ($E[|\eta|]$) = 0.02, and no dominance (i.e. $\kappa$ = 0)) using either exact allele frequencies in the experiment phase (green), or allele frequencies in the experiment phase obtained via simulated pool-seq implemented using three different levels of coverage (expected number of reads mapping a segregating site: 1000x (magenta), 500x (blue), and 100x (grey)) without any overdispersion in the number of reads mapping to an individual, as well as estimates obtained from simulated pool-seq implemented at 1000x coverage with overdispersion in the number of reads mapping to an individual (orange). Reads were modelled to be 37 base-pairs long. The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. Estimates of $V_A$ were obtained by incorporating the expected covariance structure due to pool-seq sampling in the models.}}
  \label{fig:poolseq_full}
\DIFaddendFL \end{figure}

\putbib
\end{bibunit}




%\printbibliography

\end{document}
