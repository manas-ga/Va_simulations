\documentclass[12pt]{article}
\usepackage{authblk}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage[sectionbib]{bibunits}
\defaultbibliographystyle{genetics} 
\defaultbibliography{Vw} 
\usepackage[round]{natbib}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{nameref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{lineno}
\usepackage{caption}
\usepackage{lscape}
\usepackage{geometry}
\usepackage{longtable}
\usepackage{float}  % for captionof
\linenumbers
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    pdfpagemode=FullScreen,
}
\hypersetup{linktocpage}
\renewcommand\contentsname{}


\title{\textbf{Estimating the additive genetic variance for relative fitness from changes in allele frequency}}
%\author{Manas Geeta Arun, Aidan Angus-Henry, Darren J. Obbard\\ \& Jarrod D. Hadfield}

\author[1]{Manas Geeta Arun\thanks{Corresponding author: manas.geetaarun@ed.ac.uk}}
\author[1,2]{Aidan Angus-Henry}
\author[1]{Darren J. Obbard}
\author[1]{Jarrod D. Hadfield}

\affil[1]{Institute of Ecology and Evolution, The University of Edinburgh, Ashworth Laboratories Charlotte Auerbach Road, Edinburgh, EH9 3FL, United Kingdom.}

\affil[2]{Charité - Universitätsmedizin Berlin, Charitéplatz 1, 10117 Berlin, Germany.}

\date{}



\begin{document}

\begin{bibunit}
\maketitle
%\tableofcontents
\section*{Running head}
Estimating heritable variance in fitness
\section*{Keywords}
Fisher’s Fundamental Theorem of Natural Selection, rate of adaptation, quantitative genetics, evolve and resequence.

\clearpage

\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

The rate of adaptation is equal to the additive genetic variance for relative fitness ($V_A$) in the population. Estimating $V_A$ typically involves measuring fitness proxies on a large number of individuals from a known pedigree. Such data are hard to collect and the results are often sensitive to the definition of fitness used. Here, we present a new method for estimating $V_A$ that does not involve making measurements of fitness proxies on individuals, but instead tracks changes in the genetic composition of the population. First, we show that $V_A$ can readily be expressed as a function of the genome-wide diversity/linkage disequilibrium matrix and genome-wide expected change in allele frequency due to selection. We then show how independent experimental replicates can be used to infer the expected change in allele frequency due to selection and then estimate $V_A$ via a linear mixed model. Finally, using individual-based simulations, we demonstrate that our approach yields precise and unbiased estimates over a range of biologically plausible levels of $V_A$. 

\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

Despite its simplicity, the fundamental theorem of natural selection (FTNS) \citep{fisher1930genetical,fisher1958genetical} is arguably one of the most central results in evolutionary biology, providing a concise mathematical statement of how quickly a population is expected to adapt. It describes the per generation gain in the mean fitness of a population as a result of natural selection, assuming the `environment' (including variables intrinsic to the population, such as density or allele frequencies) are held constant \citep{ewens1989interpretation, Frank.1992}. The crucial insight the FTNS provides is that the rate of this increase in mean fitness is exactly equal to the additive genetic variance for relative fitness ($V_A$) in the population \citep{burt1995evolution, grafen2015biological}. Consequently, estimating $V_A$ is one of the `\emph{holy grails}' of evolutionary genetics  \citep{walsh2022full}, despite the FTNS being criticised for its inability to predict the actual gain in mean fitness \citep{price1972fisher, ewens1989interpretation, ewens2024fundamental}. 

A number of attempts have been made to measure $V_A$ in wild populations. Typically, these have involved long term studies on natural populations in which the lifetime reproductive success of a large number of individuals has been measured. Combining these fitness data with information on the relatedness among individuals in a (generalised) linear mixed model approach yields estimates of $V_A$ \citep{kruuk2004estimating}. This is far from straightforward in natural populations, as it can be notoriously difficult to tease apart additive genetic effects from common environmental effects, such as parental effects \citep{kruuk2007separate, shaw2014quantitative}. In addition, wild study systems are rarely closed, meaning emigration can be misinterpreted as mortality and offspring sired outside the study area can be overlooked. Furthermore, many studies on wild populations lack genetic pedigrees, and as a consequence may miss substantial fitness variation acquired through undetected polygamy \citep{vedder2011polygyny, charmantier2006testing}. In addition to these biases, estimates from wild populations also tend to come with considerable uncertainty. \citet{burt1995evolution} reviewed studies estimating $V_A$ in 3 species of plants and 3 species of animals, and found that most estimates of $V_A$ were not significantly different from 0. They argued that the upper bound for estimates of $V_A$ could be as high as 0.3, but most likely less than 0.1. Consistent with this, and using a larger data set, \citet{hendry2018contemporary} reported that estimates of $V_A$ varied between 0 and 0.85, with the vast majority of estimates (73\%) being less than 0.2. Overall, the mean $\widehat{V_A}$ across studies was 0.08. In a recent meta-analysis, \citet{bonnet2022genetic} applied Bayesian quantitative genetic methods to data obtained from 19 long term studies on wild vertebrate populations. They reported a meta-analytic mean $V_A$ of 0.185 across studies, considerably higher than those obtained by \citet{burt1995evolution} and \citet{hendry2018contemporary}. Surprisingly, estimates of $V_A$ in populations of Spotted Hyenas (\emph{Crocuta crocuta}), as well as two of the three populations of Blue Tits (\emph{Cyanistes caeruleus}) were higher than 0.4. This is a remarkable finding, since it suggests that growth rates in these populations should increase nearly 1.5 fold every generation due to selection, provided the environment remains constant. All three meta-analyses investigating $V_A$ \citep{burt1995evolution,hendry2018contemporary,bonnet2022genetic} have detected substantial variability between study systems in their estimates of $V_A$. Although most of this variability will be sampling error, the best estimate suggests the variability in actual $V_A$ across populations is also large with a standard deviation of 0.11, although there is substantial uncertainty about its exact value (95\% credible intervals: 0.01--0.26) \citep{bonnet2022genetic}.  

Measuring $V_A$ in the laboratory is considerably more straightforward, and involves either quantitative genetic breeding designs such as the full-sib half-sib design \citep{falconer1996,lynch1998}, or experimental techniques such as hemiclonal analysis \citep{abbott2011obtaining}. While the controlled environment of the laboratory can, to a large extent, help overcome some of the challenges faced by field studies, laboratory environments often lack important features that are likely to generate fitness variation, such as parasites, predators and competitors. Therefore, it is not entirely clear if laboratory estimates of $V_A$ are particularly relevant. Furthermore, many laboratory studies standardise their fitness measurements in a way that makes it hard to infer estimates of $V_A$ (eg. \citet{ruzicka2019genome})  or work with absolute fitness but then fail to report $V_A$ (eg. \citet{singh2023investigation}). However, these studies do suggest that genetic variance for fitness is likely highly dependent on the specific environment in which fitness is assayed (eg. \citet{punzalan2014comparing}). In one of the few laboratory studies that estimated the genetic variance for \emph{relative} fitness,  \citet{martinossi2018consequences} reported estimates from isofemale lines of the bean beetle, \emph{Acanthoscelides obtectus}, that were highly sensitive to evolutionary history, assay environment, and sex, being higher in males (0.13-0.42) than in females (0.013-0.056).  

A common difficulty for current field and laboratory approaches is that, while Darwinian fitness is a deceptively intuitive concept, there is little consensus on its precise definition. In fact, it has been argued that the appropriate definition of fitness can vary depending on the context \citep{hendry2018contemporary}. In the absence of a universal definition, empiricists can only measure proxies of fitness, and it is reasonable to assume that estimates of $V_A$ are likely to be sensitive to the fitness proxy used. A useful illustration of this point is provided by two studies that estimated $V_A$ in a wild population of Red Deer (\emph{Cervus elaphus}), using largely overlapping datasets, but markedly different definitions of fitness \citep{kruuk2000heritability, foerster2007sexually}. \citet{kruuk2000heritability} defined fitness as the total number of progeny produced by an individual in its lifetime and estimated $V_A$ to be 0.1, whereas \cite{foerster2007sexually} employed an alternative definition of fitness that measured an individual’s contribution to population growth \citep{coulson2006estimating} and obtained the appreciably higher estimate of 0.64. 

Some of the definitional difficulties of measuring $V_A$ can be overcome by measuring $V_A$ as the rate of adaptation, rather than comparing the fitness proxies of relatives. One of the earliest attempts to explore this idea was made by \citet{fowler1997genetic} (also see \citet{gardner2005genetic}) in laboratory populations of \emph{Drosophila melanogaster}. Using balancer chromosomes  that allow recombination to be suppressed on the third chromosome, \citet{fowler1997genetic} could track the frequency trajectories of newly introduced wild-type third chromosomes over the course of 43 weeks. By modeling fitness using genotype frequency data for a number of different wild-type third chromosomes  \citep{barton2000measuring}, they demonstrated the presence of substantial $V_A$ on the third chromosome. More recently, in a landmark study, \citet{buffalo2019linked} developed a method to estimate the amount of genome-wide allele frequency change that can be attributed to selection.  The linchpin of their theory is the idea that linked selection induces across-generation covariances in allele frequency change at neutral loci, since associations between these neutral loci and their respective non-neutral backgrounds persist across generations. This new theoretical framework has the potential to pave the way for a powerful empirical tool to detect genomic signatures of linked selection \citep{Buffalo.2020, simon2024contribution}. Of particular relevance here, \citet{buffalo2019linked} also show that their method can be used to obtain estimates of $V_A$, albeit under some potentially restrictive assumptions.

In this study, we present an alternative theoretical framework that relates $V_A$ to genome-wide changes in allele-frequency. Using mathematical identities only, we show how $V_A$ can be obtained from an initial linkage disequilibrium (LD) matrix and expected changes in allele frequency due to selection, without making any assumptions about patterns of gene action or the relationships between genotype fitnesses and genotype frequencies. Our approach, like that of \citet{buffalo2019linked}, relies on temporal genomic data and does not necessitate measuring fitness in individuals. However, in contrast to the `bottom-up' population genetic approach of \citet{buffalo2019linked}, we use a `top-down' quantitative genetic approach which simplifies and generalises some aspects of the problem.

Our aim here is three-fold. First, we derive our central theoretical result from first principles. Second, we develop the statistical machinery required to apply our result to real biological data, and validate it with individual based simulations. Third, we make a detailed comparison of our method with that of \citet{buffalo2019linked}.

\section*{Materials and Method}
\addcontentsline{toc}{section}{Materials and Method}

\subsection*{Outline of the theory}
\addcontentsline{toc}{subsection}{Outline of the theory}

Table \ref{tab:notation} summarises the notation used in the following text. We consider a population consisting of $N$ diploid individuals. We assume that there are $n_L$ segregating biallelic loci in the population. Let $c_{k,i}$ and $\alpha_i$ represent the proportion of copies of an arbitrarily chosen reference allele at locus $i$ in individual $k$ and Fisher's average effect \citep{Fisher.1941} for fitness at locus $i$, respectively. The widely accepted mathematical definition of the $\alpha$'s are the regression coefficients obtained from a multiple regression of the $c$'s on relative fitness, $w$ \citep{Fisher.1941, Lee.2013}. The vector $\boldsymbol{{\alpha}}$ can be expressed as

\begin{equation} \label{eq1}
\begin{array}{rl} 
\boldsymbol{{\alpha}} &= \textbf{L}^{-1}Cov(\textbf{c}, w) 
\end{array}
\end{equation}
where $\textbf{c}$ is the vector of predictors representing the $c$'s at all loci for an individual and $\textbf{L}$ is a symmetric ${n_L} \times {n_L}$ matrix whose $i^{th}$ (diagonal) element is the variance in the $c$'s at locus i computed over individuals, while the  $ij^{th}$ (off-diagonal) element describes the covariance between the $c$'s at locus $i$ and locus $j$ computed over individuals. 

The breeding value for the relative fitness of individual $k$ is then

$$u_k = {\bf c}^{\top}_{k}\boldsymbol{{\alpha}}$$


and the additive genetic variance for relative fitness is the variance of this quantity across individuals:

\begin{equation} \label{eq2}
\begin{array}{rl} 
{V_A} &= Var({\bf c}^{\top}\boldsymbol{{\alpha}}) \\ 
&= \boldsymbol{{\alpha}}^{\top}Var({\bf c}, {\bf c}^{\top})\boldsymbol{{\alpha}}\\ 
&= \boldsymbol{\alpha}^{\top}\textbf{L}\boldsymbol{\alpha}\\
\end{array}
\end{equation}
This follows from the fact that at any given point in time, $\alpha$'s are constant across individuals. In the absence of mutation and meiotic drive, the allele frequency in parents is transmitted to offspring without bias, such that the vector of expected change in allele frequencies due to selection can be expressed as Robertson's covariance \citep{robertson1966mathematical, price1970selection, queller2017fundamental}:

\begin{equation} \label{eq3}
\begin{array}{rl}
E[\Delta{\textbf{p}}] &= E[\Delta\bar{{\textbf{c}}}]\\
&= Cov(\textbf{c}, w)
\end{array}
\end{equation}

Substituting Equation \ref{eq1} into Equation \ref{eq3} gives $E[\Delta{\textbf{p}}] = {\bf L}\boldsymbol{\alpha}$, which is the multivariate analogue of Equation 10 in \citet{Kirkpatrick.2002}. Combining this with Equation \ref{eq2} yields,

\begin{equation} \label{eq4}
\begin{array}{rl}
{V_A} &= \left({\textbf{L}^{-1}E[\Delta{\textbf{p}}]}\right)^{\top}{\textbf{L}}\left({\textbf{L}^{-1}E[\Delta{\textbf{p}}]}\right)\\
&= E[\Delta{\textbf{p}}]^{\top}{\textbf{L}^{-1}}E[\Delta{\textbf{p}}]
\end{array}
\end{equation}

Equation \ref{eq4} is a general result and involves no assumptions about the patterns of dominance or epistasis for fitness, or about patterns of mating. An intuitive explanation of why $V_A$ can be calculated this way is to note Fisher's Fundamental Theorem states that ${V_A}$ is equal to the (partial) increase in mean fitness caused by evolutionary change through natural selection. Equation \ref{eq2} can be expressed as a sum of $\alpha_i E[\Delta p_i]$ over all loci, $i$:

\begin{equation} \label{eq2b}
\begin{array}{rl}
{V_A} &= \boldsymbol{\alpha}^{\top}E[\Delta{\textbf{p}}]
\end{array}
\end{equation}

In this,  $\alpha$ represents the proportional change in the population mean fitness that is caused by a unit change in allele frequency at a locus \citep{Fisher.1941, Kojima.1959, Lee.2013}. Therefore, multiplying $\alpha$ by the actual change caused by natural selection, $E[\Delta p]$, we get the proportional change in mean fitness caused by evolutionary change by natural selection at that locus. If we then add these changes at every locus in the genome, we obtain the total proportional change in mean fitness due to evolutionary change by natural selection, and hence $V_A$.  



\subsection*{Extending our approach to practical situations}
\addcontentsline{toc}{subsection}{Extending our approach}


Our theoretical approach assumes $\boldsymbol{\alpha}$ or $E[\Delta {\bf p}]$ are known. In reality, neither can be directly observed and must be inferred from data on observed allele frequency change, $\Delta {\bf p}$. Since $\Delta {\bf p}$ will vary around $E[\Delta {\bf p}]$ due to genetic drift, $E[\Delta {\bf p}]$ must be inferred using replicate observations of $\Delta {\bf p}$. Since time cannot be replayed, we infer $E[\Delta {\bf p}]$ through experimental replicates (see \citet{Buffalo.2020} also). Our theoretical model also assumes ${\bf L}$ is known, but since it is hard to generate experimental replicates without at least one round of reproduction, we condition on ${\bf L}_{0}$ (${\bf L}$ in a generation prior to the first generation over which allele frequency change is measured). In what follows we will refer to the population at time zero (generation 0) as the `base population'. Our aim is then to estimate an additive genetic variance for fitness in the base population, $V_A(0)=\bar{\boldsymbol{\alpha}}^{\top}{\bf L}_0\bar{\boldsymbol{\alpha}}$, where $\bar{\boldsymbol{\alpha}}$ is the vector of mean average effects across time and replicates. \\

We also allow allele frequency changes to be measured over multiple generations, rather than a single generation. Thus, $\Delta {\bf p}_m = \Delta {\bf p}_{t_m,m}+\Delta {\bf p}_{t_m+1,m}\dots\Delta {\bf p}_{\tau_m-1,m}$ is the observed change in allele frequency from generation $t_m$ to $\tau_m$ in replicate $m$, with $\Delta {\bf p}_{t,m}$ being the change from time $t$ to $t+1$. Note that $t_m$ (i.e. the generation in which we start recording allele frequency changes) can be any positive integer. If replicate populations are derived from the base population with exactly one round of reproduction, $t_m$ would be 1. $\tau_m$ can be any integer greater than $t_m$. We first note that the total change in allele frequency in replicate $m$ between times $t_m$ and $\tau_m$ is

\begin{equation}
\Delta {\bf p}_{m} = \sum^{\tau_m-1}_{t=t_m}\left({\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t,m}\right)
\end{equation}

where ${\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}=E[\Delta{\bf p}_{t,m}]$ is the expected change in allele frequency due to selection in replicate $m$ between generation $t$ and $t+1$ and $\underset{D}\Delta {\bf p}_{t,m}$ is the change due to drift. It is important to note that ${\bf L}_{t,m}\boldsymbol{\alpha}_{t,m}$ captures responses to both direct and indirect selection. ${\bf L}$ will vary over time and we decompose ${\bf L}$ at a particular time into a part that can be predicted by ${\bf L}_0$ and the action of drift and recombination, and a part that cannot be predicted. To do this we decompose  ${\bf L}$ into ${\bf L}^{'}$ and ${\bf L}^{''}$, following the notation of \citet{buffalo2019linked}. ${\bf L}^{'}$ represents the (co)variances in the $c$'s computed over the haploid genomes of all $2N$ gametes that constitute the base population. Thus, the diagonal elements of ${\bf L}^{'}$ are proportional to gametic (gene) diversity and the off-diagonals are proportional to gametic-phase disequilibrium. On the other hand, ${\bf L}^{''}$  represents the (co)variances that arise due to alleles within the different gametic contributions of a genotype, and thus the diagonal elements are proportional to the additive coefficients of Hardy-Weinberg disequilibrium (\citet{bulmer1980mathematical} and Chapter 12 in \citet{Weir.1989}), and the off-diagonal elements are proportional to the nongametic-phase disequilibrium. Given this decomposition (See Appendix \ref{Appendix:LD} for details):

\begin{equation}
{\bf L}_{t,m}= {\bf N}_{t,m}\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}
\label{Eq:LD_dynamics}
\end{equation}
where $\circ$ is the Hadamard product, $\tilde{\bf L}_{0}$ is the weighted sum of ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$ , with the $ij^{th}$ element of ${\bf L}^{''}_{0}$ weighted by $r_{i,j}/(1-r_{i,j})$ and ${\bf N}_{t,m}$ is a matrix with the $ij^{th}$ element being $(1-r_{i,j})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$. $r_{i,j}$ is the recombination rate between the two loci and  $N_{e_{k,m}}$ is the effective population size in generation $k$ in replicate $m$. $\Delta {\bf L}^{'}_{t,m}$ is a stochastic term with zero expectation that represents the accumulated change in ${\bf L}^{'}$ between generations 0 and $t$ in replicate $m$ that cannot be predicted. ${\bf L}^{''}_{t,m}$ is the matrix of nongametic-phase disequilbria that arises in generation $t$ in replicate $m$.  In the following, it will be useful to designate $\boldsymbol{\mathcal{L}}_{t,m} = {\bf N}_{t,m}\circ\tilde{\bf L}_0$ as the expected ${\bf L}_{t,m}$, for $t>0$, conditional on ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$. Also, we represent the deviation of ${\bf L}_{t,m}$ from this expectation as $\Delta {\bf L}_{t,m}=\Delta {\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}$. It will also be useful to denote $\boldsymbol{\alpha}_{t,m}=\bar{\boldsymbol{\alpha}}+\Delta\boldsymbol{\alpha}_{t,m}$ where $\Delta\boldsymbol{\alpha}_{t,m}$ is the deviation of the average effects (in generation $t$ in replicate $m$) from the mean of the average effects across time and replicates.  We can then decompose the change due to selection into two terms:

\begin{equation}
\begin{array}{rl}
\Delta {\bf p}_m
=& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
=& \sum_{t=t_m}^{\tau_m-1} \left(\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t, m}+\underset{D}\Delta {\bf p}_{t, m}\right)\\
\end{array}
\label{Eq:dp}
\end{equation}

where the predictable change due to selection is $\boldsymbol{\mathcal{L}}_{t,m}\bar{\boldsymbol{\alpha}}$ and is similar to that derived for a single locus in \citet{Santiago.1998}, and the unpredictable change due to selection caused by stochastic changes in  ${\bf L}$ and/or $\boldsymbol{\alpha}$ is $\underset{U}\Delta {\bf p}_{t,m}=\Delta{\bf L}_{t,m}\bar{\boldsymbol{\alpha}}+\boldsymbol{\mathcal{L}}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}+\Delta{\bf L}_{t,m}\Delta\boldsymbol{\alpha}_{t,m}$. Note that $\underset{D}\Delta {\bf p}$ and $\underset{U}\Delta {\bf p}$ have expectation zero and that the $\underset{D}\Delta {\bf p}$ terms are independent across replicates, generations, and generations within replicates \citep{buffalo2019linked}. The $\underset{U}\Delta {\bf p}$ are never independent across generations within replicates since the $\Delta {\bf L}^{'}$ are sums of changes over all previous generations after generation 0. They may, however, be independent across replicates if each replicate is initiated from individuals independently generated from Generation $0$ individuals (e.g. $t_m=1$ for all $m$).  If replicates are derived from a single population that was derived from generation 0 $t_m-1$ generations before, then the $\Delta {\bf L}$ will be dependent due to the shared changes in ${\bf L}$ from generation $0$ to $t_m-1$. However, even when replicates are independently generated from generation $0$, there may be cases where the $\underset{U}\Delta {\bf p}$ are non-independent between replicates, because of some structure to either the $\Delta {\bf L}^{'}$'s or the $\Delta\boldsymbol{\alpha}$'s. The $\Delta\boldsymbol{\alpha}$'s may be non-independent across replicates, if a selection regime is unique to a time point but experienced by all replicates. The $\Delta {\bf L}$'s may also be non-independent if selection induces correlated changes in ${\bf L}$ across replicates, although here we follow the assumption of the infinitesimal model where such changes are negligible \citep{Barton.2017}, at least for the diagonal elements \citep{Bulmer.1971}. Making $t_m$ as small as possible so that changes in ${\bf L}$ from ${\bf L}_0$ are minimised (i.e. the replicates are initiated using the offspring of the base population such that $t_m=1$) and calculating change in allele frequency over a single generation (i.e. $\tau_m-t_m=1$) will result in the least bias since any change in ${\bf L}$ due to selection should be minimised and the approximations that follow should hold well.  However, although the approximations will hold better when $\tau_m-t_m=1$, increasing  $\tau_m-t_m$ (i.e. calculating change in allele frequency over multiple generations) will increase power since the changes in allele frequency due to selection will be larger.  

Assuming the $\Delta {\bf L}$'s and the $\Delta\boldsymbol{\alpha}$'s are independent across replicates we can then derive the mean and covariance structure of allele frequency change across replicates in terms of the mean ($\boldsymbol{\mu}_{\bar{\alpha}}$) and covariance structure (${\bf V}_{\bar{\alpha}}$) of the mean average effects (Appendix \ref{App:dist}). Note that here we treat the average effects as random variables rather than fixed quantities (See Appendix \ref{App:alpha_random} and \citet{gianola2009additive} for a discussion on what this implies):

\begin{equation}
\begin{array}{rl}
E\left[\Delta {\bf p}_m\right]
=& \boldsymbol{\mathcal{L}}_m\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}
\label{eq:Edelta}
\end{equation}

where $\boldsymbol{\mathcal{L}}_m=\sum_{t=t_m}^{\tau_m-1}\boldsymbol{\mathcal{L}}_{t,m}$. 

The conditional among-replicate covariance is also straightforward

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})
=&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_n\\
\end{array}
\label{eq:covdelta}
\end{equation}

where $m$ and $n$ are a pair of replicates. The within-replicate (co)variances are more challenging to derive,  as not only do they include the predictable response to selection, but also the cumulative effects of drift and the unpredictable response to selection. There is no easy form for the within-replicate (co)variances in the allele frequency change caused by the total impact of the unpredictable response to selection. Here, we simply write the covariance due to the cumulative unpredictable response to selection as $\boldsymbol{\mathcal{U}}_m$, which gives

\begin{equation}
\begin{array}{rl}
VAR\left(\Delta {\bf p}_m\right) =&\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}\boldsymbol{\mathcal{L}}_m+\boldsymbol{\mathcal{D}}_m+\boldsymbol{\mathcal{U}}_m\\
\end{array}
\end{equation}

where $\boldsymbol{\mathcal{D}}_m$ is the covariance due to the cumulative action of drift and is equal to $\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ where ${\bf M}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}$ and the $ij^{th}$ element of ${\bf M}_{t,m}$ is $(1-r_{i,j})/N_{E_{t,m}}$ (Appendix \ref{App:dist}). Note that since the predictable response to selection includes both direct and indirect selection, the relevant effective population size for the drift covariance in allele frequency does not include the effects of linked selection and for this reason we denote it as $N_E$ rather than $N_e$. Using this notation, $N_E=4N/(2+V_o)$ where $N$ is the census population size and $V_o$ is the variance in offspring number in the absence of genetic fitness variation \citep{Wright.1938}. Although the dynamics of ${\bf L}$ (Equation \ref{Eq:LD_dynamics}, also see Appendix \ref{Appendix:LD}) were derived under drift and recombination in the absence of selection, and hence $N_e=N_E$, the dynamical equations for ${\bf L}$ will better approximate reality when an effective population size that incorporates all excess variation in fitness is used. Consequently, we use $N_e$ and $N_E$ to distinguish the effective population sizes that are relevant for stochastic changes in ${\bf L}$ and allele frequency, respectively. It should also be noted that if $VAR(\Delta {\boldsymbol \alpha})$, and hence $\boldsymbol{\mathcal{U}}$, is non-zero then the additive genetic variance exhibited in replicate $m$ at generation $t$ will in general exceed $V_A(0)$. When $VAR(\Delta {\boldsymbol \alpha})$ is non-zero,  we should more generally think of $V_A(0)$ not as the additive genetic variance for fitness in the base population, but the additive genetic covariance in fitness between replicates.

\subsection*{Inference outline}
\addcontentsline{toc}{subsection}{Inference outline}

By applying sum of squares theory \citep[page 355]{searle2006} to Equation \ref{eq2} we can obtain the expected $V_A(0)$ after averaging over the distribution of average effects:
By applying sum of squares theory \citep[page 355]{searle2006} to Equation \ref{eq2} we can obtain the expected $V_A(0)$ after averaging over the distribution of average effects:


\begin{equation} \label{eq6}
\begin{array}{rl}
E[V_A(0)] &= E[\boldsymbol{\bar \alpha}^{\top}\textbf{L}_0\bar{\boldsymbol{\alpha}}]\\
&= Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}
\end{equation}

where we aim to estimate $\boldsymbol{\mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}}$ through Equations \ref{eq:Edelta} and \ref{eq:covdelta} using multiple evolutionary replicates starting from a common base population.

Rather than working with the allele frequency changes directly, we project them on to a new (reduced) basis and denote this new vector of changes as $\Delta\overrightarrow{\bf p} = {\bf P}\Delta{\bf p}$ where ${\bf P}$ is some projection matrix. We chose a projection that collapses allele frequency changes into the non-null subspace of ${\bf L}_{0}$, since $V_A(0)$ only depends on this subspace \citep{de2015genomic}. To do this, let ${\bf U}_{\bf L}$ be the eigenvectors of ${\bf L}_{0}$ with non-zero eigenvalues and then the drift covariance in the reduced subspace is ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L}$. If we have ${\bf U}_2$ and ${\bf D}_2$ as the eigenvectors and a diagonal matrix of square-rooted eigenvalues of this matrix, then the projection matrix ${\bf P} = {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$ results in projected allele frequency changes that are identically and independently distributed under drift in the reduced subspace only (see Appendix \ref{App:projection}).

The mean and covariance of the projected allele frequency changes due to predictable selection are:

\begin{equation} 
\begin{array}{rl}
E[\Delta \overrightarrow{\bf p}_m] = &
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m
\boldsymbol{\mu}_{\bar{\alpha}}
\end{array}
\end{equation}

and 

\begin{equation} 
\begin{array}{rl}
COV(\Delta \overrightarrow{\bf p}_m, \Delta \overrightarrow{\bf p}_n) = &
{\bf P}_{m}\boldsymbol{\mathcal{L}}_m{\bf V}_{\bar{\alpha}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}_{n}
\end{array}
\end{equation}

In Appendix \ref{App:alpha_random} we determine permissible models for $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}$ and ${\bf V}_{\bar{\alpha}}$.  Of those, we identify the sensible biological model for the mean average effect:

\begin{equation} 
\begin{array}{rl}
\boldsymbol{\mu}_{\bar{\alpha}} = & \beta^{(0)}_{\bar{\alpha}}+\beta^{(1)}_{\bar{\alpha}}({\bf p}_{0}-{\bf q}_{0})
\end{array}
\end{equation}
where ${\bf p}_{0}$ is the frequency of the reference alleles at each locus in the base population and ${\bf q}_{0}=1-{\bf p}_{0}$. For the variance of the average effects, we identify the model 

\begin{equation} 
\begin{array}{rl}
{\bf V}_{\bar{\alpha}}=& \sigma^2_{\bar{\alpha}}{\bf L}_{0}^{p_{\bar{\alpha}}}
\end{array}
\end{equation}
although in our analysis of simulated data we set the off-diagonal elements of ${\bf L}_{0}$ to zero in the above equation, such that the variance in average effects is simply a power function of the genetic diversities \citep{zeng2018signatures}. With $p_{\bar{\alpha}}$ known, the model is a linear mixed model with covariance structure due to the predictable response to selection being proportional (by a factor $\sigma^2_{\bar{\alpha}}$ that is to be estimated) to

\begin{equation} 
{\bf V}_{m,n} \propto {\bf P}\boldsymbol{\mathcal{L}}_m{\bf L}_{0}^{p_{\bar{\alpha}}}
\boldsymbol{\mathcal{L}}_n{\bf P}^{\top}
\end{equation}
between replicates $m$ and $n$. When $\boldsymbol{\mathcal{L}}^{(m)}=\boldsymbol{\mathcal{L}}^{(n)}$ for all $n$ and $m$, then this can more easily be fitted by incorporating locus as a random effect with the above covariance structure. The fixed-effect covariate (shown for replicate $m$)

\begin{equation} 
{\bf P}\boldsymbol{\mathcal{L}}^{(m)}({\bf p}_{0}-{\bf q}_{0})
\end{equation}
can also be fitted, with associated coefficient $\beta^{(1)}_{\bar{\alpha}}$ to be estimated in addition to the intercept, $\beta^{(0)}_{\bar{\alpha}}$. 

We estimate the parameters of the model by treating it as a separable linear mixed model problem
\citep{richards1961method}. Conditional on a value of ${p_{\bar{\alpha}}}$ the model is linear mixed model and the conditional (restricted) maximum likelihood can be obtained from asreml \citep{Butler.2023}. In order to maximise the (unconditional) likelihood we use the R function `optim()' to find the value of  ${p_{\bar{\alpha}}}$ that results in the highest conditional likelihood. Note that the residual variance should equal one if there is no unpredictable response to selection. 

Although linear (mixed) models generate unbiased estimates of $\boldsymbol{\mu}_{\bar{\alpha}}$, the quadratic form $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$ will be upwardly biased by sampling error in ${\boldsymbol \beta}_{\bar{\alpha}}$. To correct for this bias, we use the inverse Hessian (conditional on the best estimate of ${p_{\bar{\alpha}}}$) to get an approximate expression for the sampling (co)variance matrix (${\bf S}_{\bar{\alpha}}$) of the two parameters, and use this in order to get an improved estimate of the quadratic form as follows (see Appendix \ref{App:bias_correction}):

\begin{equation} 
\widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}}= \widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}-Tr\left({\bf X}^{\top}{\bf L}_0{\bf X}{\bf S}_{\bar{\alpha}}\right)
\end{equation}
where ${\bf X}$ is the fixed effect design matrix.

\subsection*{Comparison with  \citet{buffalo2019linked}}
\addcontentsline{toc}{subsection}{Comparison to the results of \citet{buffalo2019linked}}


To connect our work with \citet{buffalo2019linked} (henceforth `B\&C') it will be useful to express the covariance matrix  ${\bf L}$ in terms of a diagonal matrix of standard deviations,  ${\bf B}$, (half the square-root of the genetic diversities under random mating) and the correlation matrix, ${\bf R}$, such that  ${\bf L}={\bf B}{\bf R}{\bf B}$. We can then split the response to selection in generation $t$ into two parts:

\begin{equation}
\begin{array}{rrcl}
{\bf L}_t\boldsymbol{\alpha}_t =& {\bf B}_t{\bf B}_t\boldsymbol{\alpha}_t&+&{\bf B}_t({\bf R}_t-{\bf I}){\bf B}_t\boldsymbol{\alpha}_t\\
=&\underset{S}\Delta {\bf p}_t&+&\underset{L}\Delta {\bf p}_t
\end{array}
\end{equation}
where the first term is due to direct selection at the loci, and the second term is due to linkage-disequilibria with other selected loci. It will also be useful to distinguish the additive \textit{genetic} variance ($V_A(t)$) from the additive \textit{genic} variance  ($V_a(t)$) in generation $t$, i.e. :
\begin{equation}
V_A(t) = \boldsymbol{\alpha}_t{\bf L}_t\boldsymbol{\alpha}^{\top}_t
\end{equation}
versus
\begin{equation}
V_a(t) = \boldsymbol{\alpha}_t{\bf B}_t{\bf B}_t\boldsymbol{\alpha}^{\top}_t
\end{equation}
with the distinction being that the additive \emph{genetic} variance ($V_A(t)$) captures the contributions of both genetic diversities at individual loci and the linkage disequilibria between pairs of loci, while the additive \emph{genic} variance ($V_a(t)$) captures the contributions of genetic diversities only.

We can also think about the additive genetic/genic covariance in fitness between time points $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$:

\begin{equation}
C_A(\tau\rightarrow t) = \boldsymbol{\alpha}_{t}{\bf L}_t\boldsymbol{\alpha}^{\top}_{\tau}
\end{equation}

and

\begin{equation}
C_a(\tau\rightarrow t) = \boldsymbol{\alpha}_{t}{\bf B}_t{\bf B}_t\boldsymbol{\alpha}^{\top}_{\tau}
\end{equation}

These will differ from $V_A(t)$ or $V_a(t)$ when the average effects at generation $\tau$ are different from those at generation $t$. This could happen when the selective environment changes between generations $t$ and $\tau$, meaning parameters such as $s$ and $h$ change. The average effects will also change if the genetic composition of the population changes between generations $t$ and $\tau$ (i.e. ${\bf L}_{t}\neq{\bf L}_{\tau}$) and there is non-additivity (e.g. $h\neq0.5$) since the average effects are the coefficients of a multiple regression of the $c$'s on relative fitness (Equation \ref{eq1}).\\

In the theory section above, we assumed ${\bf L}_t$ and $\boldsymbol{\alpha}_t$ were known and so the change due to both direct and linked selection are fixed quantities, as is $V_A(t)$. In contrast, B\&C condition on ${\bf B}_t$ and $\boldsymbol{\alpha}_t$, and treat ${\bf R}_t$ as a random variable. Consequently, in B\&C, the change due to direct selection and $V_a(t)$ are fixed, as in our approach, since genetic diversities and average effects are known. However, the change due to indirect selection and $V_A(t)$ is random since the linkage-disequilibrium is unknown.  In our inference section we acknowledge that $\boldsymbol{\alpha}$ cannot be directly observed, but develop a model for the distribution of $\alpha$'s, where estimates of $V_A(t)$ can be made after marginalising $\boldsymbol{\alpha}$. Similarly, in the approach of B\&C the $\boldsymbol{\alpha}$'s and the elements of ${\bf B}$ for selected sites are also not directly observed, but they make a number of strong assumptions that effectively allow the joint distribution of the average effects and selected site diversities to be marginalised.\\

In Appendix \ref{App:BandC} we work through the derivation of B\&C using our own notation and retaining a full multi-locus treatment. For easy comparison with the present work, here we summarise both the explicit and implicit  assumptions underlying the general approach of B\&C:
 
\begin{itemize}

\item A) Allele frequency changes are only measured over a single generation.

\item B) There is no direct selection on the loci for which allele frequency change is measured.

\item C) The reference allele at a neutral locus is chosen arbitrarily.

\item D) The signed linkage-disequilibrium between selected sites is zero, which precludes processes such as Hill-Robertson interference. Under this assumption $V_A=V_a$.

\item E) Changes in ${\bf R}$ are due to recombination alone - selection and drift are absent. 

\item F) Nongametic-phase linkage disequilibrium is absent.  

\item G)  There is no relationship between the additive genic variation at a selected site and its LD with neutral sites, as measured through $R_{i_t, j_t}R_{i_\tau, j_\tau}$ where $i$ is a neutral locus and $j$ a selected locus. Note that since genetic diversity determines the additive genic variation and LD (even measured as a correlation) is constrained by the genetic diversities at the two loci, this is unlikely to be met \citep{sved2018one}.

\item H) The average effects are constant, i.e. $\boldsymbol{\alpha}_t=\boldsymbol{\alpha}_{\tau}$ if estimates are to be interpreted as the additive genic variance (or additive genetic variance, if Assumption D is met) in generation $\tau$. If they are not constant, it is the additive genic/genetic covariance between generations $t$ and $\tau$ that is measured.  

\item I) The initial expected LD-structure between selected and neutral loci, $E[R_{i_t, j_t}^2]$, is approximated from an expression for $E[L_{i_t, j_t}^2]$, which is itself derived under mutation-recombination-drift balance (i.e. no selection). This assumption is partly relaxed in the appendix by assuming the expected LD-structure between selected and neutral loci is equal to the observed LD-structure between all loci, not distinguishing between selected and neutral loci (Assumption I-b). However, in many cases the genetic diversity at selected loci will be less than that found at (or assumed for) neutral loci and so $E[R_{i_t, j_t}^2]$ will likely be smaller than assumed \citep{sved2018one}.

\item J) The ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ ($\phi_{t,\tau}$), is constant across all selected loci. Under this assumption, dividing the estimate of $V_a(\tau)$ by $\phi_{t,\tau}$ gives an estimate of $V_a(t)$.

\item K) The recombination rate between two sites $g$ base pairs apart is given by $(1 - e^{-2g\bar{r}})/2$ (i.e. Haldane's \citeyearpar{haldane1919map} mapping function) where $\bar{r}$ is the average crossover rate per site per generation. 

\item L) Neutral and selected loci are distributed uniformly and independently across the genome such that the distance between them has a triangular distribution. 

\item M) Since the genetic diversity at selected sites is not measured, it is assumed that $\phi_{t,\tau}$ is equal to the average ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ across all neutral loci.
\end{itemize}

When applying the theory to data, the method of B\&C requires two additional assumptions:

\begin{itemize}

\item Ib) The average LD between selected and neutral sites is equal to the average LD observed between all sites: see Assumption I) above.

\item N) The (co)variance in allele frequency changes divided through by the average genetic diversity is a good approximation for the (co)variance of weighted allele frequency changes where the weights are the inverse of the square root of the genetic diversities. 

\item O) If allele frequencies are estimated from a sample, then the estimation error is binomially distributed.
\end{itemize}

Our approach relaxes most of these assumptions, but not all. Assumption E is only partly relaxed - the change in ${\bf R}$ does not assume a lack of drift but it does assume a lack of selection. We also make Assumption H if we choose to interpret $V_A(0)$ as an additive genetic variance rather than an additive genetic covariance. Assumptions E \& H result in the unpredictable response to selection being zero. While we do not make this assumption, we do assume that the unpredictable responses to selection are independent across replicates. However, when applying the theory to data we assume that the within-replicate (residual) (co)variances are driven by drift only (rather than an unpredictable response to selection) and that the drift (co)variances are equal to their expected values (conditional on ${\bf L}_0$). In reality, the within-replicate covariances are likely larger, due to the unpredictable response to selection and evolutionary variance in the drift (co)variances. These assumptions might not be too severe if these two additional processes result in within-replicate (co)variances that are proportional to those under pure drift. Under this scenario, the model should perform well, although the residual variance may be higher than expected. In addition, in the absence of a recombination map, Assumption K may also be applied in our method, and if ${\bf L}_0$ cannot be partitioned into gametic-phase and nongametic-phase contributions, assumption F might also be made by substituting ${\bf L}_0$ for ${\bf L}^{'}_0$ in $\tilde{\bf L}_0\circ{\bf N}$ and $\tilde{\bf L}_0\circ{\bf M}$. By relaxing some of the more extreme assumptions of B\&C we are instead forced into making assumptions about the mean and covariance structure of the average effects of projected loci when making inferences. 

\subsection*{Multilocus simulations}
\addcontentsline{toc}{subsection}{Multilocus simulations}
To validate our method and inference approach, we performed multilocus simulations using msprime (version 1.2.0) \citep{kelleher2016efficient} and SLiM (version 4.2.2) \citep{haller2023slim}. The code for the simulations and the downstream analyses performed in R (version 4.3.3) is available on GitHub (\url{https://github.com/manas-ga/Va_simulations}) and includes the R library, \texttt{Vw}. We first describe the structure of the simulations in general terms. Towards the end of this section (see `Varying simulation parameters') we discuss the specifics of our parameter choices in the context of the scaling used in the simulations. 

We simulated a single, contiguous 1 million base-pair long genomic region. Our simulations had two distinct phases: the first phase simulated the history of an ancestral population and the second phase simulated a typical evolve and resequence experiment with independent replicate experimental populations derived from a base population drawn from the ancestral population.  

\subsubsection*{Model for fitness}

We used an additive model for log absolute fitness, $log(W)$, as in \citet{buffalo2019linked}. The breeding value of log fitness for individual $k$ is equal to $u_k = \sum_{i=1}^{n_L}{c_{k,i}}{\eta_i}$, where, as before, ${c_{k,i}}$ represents the proportion of copies of the reference allele in individual $k$ at locus $i$, and $\eta_i$ is the (average) effect of the allele on log fitness.  The average effects for (relative) fitness are well approximated by the $\eta$'s when they are small in magnitude, but higher-order approximations are required when the $\eta$'s are large (see Appendix \ref{App:loglinear}).  To obtain the log fitness of each individual we added a noise term drawn from a standard normal distribution (mean = 0, variance = 1) to the breeding value.  The fitness of each individual is then obtained by exponentiating the individual's log fitness.  

We sampled the $\eta$'s from a distribution comprising a weighted mixture of three distributions: (1) a point mass at $\eta = 0$ representing neutral mutations, (2) a reflected gamma distribution with shape = 0.3 and scale = $\eta_{scale}$ (typically 0.033, unless specified otherwise) representing deleterious mutations, and (3) a gamma distribution with shape = 0.3 and scale = $\eta_{scale}$ (typically 0.033, unless specified otherwise) representing beneficial mutations. Thus, for both deleterious and beneficial mutations, the mean absolute $\eta$ (scale $\times$ shape) was, typically, 0.01. The ratio of the frequency of beneficial to deleterious mutations, and $\eta_{scale}$ varied among simulations. Below, we refer to the distribution of non-neutral $\eta$'s (i.e. omitting mixture component (1) described above) as the `distribution of fitness effects' (DFE), but note that this is in fact the distribution of non-zero effects on log fitness.   


\subsubsection*{Phase 1 (`history phase'): Simulating the history of an ancestral population}

We first used a neutral coalescent simulation implemented in msprime \citep{kelleher2016efficient} to construct genealogies for 2,500 diploid genomes (i.e. $N_e$ = 2,500). To initialise a (non-equilibrium) set of selected loci, we then simulated mutations at a rate $\mu_{msp}$, using the pyslim package to attach fitness effects ($\eta$) drawn randomly from the non-neutral part of the distribution described above. Since derived mutations are rare, and the DFE is predominantly deleterious, this will generate a positive relationship between the reference allele frequency and the fitness effects $\eta$'s (and therefore the $\alpha$'s, i.e. the average effects for relative fitness), such that $\beta^{(1)}_{\bar \alpha} >0$ but there should be no relationship between genetic diversities and the $\eta$'s (i.e. $p_{\bar \alpha} = 0$). We implemented the fitness model described above by adapting SLiM's \citep{haller2023slim} default recipe for polygenic selection in the Wright-Fisher mode. To reach mutation-selection-drift balance,  we then let this population of 2,500 individuals evolve forward in time with selection for 25,000 generations (see below for an explanation on the consequence of setting $N_e = 2500$ on other parameter choices). Non-neutral mutations drawn from the same DFE were allowed to occur in this period at a rate given by $\mu_{SLiM}$.  At generation 25,000, as the alleles reach mutation-selection-drift balance, we expect $\beta^{(1)}_{\bar \alpha}$ to have become more positive and $p_{\bar \alpha}$ to have become more negative, better reflecting a real population undergoing selection. 

In generation 25,000, we sampled $N_0$ diploid individuals (typically 1000, unless specified otherwise) from this population, which then go on to become the base population in the next phase of the simulation. At this stage, we generated complete genomes for the $N_0$ individuals in the base population by using pyslim to add neutral mutations to the tree sequence recorded so far. To obtain our target number of loci, $n_L$ (typically 65,000, unless specified otherwise), we set the neutral mutation rate to be $(n_L-n_{L_\mathcal{S}})/g$ where $n_{L_\mathcal{S}}$ is the number of non-neutral segregating sites already present and $g$ is the total branch length of the recorded tree sequence. We recorded the phased genotype of each parent at each locus, allowing  us to construct ${\bf L}_0$ and ${\bf L}^{'}_0$. 

\subsubsection*{Phase 2 (`experiment phase'): Simulating an evolve and resequence experiment}

In the second phase of our simulations, again implemented in SLiM, we first allowed the base population to undergo one round of reproduction without selection to establish replicate experimental populations (typically 10 replicates, unless specified otherwise). Next, we allowed each of these populations to evolve forward in time with selection as in the history phase. We allowed the number of generations in the experiment to be either 1, 3, or 5. Since our goal was to estimate $V_A$ in the base population, we restricted our analyses only to the set of loci segregating in the base population. Any new mutations in subsequent generations would, in all likelihood, occur at loci outside this set.  Therefore, we did not simulate new mutations during the experiment phase. For each of the independent replicate populations, we recorded the genome-wide vector of allele frequencies in each generation of the experiment. 

\subsubsection*{Varying the true levels of $V_A$}

We varied the true (i.e. simulated) levels of $V_A$ in the base population from \textit{ca.} 0.01 to 0.1 by changing the rate of non-neutral mutations in the history phase, implemented in msprime ($\mu_{msp}$) and SLiM ($\mu_{SLiM}$). In simulations with $\eta_{scale} = 0.033$ and no beneficial mutations, we varied $\mu_{msp}$ between $5.56 \times 10^{-9}$ and $5.56 \times 10^{-8}$ and $\mu_{SLiM}$ between $5.56 \times 10^{-7}$ and $5.56 \times 10^{-6}$ (for other scenarios see Table \ref{tab:Table_1}). We set $\mu_{msp}$ to be an order of magnitude smaller than $\mu_{SLiM}$ in most simulations because otherwise all individuals would have had a fitness of zero at the end of the coalescent part of the history phase. This extreme mutation load arises because deleterious alleles, having previously evolved under neutrality, would segregate at fairly high frequencies. However, the choice of $\mu_{msp}$ is  unlikely to significantly affect the composition of the base population in most simulations, since the non-neutral genetic diversity of the base population of the experiment phase was primarily determined by the drift-recombination-mutation-selection equilibrium reached over the course of the 25,000 generation long forward simulation, and therefore primarily dependent on $\mu_{SLiM}$.




\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
        $\eta_{scale}$&$\mu_{ben}:\mu_{del}$ &\textbf{$\mu_{msp}$}  &\textbf{$\mu_{SLiM}$}  & $n_{L_\mathcal{S}}$\\
        \hline
        0.033 & 0 & $5.56\times10^{-8}$ -- $5.56\times10^{-7}$ &$5.56\times10^{-7}$ --  $5.56\times10^{-6}$  & 10058  -- 63755\\
        0.033 & 0.0002 & $5.56\times10^{-8}$ --  $5.56\times10^{-7}$ & $5.56\times10^{-7}$ -- $5.56\times10^{-6}$ & 9742 -- 63797\\
         0.033 & 0.02  & $2.0\times10^{-8}$ -- $2.0\times10^{-7}$ & $2.0\times10^{-7}$ -- $2.0\times10^{-6}$ & 3127 --  29999\\
         0.045 & 0 & $3.6\times10^{-8}$ --  $3.6\times10^{-7}$ & $3.6\times10^{-7}$ --  $3.6\times10^{-6}$ & 6565 --  42097\\
         0.1 & 0 & $1.8\times10^{-8}$ -- $1.6\times10^{-7}$ & $1.8\times10^{-7}$ -- $1.6\times10^{-6}$ & 2998 --  18011 \\
         \hline
    \end{tabular}
    \caption{The ranges for the rates for non-neutral mutations used in the history phase of the full simulations implemented in msprime ($\mu_{msp}$) (the coalescent simulation) and SLiM ($\mu_{SLiM}$) (the forward simulation of the history), along with the ranges for the resulting number of non-neutral sites segregating in the population at the end of the history phase ($n_{L_\mathcal{S}}$) in simulations with different values of the scale ($\eta_{scale}$) of the gamma distribution from which $\eta$'s for non-neutral mutations were sampled, and the ratio of the rate of beneficial mutations to the rate of deleterious mutations in the history phase ($\mu_{ben}:\mu_{del}$). Note that the ranges for the number of selected loci, $n_{L_\mathcal{S}}$, are only shown for the simulations where the map length in the history phase was 0.5 morgans.}
    \label{tab:Table_1}
\end{table}

\subsubsection*{Simplified simulations}

In addition to the full simulations described above, we performed a set of simplified, proof-of-principle simulations to test the logic of our method. These simulations were different from the full simulations in three ways:

(1) The history phase was highly abbreviated -- the forward simulation implemented in SLiM lasted only a single generation without any selection. This meant that the ancestral population -- from which replicate experimental population were founded -- had evolved entirely under neutrality. 

(2) Rather than attach $\eta$'s to the derived alleles generated with msprime, we attached the $\eta$'s randomly with respect to either of the two alleles segregating at the locus. Amendments (1) and (2) generate a scenario where there is no relationship between allele frequency and $\eta$:  both $p_{\bar \alpha}$ and $\beta^{(1)}_{\bar \alpha}$ are expected to be zero.  

(3) Given that the ancestral population had evolved without selection, these simplified simulations had considerably higher genetic diversities compared to the full simulations. This meant that fewer segregating non-neutral sites ($n_{L_\mathcal{S}}$) were required to achieve true levels of $V_A$ between 0.01 and 0.1. Therefore, in these simulations, we set $n_L$ to be 3000, much lower than the 65,000 used for the full simulations. We achieved this by varying $\mu_{msp}$ between $3 \times 10^{-9}$ and $2.35 \times 10^{-8}$. $\mu_{SLiM}$ was set to 0 in these simulations. This resulted in $n_{L_\mathcal{S}}$ at the end of the history phase being between 160 and 1902. We then added neutral mutations using a suitable rate as described above such that $n_L$ was expected to be 3000. 

\subsubsection*{Varying simulation parameters}

Our aim was to investigate the sensitivity of our method to the following parameters: (1) map length in the history phase (0.5 morgans, 5 morgans, 50 morgans, 250 morgans), (2) map length in the experiment phase (0.01 morgans, 0.2 morgans, 2 morgans), (3) number of replicate populations in the experiment phase (3, 5, 10), (4) the population size of each of the replicate populations (100, 500, 1000), (5) number of generations over which allele frequency changes were recorded in the experiment phase (1, 3, 5), (6) the ratio of the rates of beneficial to deleterious mutations (0\%, 0.02 \%, 2\%), and (7) the scale of the DFE, $\eta_{scale}$ (0.033, 0.045, 0.100).

Our final choice of parameter ranges was limited by computational resources. Namely, the requirement for large $n_L \times n_L$ matrices (e.g. ${\bf L}_0$, ${\bf L}^{'}_0$, $\bf M$, and $\bf N$, etc.) imposed an upper bound of around 70,000 on $n_L$ to permit the analysis of simulations in parallel. For full simulations, the number of non-neutral segregating sites ($n_{L_\mathcal{S}}$) was typically smaller than 65,000 (see Table \ref{tab:Table_1}). Therefore, in general, we set $n_L$ to 65,000 in the full simulations. However, as the map length in the history phase increased, $n_{L_\mathcal{S}}$ also increased, presumably as a consequence of the strength of background selection being weakened by greater recombination. For the simulations where $\eta_{scale}$ was 0.033, accommodating all levels of map length in the history phase (up to 250 morgans), would have required us to increase $n_L$ to more than 100000, which was beyond the maximum $n_L$ we could handle. Therefore, for $\eta_{scale} = 0.033$, we restricted ourselves to only those simulations where $n_{L_\mathcal{S}}$ was less than or equal to 65000. When the map length in the history phase was 0.5 morgans, we could analyse simulations in which the true $V_A$ spanned the whole of the target range (0.01 to 0.1). However, for higher map lengths, the analyses we present here do not include simulations where the true $V_A$ was close to the higher end of the target range (see Figure \ref{fig:Figure 4}B).   

Our choices for recombination rates (or map lengths) were dictated by the fact that our simulations were scaled in two ways relative to, say, the global \emph{Drosophila melanogaster} population: (1) in the history phase of our simulations,  we simulate a population of 2,500 individuals, which is 532 times smaller than $1.33 \times 10^6$, the estimate of $N_e$ in \emph{D. melanogaster} \citep{campos2013codon, campos2019effects}, and (2) we assume that all the heritable variation in fitness is limited to a genomic region that is one million base-pairs long - nearly 200 times smaller than the \emph{D. melanogaster} genome. Therefore, the effective crossover rate in \emph{D. melanogaster} would need to be scaled appropriately. We assumed the true effective crossover rate in \emph{D. melanogaster} to be $1 \times 10^{-8}$ per generation per site, which -- to control for the absence of crossovers in males -- is half the standard estimate of female recombination rate in European \emph{D. melanogaster} \citep{wang2023variation} (also see \citet{comeron2012many}). To account for (1), the recombination rate would need to be scaled up by a factor of 532 such that the product of $N_e$ and the recombination rate remains conserved (similar to Table 1 in \citet{campos2019effects}). The map length of the simulated region would then be 5.32 morgans. However, our study focuses on the \textit{total} additive genetic variation for a trait, and therefore, we also need to account for (2). Specifically, since all the sites that code for fitness in our simulations are concentrated in a region that is about 50 times smaller than a typical \emph{D. melanogaster} chromosome, we would need to further scale up the recombination rate 50-fold such that the average number of crossovers between a randomly chosen pair of sites is comparable to a typical \emph{D. melanogaster} chromosome. Under this scaling the map length of the simulated region would then be 266 morgans.

It is important to note that our method relies on linkage disequilibria $D_{ij}$ at the end of the history phase, as well as the crossover rate $r_{ij}$ between pairs of loci during the experiment phase. Accounting only for (1), and using a map length of 5.32 morgans, could in principle lead to reasonable $D_{ij}$'s. However, the $r_{ij}$'s will be considerably lower.  Accounting for both (1) and (2), however, would result in reasonable $r_{ij}$'s but much lower $D_{ij}$'s. Therefore, in our simulations, we try to span this entire range by running simulations with the map length in the history phase chosen to be either 0.5, 5, 50, or 250 morgans. We use a similar logic for choosing recombination rates in the experiment phase. However, our goal in the experiment phase was to simulate an actual population with census size $N_0$ individuals, rather than mimicking the effects of evolution at a global scale with a realistic $N_e$. Therefore, in the experiment phase we do not account for (1). Instead we vary the map length in the experiment phase over a broad range  (0.01 to 2 morgans) that spans both extremes -- having a reasonable crossover rate per site per generation ($1 \times 10^{-8}$) at one end of the simulated parameter range - which translates to a map length of 0.01 morgans - and having a sensible average $r_{ij}$ between pairs of site at the other end of the range, by using a map length comparable to that in \emph{D. melanogaster}.

Rather than vary all parameters in a fully factorial design, we selected a reference parameter set and explored the sensitivity of the method by changing each parameter in turn. The reference parameter set was (1) a map length of 0.5 morgans in the history phase (2) a map length of 2 morgans in the experiment phase, (3) 10 replicate populations in the experiment phase, (4) a population size of 1000 in each of the replicate populations in the experiment phase, (5) 3 generations over which allele frequency changes were recorded in the experiment phase, (6) no beneficial mutations in the history phase, and (7) 0.033 for the scale of the DFE, $\eta_{scale}$. The reference parameter set was chosen to best reflect evolve-and-resequence experiments using \emph{D. melanogaster}. 

For logistical reasons, in the simulations in which we varied the map length in the history phase, we could not span the entire target range for $V_A$ (0.01 to 0.1) when $\eta_{scale}$ was set to its default level of 0.033 (see above). Therefore, we ran an additional set of full simulations in which we varied the map length in the history phase while setting $\eta_{scale}$ to 0.045. In these simulations, even at a map length of 250 morgans, $n_{L_\mathcal{S}}$ seldom exceeded 65,000, allowing us to set $n_L$ to 67,500 for all map lengths.

\subsubsection*{Comparison with B\&C}

To compare the precision and the accuracy of our approach to that of B\&C, we performed additional simplified and full simulations. Although originally designed for the covariance in allele frequency change between multiple time points, B\&C's method can be readily adapted to allele frequency changes recorded over a single generation in multiple independent evolutionary replicates (see Equation \ref{Eq:BCcov13} and \citet{Buffalo.2020}). We set simulation parameters to their reference values (see above) with a few modifications. First, to make comparisons of biases clearer, we reduced noise by employing 50 replicate populations, and second, allele frequency change in the experiment phase was recorded over a single generation. We also ran these simulations at four different levels of map length in the history phase: 0.5 morgans, 5 morgans, 50 morgans, and 100 morgans.

To investigate the consequences of Assumptions B, Ib, and N, we implemented B\&C's method using six different approaches. For clarity, we label the six approaches using a code (see Table \ref{tab:Table_2}) that indicates with superscripts whether an assumption is required (+) or not required (0) for an approach to work. To test Assumption B, we recorded allele frequency changes at either all segregating sites ($B^+$) or neutral sites only ($B^0$). To test Assumption Ib, we used either the average LD between all sites ($Ib^+$) or the average LD between selected sites with neutral sites ($Ib^0$). And finally, we either divided the (co)variance in allele frequency change throughout by twice the average genetic diversity ($N^+$; analogous to Equation 16 in B\&C) or used the (co)variance of weighted allele frequency change, where the weights are the inverse of the square root of twice the genetic diversity ($N^0$).  

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        Approach & $\Delta\textbf{p}$ & Average LD between &  $Cov(\Delta\textbf{p}_m,\Delta\textbf{p}_n)$  \\
         \hline
         $B^+Ib^+N^+$&all sites&all sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^0Ib^+N^+$&neutral sites&all sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^0Ib^0N^+$&neutral sites&selected \& neutral sites&divided throughout by ${(\bar{p}_m\bar{q}_m + \bar{p}_n\bar{q}_n )/2}$\\
         $B^+Ib^+N^0$&all sites&all sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         $B^0Ib^+N^0$&neutral sites&all sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         $B^0Ib^0N^0$&neutral sites&selected \& neutral sites&replaced by $Cov(\Delta\overrightarrow{\textbf{p}_m},\Delta\overrightarrow{\textbf{p}_n})$\\
         \hline
    \end{tabular}
    \caption{We applied B\&C's method to our simulations using six different approaches. The requirement of Assumptions B, Ib, and N is indicated using superscripts ("+" when required and "0" when not required). We used allele frequency change ($\Delta\textbf{p}$) at either all segregating sites (Assumption B required) or at neutral segregating sites only (Assumption B not required). We computed average LD using either the LD between all segregating sites (Assumption Ib required) or the LD between selected and neutral sites (Assumption Ib not required). We used either the (co)variance in $\Delta\textbf{p}$ divided throughout by twice the average genetic diversity (Assumption N required) or the (co)variance in weighted $\Delta\textbf{p}$ (i.e. $\Delta\overrightarrow{\textbf{p}}$) where the weights are the square roots of twice the genetic diversity at each site (Assumption N not required).}
    \label{tab:Table_2}
\end{table}

\section*{Results}
\addcontentsline{toc}{section}{Results}
\subsection*{Simplified simulations}

We begin by discussing results from the simplified simulations in which we expect there to be no relationship between allele frequencies and $\alpha$'s. Under our reference parameter set, our method provided precise and unbiased estimates of $V_A$ throughout the simulated range (0.01-- 0.1) (Figure \ref{fig:Figure 1}A). Furthermore, the estimates of $p_{\bar \alpha} $, $\beta^{(0)}_{\bar{\alpha}}$, and $\beta^{(1)}_{\bar{\alpha}}$ were centred around 0 as expected (Figure \ref{fig:Figure 1}B-D). We next investigated how this relationship between the true and estimated levels of $V_A$ was affected by changing (1) map length of the genomic region being simulated, (2) population size of each replicate population in the evolve and resequence experiment, (3) number of replicate populations, and (4) number of generations over which allele frequency changes were recorded in the experiment. Our estimates of $V_A$ remained unbiased as the map length in the experiment became smaller, although estimates became noisier, particularly at higher values of $V_A$ (Figure \ref{fig:Figure 2}A).  As expected, estimates also became noisier as the number of individuals, replicate populations, or generations became smaller (Figure \ref{fig:Figure 2}B-D). However, estimates appeared upwardly biased when the number of replicate populations or generations was small (Figure \ref{fig:Figure 2}C-D). 

\begin{figure}[H]
\includegraphics[scale = 0.15]{Figures/Fig1.jpg}
\caption{Results of simplified simulations  (map length in the history phase = 0.5 morgans, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1000, number of generations = 3, $\eta_{scale} = 0.033$). (A) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. (B)-(D) Histograms of the estimates of $p_{\bar \alpha} $, $\beta^{(0)}_{\bar{\alpha}}$, and $\beta^{(1)}_{\bar{\alpha}}$, respectively. The vertical red line indicates 0.}
  \label{fig:Figure 1}
\end{figure}

\begin{figure}[H]
\includegraphics[scale = 0.12]{Figures/Fig2.jpg}
\caption{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for simplified simulations at different levels of (A) map length in the experiment, (B) population size of each replicate population in the evolve and resequence experiment, (C) number of replicate populations, and (D) number of generations for over which allele frequency changes were recorded in the experiment. In each case, other than the parameter to be varied, the other parameters were fixed at their default values ($\eta_{scale} = 0.033$, map length in the history phase = 0.5 morgans, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1000, number of generations = 3). The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$.}
  \label{fig:Figure 2}
\end{figure}

\subsection*{Full simulations}
In our full simulations we let the ancestral population evolve forward in time with selection for 25000 generations before simulating the experiment. In these simulations, we expect the population to be at drift-recombination-mutation-selection equilibrium, such that $p_{\alpha} $ is negative and $\beta^{(1)}_{\bar{\alpha}}$ is positive. Results from our standard set (Figure \ref{fig:Figure 3}) suggest that not only does our method provide precise and unbiased estimates of $V_A$, but it does so by correctly estimating the signs of $p_{\alpha}$ and $\beta^{(1)}_{\bar{\alpha}}$ (Figure \ref{fig:Figure 3}B,D). As before, estimates of $V_A$ became slightly noisier at shorter map lengths during the experiment (Figure \ref{fig:Figure 4}A). The quality of our estimates of $V_A$ was not significantly affected by adding beneficial mutations during the history phase (Figure \ref{fig:Figure 4}C). On the other hand, our estimates were downwardly biased at larger map lengths in the history phase (Figure \ref{fig:Figure 4}B, also see Figure \ref{fig:Figure S1}) and when non-neutral loci had on average larger fitness effects (i.e. when $\eta_{scale}$ was larger) (Figure \ref{fig:Figure 4}D). The bias at larger $\eta_{scale}$ was likely driven by the loss of additive genic variance at large-effect loci during the experiment (Figure \ref{fig:Figure S2}A-D).  

Finally, we re-analysed our standard set of full simulations in two different ways (Figure \ref{fig:Figure 4}E-F). First, to accommodate cases in which phased genomes, and therefore ${\bf L}^{'}_{0}$, are unavailable, we assumed that ${\bf L}^{''}_{0}$ was 0 and set ${\bf L}^{'}_{0}$ = $\bf L_0$. In other words, we assumed that $\tilde{\bf L}_0$ = ${\bf L}_0$. Our analyses suggest that this assumption leads to a slight downward bias in our estimates of $V_A$ (Figure \ref{fig:Figure 4}E). Second, to account for instances where $N_E$ in the experiment phase is unknown, we replaced our estimate of $N_E$ in the experiment phase by the number of individuals. Our analyses suggest that this does not affect our estimates of $V_A$ in any way (Figure \ref{fig:Figure 4}F), with the faster than expected drift being absorbed by an increased residual variance (Figure \ref{fig:Figure S3}): estimates of $N_E$ can be obtained by dividing the assumed value of $N_E$ by the estimated residual variance. 

\begin{figure}[H]
\includegraphics[scale = 0.15]{Figures/Fig3.jpg}
\caption{Results of full simulations with a burn-in phase of 25000 generations (map length in the history phase = 0.5 morgans, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1000, number of generations = 3, $\eta_{scale} = 0.033$). (A) A scatter plot of estimates of $V_A$ vs true values of $V_A$. The solid black line indicates the 1:1 line. (B)-(D) Histograms of the estimates of $p_{\bar \alpha} $, $\beta^{(0)}_{\bar{\alpha}}$, and $\beta^{(1)}_{\bar{\alpha}}$, respectively. The vertical red line indicates 0.}
  \label{fig:Figure 3}
\end{figure}

\begin{figure}[H]
\includegraphics[scale = 0.12]{Figures/Fig4.jpg}
\caption{Scatter plots of estimates of $V_A$ vs true values of $V_A$ for full simulations with a burn-in phase of 25000 generations at different values of (A) map length in the experiment phase, (B) map length during the history phase, (C) the ratio of rates of beneficial and deleterious mutations in the history phase, and (D) $\eta_{scale}$ for non-neutral mutations. In each case, other than the parameter to be varied, the other parameters were fixed at their default values (map length in the history phase = 0.5 morgans, map length in the experiment phase = 2 morgans, number of replicate populations = 10, population size = 1000, number of generations = 3), $\eta_{scale}$ for non-neutral mutations = 0.033. The solid black line indicates the 1:1 line. The coloured lines represent regression lines for estimates of $V_A$ vs true values of $V_A$. The effect of analysing the standard set of simulations (Figure \ref{fig:Figure 3}) (E) without partitioning $\tilde{\bf L}_0$ into its gametic (${\bf L}^{'}_{0}$) and non-gametic phase (${\bf L}^{''}_{0}$) components, and (F) using $N_E = N = 1000$. Note that in (F), a large number of green points are eclipsed by the blue points.}
\label{fig:Figure 4}
\end{figure}

\subsection*{Comparison with B\&C}

In both simplified and full simulations, all implementations of B\&C's method resulted in a strong upward bias at low recombination rates in the history phase (Figures \ref{fig:Figure 5} and\ref{fig:Figure 6}). This was likely a consequence of Assumption G being violated; the correlation between the contribution of a selected site $j$ to $V_a$ and the persistent association of this site with neutral alleles ($\sum_{ \mathcal{N}_i}(R_{{i_m}{j_m}}R_{{i_n}{j_n}})$) was considerably higher than 0 when the map length in the history phase was low (panel H of Figures \ref{fig:Figure 5} and \ref{fig:Figure 6}). In contrast, the estimates of $V_A$ provided by our method were unbiased and had far greater precision compared to any of the six implementations of B\&C's method in the simplified simulations (Figure \ref{fig:Figure 5}G), although there was a small upward bias at low recombination rates in the full simulations (Figure \ref{fig:Figure 6}G). Due to the difficulty of distinguishing selected from unselected sites, B\&C suggested that the average LD between all sites could be used instead of the LD between selected and unselected sites (Assumption Ib) and indeed this assumption seems to be well justified (panels D \& F in Figures \ref{fig:Figure 5} and \ref{fig:Figure 6} are very similar). However, an inability to distinguish selected from unselected sites would likely mean that B\&C's method is applied to allele frequency change data from \emph{all} segregating sites, contravening Assumption B. This results in considerable overestimation of $V_A$ in simplified simulations (Figure \ref{fig:Figure 5}A-B) but not in full simulations (Figure \ref{fig:Figure 6}A-B). Under all scenarios the bias in the method of B\&C can be reduced (but not eliminated) by relaxing Assumption N (compare panels B, D, and F in Figures \ref{fig:Figure 5}-\ref{fig:Figure 6} to panels A, C and E). Under assumption N, it is assumed that the (co)variance in allele frequency change weighted by the square root of twice the genetic diversities can be approximated by the (co)variances in allele frequency change divided through by twice the average diversities. However, this approximation is not required. 

\newgeometry{left=1cm,bottom=2cm, top=1cm, right=1cm}
\begin{landscape}
\begin{figure}[H]
\begin{center}
\includegraphics[scale = 0.14]{Figures/Fig5.jpg}
\end{center}
\caption{Estimates of $V_A$ obtained using our method (G) and various applications of the B\&C Approach (A--F) from simplified simulations with varying 
    map lengths in the history phase: 0.5 morgans (green), 5 morgans (magenta), 50 morgans (blue), and 100 morgans (grey). The solid black line indicates the 1:1 line. Each application of B\&C is defined in terms of which three assumptions (B, Ib, N) are required or not (designated with a $+$ or 0 superscript, respectively). Assumption B is that allele frequencies are tracked at unselected loci only, Assumption Ib is that the average LD between all sites is equal to the average LD between selected and unselected sites, and Assumption N is that the covariance between projected allele frequency changes is equal to the covariance between allele frequencies changes scaled by the average projection (see Table \ref{tab:Table_2} for details). Panel H is the correlation between the contribution of a selected sites to $V_a$ and their persistent associations with neutral alleles (i.e. deviations from Assumption G in B\&C)}
    \label{fig:Figure 5}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[H]
\begin{center}
\includegraphics[scale = 0.14]{Figures/Fig6.jpg}
\end{center}
\caption{Estimates of $V_A$ obtained using our method (G) and various applications of the B\&C Approach (A--F) from full simulations with varying map lengths in the history phase: 0.5 morgans (green), 5 morgans (magenta), 50 morgans (blue), and 100 morgans (grey). The solid black line indicates the 1:1 line. Each application of B\&C is defined in terms of which three assumptions (B, Ib, N) are required or not (designated with a $+$ or 0 superscript, respectively). Assumption B is that allele frequencies are tracked at unselected loci only, Assumption Ib is that the average LD between all sites is equal to the average LD between selected and unselected sites, and Assumption N is that the covariance between projected allele frequency changes is equal to the covariance between allele frequencies changes scaled by the average projection (see Table \ref{tab:Table_2} for details). Panel H is the correlation between the contribution of a selected sites to $V_a$ and their persistent associations with neutral alleles (i.e. deviations from Assumption G in B\&C). For clarity of presentation, in (A), (C), and (E), we have restricted the range of the y axis between 0 and 0.35. As a consequence, points having an estimate of $V_A$ above 0.35 have been excluded from the plot for 0.5 morgans (green).}
    \label{fig:Figure 6}
\end{figure}
\end{landscape}
\restoregeometry

\section*{Discussion}
\addcontentsline{toc}{section}{Discussion}

In this paper we estimate the additive genetic variance for relative fitness ($V_A$) directly from the change in the genetic composition of a population caused by selection. Assuming only the absence of meiotic drive, we show that $V_A$ can be conveniently expressed as a function of the genome-wide genetic diversity matrix $\textbf{L}$, and the vector of genome-wide expected allele frequency change due to selection $E[\Delta{\textbf{p}}]$. In our inference approach, we describe how a linear mixed model can be employed to estimate $E[\Delta{\textbf{p}}]$ via independent evolutionary replicates derived from the same base population with a known $\textbf{L}$ -- a common feature of evolve-and-resequence studies.  Unlike alternative methods \citep{buffalo2019linked}, this allows us to obtain estimates of $V_A$ that are largely robust to the underlying genetic properties of the population and the genetic architecture of fitness. Moreover, the underlying modeling framework not only allows $V_A$ to be estimated, but allows inferences about the relationship between effect sizes and allele frequency.    

Although $E[\Delta{p}]$'s at individual loci cannot be usefully estimated, for our purposes it is sufficient to estimate their distribution as parameterised through the mean vector $\boldsymbol{\mu_{\bar{\alpha}}}$ and the (co)variance matrix $\boldsymbol{V_{\bar{\alpha}}}$ for the distribution of the average effects for fitness, the $\alpha$'s. Our inference approach uses a low-dimensional (4-parameter), but biologically sensible, model for the means and (co)variances. It is superficially surprising that such a simple model for an $n_L$ (the number of loci) dimensional distribution can produce accurate results. However, in a typical dataset one expects the number of individuals, $N$, to be far smaller than the number of loci, $n_L$. Therefore, the non-null subspace of $\textbf{L}$ has only $N$ dimensions, and we can work with allele frequency changes projected into this reduced space. This provides a route to understanding how the distribution of $\alpha$'s can be estimated from selected changes in allele frequency that must be negligible compared to the impact of drift: the projection defines `\emph{chunks}' of genome, and it is the frequency changes in these chunks, rather than individual alleles, that are tracked. Since the aggregate fitness effects of alleles across chunks will be more substantial, they can be more easily detected. Moreover, since these aggregate effects may involve a large number of loci, they will, thanks to the central limit theorem, tend to normality and, conditional on the projection, converge in distribution. Since the projection is defined by ${\bf L}$, a model of the $\alpha$'s that conditions on aspects of ${\bf L}$ ($p-q$ and $pq$ in our case) is expected to be sufficient.      

The results of our simulations demonstrate that our approach provides usefully precise and consistent estimates of $V_A$ over a wide range of parameter combinations and experimental designs. In the simplified simulations, in which the relationship between allele frequencies and $\alpha$'s was expected to be absent, the model requires only a single parameter: the variance in average effects, $\sigma^2_{\bar{\alpha}}$. If such a model is assumed, this is a relatively straightforward inference problem and the method of \citet{buffalo2019linked} can give accurate estimates if selected and neutral sites can be distinguished, and certain patterns of recombination and linkage-disequilibrium hold.  Although our approach does not assume such a model, it can accurately infer $V_A$ and also the lack of relationship between allele frequencies and $\alpha$'s, with the three parameters that determine the relationship between allele frequency and $\alpha$ all centered on their null expectations (Figure \ref{fig:Figure 1}). However, in reality, independence between allele frequency and $\alpha$ seems implausible at mutation-selection-drift balance, and the elevated contribution of high-diversity loci to $V_A$ under the simple, but unrealistic, scenario may result in greater power to detect $V_A$.

At mutation-selection-drift balance a negative relationship is expected between $\alpha$'s and allele frequencies \citep{Charlesworth.2010}. Although it could be argued that the strength of this relationship will be reduced in experimental evolution studies, which generally expose populations to novel environmental stressors (such as a laboratory environment, pathogens \citep{basu2024experimental}, extreme population densities \citep{joshi1996density} and temperatures \citep{singh2015egg, hsu2024reproductive}, desiccation \citep{gibbs1997physiological}, malnutrition \citep{kawecki2021genomic}, or toxic substances \citep{godinho2024limits, xiao2019experimental}) it seems unlikely that no relationship would persist. Even under the more realistic scenario of our full simulations, in which the base population had evolved under selection for 25,000 generations, our approach provided reliable estimates of $V_A$ that were remarkably robust to the details of the distribution of fitness effects, such as the relative frequency of beneficial mutations, or properties of the population such as the recombination rate. Furthermore, it did so by correctly inferring a negative relationship between fitness effects of alleles and genetic diversity, and a positive relationship between fitness effects and $p-q$, as expected under mutation-selection balance.

Although our method generally performs well, some biases were observed. In terms of experimental design, small upward biases are evident when power is low - either because there are few replicates and/or allele frequency change is only calculated over a single generation. In terms of genetic architecture, our approach marginally underestimates $V_A$ when the fitness effects of new non-neutral mutations are large. This downward bias seems to arise because there is a large contribution of rare highly deleterious variants to $V_A$ and these get lost during the experimental phase. Nevertheless, even when 25\% of $V_A$ was lost during the course of the experiment the impact on estimates was rather minor.  Similarly, modest downward biases were observed when the recombination rate in the history phase was increased, but the source of this bias has been harder to diagnose. Increasing the recombination rate resulted in an increase in the number of segregating selected sites and their genetic diversity, and a steeper relationship between $\alpha$ and genetic diversity, consistent with a reduction in the effects of background selection \citep{charlesworth1993effect} on weakly selected sites \citep{stephan1999effect}.  While it is not clear why this causes downward bias in the estimates, it is also unclear whether real populations would ever have such extreme genetic architecture where the bulk of the additive genetic variance for fitness is caused by highly deleterious variants segregating at very low frequencies. In order to make the forward simulations manageable we were working with considerably smaller population and genome sizes than are typical of real populations. It is not clear, however, whether the standard rescaling of mutations rates, recombination rates and selection coefficients to accommodate this downsizing results in genetic architectures that would be typical of larger populations and larger genomes \citep{dabi2025population}. 

While our method performs well when applied to simulated data, application to real-world data would involve overcoming a number of challenges. First, we require genome-wide allele frequency change data from multiple independent evolutionary replicates -- although this should be readily available for most evolve-and-resequence experiments. Second, we require the genetic diversity matrix $\textbf{L}$ in the base population from which the replicates are derived. This is not always the case for evolve-and-resequence studies, in which base populations are often split into replicate baseline populations long before the experiment, or when newer selection regimes are derived mid-experiment \citep{burke2010genome,singh2015egg,gupta2016no, robinson2023evolution}. Furthermore, our method requires that sufficient individuals from the base population are individually sequenced  to estimate  $\textbf{L}$, or -- even better --  its gametic phase ($\textbf{L}^{'}$) and non-gametic phase ($\textbf{L}^{''}$) components, although the required phasing should become more readily available with long-read sequencing. Third, to predict how $\textbf{L}$ evolves, we require an estimate of the recombination probability between all pairs of segregating sites, such as a recombination map for the population. In reality, recombination maps are likely to have been derived from other populations, in which recombination patterns may differ \citep{johnston2024understanding}. Although recombination maps can be approximated, for example by using Haldane's mapping function, it is not clear how sensitive the method is to errors in the recombination map. Fourth, our method requires the mean number of generations over which allele frequency changes are calculated, which may be hard to infer with overlapping generations. As a first approximation, $V_A\approx E[\Delta({\bf p}^{\top})]{\bf L}^{-1}E[\Delta({\bf p})]/(\tau-t)^2$ where $\tau-t$ is the number of generations over which allele frequency is tracked. Consequently, estimates might be out by a factor $(\tau-t)^2/(\widehat{\tau-t})^2$. Fifth, our method uses effective population size to predict how $\textbf{L}$ evolves ($N_e$) and to derive expressions for the drift (co)variance ($N_E$). Although reliable estimates of both effective population sizes may be hard to obtain, this is unlikely to be a major issue because: (i) $\textbf{L}^{'}$ decays with a rate roughly proportional to $1 - 1/N_e$ (likely making it insensitive to errors in estimating  $N_e$)  and (ii) our simulations suggest that using the wrong $N_E$ does not adversely affect our estimates of $V_A$ because the mispecification is absorbed by the residual variance of the model. Sixth, our simulations minimise the unpredictable response to selection because our fitness model is close to being additive and so the average effects remain relatively constant as allele frequencies change. However, with greater non-additivity and/or selection coefficients that vary in time or across replicates, the unpredictable response to selection will be greater. Indeed in outdoor mesocosms of \emph{D. melanogaster}, \citet{Bitter.2024} report that allele frequency changes can switch signs over time-points separated by a matter of weeks in spite of exhibiting highly concordant evolution between replicates. It is not clear to what degree this will affect inferences. Finally, selection can often act in different ways in different contexts such as space \citep{whitlock2015modern, delph2018study}, time, and between the two sexes \citep{schenkel2018making}. Our approach captures the effects of selection averaged over all these different contexts. Specifically, if loci have different fitness effects in males and females, we effectively estimate $(V_{A,f} + V_{A,m} + 2COV_{A,mf})/4$, where $V_{A,f}$ and $V_{A,m}$ are the additive genetic variances for relative fitness in females and males respectively, and $COV_{A,mf}$ is the intersexual additive genetic covariance for relative fitness. For these reasons, when applied to replicate populations, our estimates of $V_A$ are perhaps best thought of as the additive genetic \emph{covariance} in fitness between replicates. Although rarely made explicit, estimates from wild systems should be interpreted in the same way: the additive genetic covariance between the environments in which relatives live \citep{Vehvilainen.2008}.   

Analysing data from wild populations is likely to entail further challenges. For example, in natural populations, allele frequency change from immigration may be consequential, and without some modification is likely to be mistaken for allele frequency change caused by natural selection \citep{simon2024contribution}. Furthermore, replicate populations are unlikely to be available for natural systems -- with some exceptions such as Trinidadian guppies \citep{reznick1996life} -- although with some modifications our method could be adapted to use allele frequency change data from multiple time points. However, a lack of individual-level sequences in the base population would mean that the estimates of $\textbf{L}$ will likely be considerably noisier in natural populations. 

While we accept that the data requirements for our method are steep, and the list of caveats appears long, we do think that information about $V_A$ can be successfully leveraged from current evolve and resequence studies. Going forward, we hope this work will inform future evolve and resequence study design, and that estimates of $V_A$ from a wide range of organisms and environments becomes available. Partitioning $V_A$ into genomic features is an obvious next step, and in the future we hope to go beyond simply knowing the magnitude of $V_A$ and start to understand its underlying causes.

\section*{Data Availability Statement}
\addcontentsline{toc}{section}{Data Availability Statement}
This study does not use any data. The code used for simulations and analyses is available in the following GitHub repository: \url{https://github.com/manas-ga/Va_simulations}.

\section*{Acknowledgments}
\addcontentsline{toc}{section}{Acknowledgments}

The authors would like to thank Bill Hill, Brian Charlesworth, Peter Keightley, Konrad Lohse, Bruce Walsh, Ben Longdon and Vince Buffalo for their insightful comments, and The Argyle for hosting us at the early stages of this project. Computer simulations described here were performed on the AC3 computing cluster based at Ashworth Laboratories, the University of Edinburgh.

\section*{Funding}
\addcontentsline{toc}{section}{Funding}
This work was funded by a Natural Environment Research Council (NERC) grant (reference: NE/W001330/1). For the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) license to any Author Accepted Manuscript version arising from this submission.

\section*{Conflict of Interest}
\addcontentsline{toc}{section}{Conflict of Interest}
The authors have no conflicts of interest to declare.

\putbib
\end{bibunit}
\newpage
\begin{longtable}{|p{2cm}|p{13cm}|}
\hline
Symbol&Description\\
\hline
$w$&Relative fitness\\
$W$&Absolute fitness\\
$V_A$&Additive genetic variance for relative fitness\\
$V_a$&Additive genic variance for relative fitness\\
$t_m$&Time at which allele frequencies are first measured in replicate $m$.\\
$\tau_m$&Time at which allele frequencies are finally measured in replicate $m$.\\
$C_{A}(t\rightarrow\tau)$&Additive genetic covariance for relative fitness between generation $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$.\\
$C_{a}(t\rightarrow\tau)$&Additive genic covariance for relative fitness between generation $t$ and $\tau$ for a population with genetic structure equal to that in generation $t$.\\
$\boldsymbol{\alpha}_{t,m}$& Vector of average effects for relative fitness at time $t$ in replicate $m$.\\
$\bar{\boldsymbol{\alpha}}$& Vector of mean average effects for relative fitness.\\
$\Delta{\bf \alpha}_{t,m}$&Vector of deviations of the average effects for relative fitness at time $t$ in replicate $m$ from the global mean.\\
$c_{k,i}$& Number of reference alleles at locus $i$ for individual $k$ divided by 2.\\
$n_L$&Number of loci.\\
$N_{t,m}$&Census population size at time $t$ in replicate $m$\\
$N_{e_{t,m}}$&Variance effective population size at time $t$ in replicate $m$\\
$N_{E_{t,m}}$&Variance effective population size at time $t$ in replicate $m$ ignoring the impact of linked-selection\\
$\boldsymbol{\eta}_{t,m}$&Linear model coefficients for the $c$'s on $log(W)$\\
${\bf p}_{t,m}$& Vector of reference allele frequencies at time $t$ in replicate $m$.\\
${\bf q}_{t,m}$& Vector of alternate allele frequencies at time $t$ in replicate $m$.\\
$\Delta {\bf p}_{t,m}$&Vector of reference allele frequency changes between time $t$ and $t+1$ in replicate $m$.\\
$\Delta {\bf p}_{m}$&Vector of reference allele frequency changes between time $t_m$ and $\tau_m$ in replicate $m$.\\
${\bf L}_{t,m}$&Covariance matrix of c's at time $t$ in replicate $m$.\\
${\bf L}^{'}_{t,m}$&Covariance matrix of $c$'s at time $t$ in replicate $m$ due to being on the same gametic contribution. \\
${\bf L}^{''}_{t,m}$&Covariance matrix of $c$'s at time $t$ in replicate $m$ due to being on different gametic contributions. \\
$\Delta{\bf L}^{'}_{t,m}$&The stochastic change in ${\bf L}^{'}$ between time zero and $t$ in replicate $m$.\\
$z_{i_{t},j_{t}}$&$(1-r_{i_{t},j_{t}})(1-\frac{1}{2N_{e_t}})$\\
$\zeta_{i_{t},j_{t}}$&$r_{i_{t},j_{t}}(1-\frac{1}{2N_{e_t}})$\\
$\tilde{\bf L}_{0}$&Weighted sum of ${\bf L}^{'}_0$ and ${\bf L}^{''}_0$ with weights for element $ij$ being 1 and $z_{i_{0},j_{0}}/\zeta_{i_{0},j_{0}}$ respectively.\\
$r_{i,j}$&Recombination rate between loci $i$ and $j$.\\
${\bf R}_{+}$&Matrix of recombination probabilities.\\
${\bf R}_{-}$&Matrix of non-recombination probabilities.\\
${\bf N}_{t,m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the expected ${\bf L}$ at time $t>0$ in replicate $m$.\\
${\bf N}_{m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the sum of the expected ${\bf L}$ from time $t_m>0$ to $\tau_m$ in replicate $m$.\\
$\boldsymbol{\mathcal{L}}_m$&A matrix that gives, when post-multiplied by $\boldsymbol{\alpha}$, the predictable change in allele frequency due to selection between generation $t_m$ and $\tau_m$ in replicate $m$.\\
${\bf M}_{t,m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the covariance in allele frequency changes  due to drift between time $t>0$ and $t+1$ in replicate $m$.\\
${\bf M}_{m}$&Matrix of weights for $\tilde{\bf L}_{0}$ that gives the covariance in allele frequency changes  due to drift between time $t_m>0$ and $\tau_m$ in replicate $m$.\\
$\boldsymbol{\mathcal{D}}_m$&Matrix that gives the covariance in allele frequency changes between generation $t_m$ and $\tau_m$ in replicate $m$ due to drift.\\
$\boldsymbol{\mathcal{U}}_m$&Matrix that gives the covariance in allele frequency changes between generation $t_m$ and $\tau_m$ in replicate $m$ due to the unpredictable response to selection.\\
$\boldsymbol{\mu}_{\bar{\alpha}}$&Vector of expected values for the mean average effects.\\
$\beta^{(0)}_{\bar{\alpha}}$&Intercept of the regression of the mean average effects on some covariate.\\
$\beta^{(1)}_{\bar{\alpha}}$&Slope of the regression of the mean average effects on some covariate.\\
${\bf X}$&Design matrix for the regression of the mean average effects on some covariate.\\
${\bf S}_{\bar{\alpha}}$&Sampling covariance matrix for the parameters of the regression of the mean average effects on some covariate.\ \\
$\bf{V}_{\bar{\alpha}}$&Covariance matrix for the mean average effects.\\\
$p_{\bar{\alpha}}$&Parameter that takes ${\bf L}_0$ to some power \\
$\sigma^{2}_{\bar{\alpha}}$&Proportionality constant that relates $\bf{V}_{\bar{\alpha}}$ to ${\bf L}_{0}^{p_{\bar{\alpha}}}$.\\
${\bf P}$&Projection matrix for allele frequencies.\\
${\bf U}_{\bf L}$&Eigenvectors of ${\bf L}_0$.\\
${\bf U}_{2}$&Eigenvectors of $\boldsymbol{\mathcal{D}}$\\
${\bf D}_{2}$&Diagonal matrix of square-rooted eigenvalues of $\boldsymbol{\mathcal{D}}$\\
${\bf B}$&Diagonal matrix of standard deviations for the $c$'s\\
${\bf R}$&Correlation matrix of the $c$'s.\\
$R_{j_t,i_t}$&Correlation in allele count between locus $i$ and $j$ at time $t$ (Note the use of the uppercase to distinguish from the recombination rate $r$).\\
${\bf W}_{t\tau}$&A matrix with the $ij^{th}$ element equal to $R_{j_t,i_t}R_{k_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$\\
${\bf H}_{t\tau}$&${\bf W}_{t\tau}$ but with the off-diagonals set to zero.\\
${\bf F}_{t\tau}$&${\bf W}_{t\tau}$ but with the diagonals set to zero.\\
$\mathcal{S}$&Used as a subscript to indicate the set of selected loci.\\
$\mathcal{N}$&Used as a subscript to indicate the set of neutral loci.\\
$\phi_{t,\tau}$&The ratio of genetic diversity in generation $\tau$ to genetic diversity in generation $t$ assumed constant across all selected loci.\\
\hline
\caption{Notation}
\label{tab:notation}
\end{longtable}

\newpage
{\Large \bf Supplementary data}


\begin{bibunit}

\setcounter{equation}{0}
    \renewcommand{\theequation}{S\arabic{equation}}
    \setcounter{figure}{0}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \setcounter{section}{0}
    \renewcommand{\thesection}{S\arabic{section}}

    
%\addcontentsline{toc}{section}{Appendix}
\section{Appendix 1: The dynamics of ${\bf L}$ under drift and recombination.} \label{Appendix:LD}
%\addcontentsline{toc}{subsection}{Appendix 3: The dynamics of ${\bf L}$ under drift and recombination.}

The matrix ${\bf L}$ is a covariance matrix whose elements are proportional to the genotypic linkage-disequilbria (off-diagonals) or variance in genotypic allele frequencies (diagonals) at the start of a generation, before selection has acted. We can decompose  ${\bf L}$ into ${\bf L}^{'}$ and ${\bf L}^{''}$ following the notation of \citet{buffalo2019linked} where ${\bf L}^{'}$ represents the (co)variances that arise due to alleles in the same gamete and ${\bf L}^{''}$ represents the (co)variances that arise due to alleles in the different gametic contributions of a genotype. Note that in \citet{Santiago.1998} the primes have a subtly different meaning after the initial generation, as the double prime in following generations designates gametic phase disequilibrium due to recombination and nongametic phase disequilibrium in the initial generation. The elements of ${\bf L}^{'}$ and ${\bf L}^{''}$ have direct correspondences with genetic diversities and additive measures of disequilibria. Under the notation of \citet{Weir.1989} (see also \citet{bulmer1980mathematical}, Chapter 12), the diagonal elements of ${\bf L}^{'}$ are half the gametic genetic diversities ($\pi_i=p_i(1-p_i)=2L^{'}_{i,i}$), and the off-diagonals are half the gametic-phase disequilibria ($D_{i,j}=2L^{'}_{i,j}$). Note that \citet{Weir.1989} uses $\pi$ to denote $p_i(1-p_i)$ rather than the more usual (and less natural) $2p_i(1-p_i)$. The diagonal elements of ${\bf L}^{''}$ are half the additive coefficients of Hardy Weinberg disequilibria ($D_{i}=2L^{''}_{i,i}$), and the off-diagonals are half the nongametic-phase disequilibria ($D_{i/j}=2L^{''}_{i,j}$). 

To see these correspondences, imagine two bi-allelic loci, $i$ and $j$, with reference/alternate alleles A/a and B/b, respectively. There are four possible gametic haplotypes, and we can denote the frequency of haplotype $mn$ as $p_{mn}$ in the gametes and the frequency of allele $m$ as $p_m$ ($m$ and $n$ are indexing variables for allelic states at locus A/a and locus B/b, respectively). The proportion of copies of the reference allele at locus $i$ in a randomly chosen individual -- i.e. $c_i$ -- can be decomposed into into the sum of maternal and paternal contribution: $c_i = m_i+f_i$ where $m_i$ (or $f_i$) takes the value 1/2 if the mother (or the father) contributed a reference allele and 0 if not. Then,

\begin{equation}
\begin{array}{rl}
L_{i,j} =& COV(c_i, c_j)\\
        =& COV(m_i+f_i,  m_j+f_j)\\
        =& COV(m_i,  m_j)+COV(f_i,f_j)+COV(m_i,  f_j)+COV(f_i,  m_j)\\
\end{array}
\end{equation}

Assuming haplotype frequencies are identical in male and female gametes we get

\begin{equation}
\begin{array}{rl}
L_{i,j} =& (p_{AB}-p_{A}p_{B})/4+(p_{AB}-p_{A}p_{B})/4+(p_{A/B}-p_{A}p_{B})/4+(p_{A/B}-p_{A}p_{B})/4\\
=& (p_{AB}-p_{A}p_{B})/2+(p_{A/B}-p_{A}p_{B})/2\\
=& D_{i,j}/2+D_{i/j}/2\\
\end{array}
\end{equation}

where $p_{A/B}$ is the frequency of zygotes that have an A from their mother and a B from their father, or vice versa.  When $i=j$,

\begin{equation}
\begin{array}{rl}
L_{i,i} =& COV(c_i, c_i)\\
=& (p_{A}^2-p_{A})/2+(p_{A/A}-p_{A}^2)/2\\
=& \pi_i/2+D_{i}/2\\
\end{array}
\end{equation}

where $p_{A/A}$ is the frequency of $A$ homozygotes. The term $D_i$ is an alternative, additive, measure of deviation from Hardy-Weinberg Equilibrium than the more commonly used inbreeding coefficient, $F$. 

To derive expressions for the dynamics of ${\bf L}^{'}$ and ${\bf L}^{''}$, note that ${\bf L}^{''}$ is generated anew each generation under random mating and in a finite population has zero expectation such that

\begin{equation}
L^{''}_{i_{t+1}, j_{t+1}} = e^{''}_{i_{t+1}, j_{t+1}}
\end{equation}

where $e^{''}_{i_{t+1}, j_{t+1}}$ is a stochastic term with mean zero and variance given in \citet{Weir.1996}. The elements of ${\bf L}^{'}$ under recombination and drift are \citep{Hill.1968, Santiago.1998}

\begin{equation}
\begin{array}{rl}
L^{'}_{i_{t+1},j_{t+1}} =& \left(1-\frac{1}{2N_{e_t}}
\right)\left((1-r_{i_{t},j_{t}})L^{'}_{i_{t},j_{t}} + r_{i_{t},j_{t}}L^{''}_{i_{t},j_{t}}\right)+e^{'}_{i_{t+1},j_{t+1}}\\
=& z_{i_{t},j_{t}}L^{'}_{i_{t},j_{t}} + \zeta_{i_{t},j_{t}}L^{''}_{i_{t},j_{t}}+e^{'}_{i_{t+1},j_{t+1}}\\
\end{array}
\end{equation}

where $z_{i_{t},j_{t}}=(1-r_{i_{t},j_{t}})(1-\frac{1}{2N_{e_t}})$ and  $\zeta_{i_{t},j_{t}}=r_{i_{t},j_{t}}(1-\frac{1}{2N_{e_t}})$, with $r_{i_{t},j_{t}}$ being the recombination rate between locus $i$ and $j$ in generation $t$, and $N_{e_t}$ the effective population size in generation $t$. The stochastic terms, $e^{'}_{i_{t+1},j_{t+1}}$, have zero mean and are uncorrelated over time, with variances given by \citet[][Eq 25, although those variances must be divided by 4 here since we are working with the frequency of alleles in individuals rather than gametes]{Ohta.1969}. The covariances between, for example, $e^{'}_{i_{t+1},j_{t+1}}$ and $e^{'}_{k_{t+1},l_{t+1}}$ are not given in \citet{Ohta.1969}, and may be unknown. As a consequence,

\begin{equation}
\begin{array}{rl}
L^{'}_{i_{1},j_{1}} =& z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}}\\
\\
L^{'}_{i_{2},j_{2}} =& z_{i_{1},j_{1}}(z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}})+\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+e^{'}_{i_{2},j_{2}}\\
\\
L^{'}_{i_{3},j_{3}} =& 
z_{i_{2},j_{2}}(z_{i_{1},j_{1}}(z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+e^{'}_{i_{1},j_{1}})+\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+e^{'}_{i_{2},j_{2}})\\
&+\zeta_{i_{2},j_{2}}L^{''}_{i_{2},j_{2}}+e^{'}_{i_{3},j_{3}}\\
\\
L^{'}_{i_{3},j_{3}} =&z_{i_{2},j_{2}}z_{i_{1},j_{1}}z_{i_{0},j_{0}}L^{'}_{i_{0},j_{0}}+z_{i_{2},j_{2}}z_{i_{1},j_{1}}\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}+z_{i_{2},j_{2}}z_{i_{1},j_{1}}e_{i_{1},j_{1}}^{'}\\
&+z_{i_{2},j_{2}}\zeta_{i_{1},j_{1}}L^{''}_{i_{1},j_{1}}+z_{i_{2},j_{2}}e_{i_{2},j_{2}}^{'}+\zeta_{i_{2},j_{2}}L^{''}_{i_{2},j_{2}}+e_{i_{3},j_{3}}^{'}\\
\\
\cdots \hspace{0.3cm}= &\cdots\\
\\
L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\sum_{k=0}^{t-1}\zeta_{i_{k},j_{k}}L^{''}_{i_{k},j_{k}}\prod_{u=k+1}^{t-1}z_{i_{u},j_{u}}\\
&+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\

\\
L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\zeta_{i_{0},j_{0}}L^{''}_{i_{0},j_{0}}\prod_{k=1}^{t-1}z_{i_{k},j_{k}}\\
&+\sum_{k=1}^{t-1}\zeta_{i_{k},j_{k}}L^{''}_{i_{k},j_{k}}\prod_{u=k+1}^{t-1}z_{i_{u},j_{u}}+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\
\\
L^{'}_{i_{t},j_{t}} =&L^{'}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\frac{\zeta_{i_{0},j_{0}}}{z_{i_{0},j_{0}}}L^{''}_{i_{0},j_{0}}\prod_{k=0}^{t-1}z_{i_{k},j_{k}}+\sum_{k=1}^{t-1}\frac{\zeta_{i_{k},j_{k}}}{z_{i_{k},j_{k}}}L^{''}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}\\
&+\sum_{k=1}^{t-1}e^{'}_{i_{k},j_{k}}\prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}\\
\\
L^{'}_{i_{t},j_{t}} =&\left(L^{'}_{i_{0},j_{0}}+\frac{\zeta_{i_{0},j_{0}}}{z_{i_{0},j_{0}}}L^{''}_{i_{0},j_{0}}\right)\prod_{k=0}^{t-1}z_{i_{k},j_{k}}\\
&+\sum_{k=1}^{t-1}\left(e^{'}_{i_{k},j_{k}}+\frac{\zeta_{i_{k},j_{k}}}{z_{i_{k},j_{k}}}L^{''}_{i_{k},j_{k}}\right) \prod_{u=k}^{t-1}z_{i_{u},j_{u}}+e^{'}_{i_{t},j_{t}}
\end{array}
\label{eq:LD1}
\end{equation}
\\
 Having the matrix ${\bf N}_t$ with the $ij^{th}$ element being the relevant $\prod_{k=0}^{t-1}z_k$, we have for $t>0$
 
\begin{equation}
{\bf L}_{t}= {\bf N}_t\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_t+{\bf L}^{''}_t
\label{eq:LD3}
\end{equation}
 
where $\circ$ is the Hadamard product. The first term is the expected ${\bf L}$ (and ${\bf L}^{'}$) in generation $t$, conditional on the genotypic composition of the population in generation 0, where $\tilde{\bf L}_{0}$ is the sum of ${\bf L}^{'}_{0}$ and ${\bf L}^{''}_{0}$ with the elements of the latter weighted by $\zeta_{i_{0},j_{0}}/z_{i_{0},j_{0}}=r_{i_0,j_0}/(1-r_{i_0,j_0})$. $\Delta {\bf L}^{'}_t$ is a matrix with elements equal to the sum of the stochastic terms involving $e$ in Equation \ref{eq:LD1} and represents stochastic changes in ${\bf L}^{'}$ from generation 0 to generation $t$. ${\bf L}^{''}_t$ are the new nongametic-phase disequilibria that arise in generation $t$. Note that if replicate populations are initiated from the offspring of Generation $0$, then the stochastic terms, $\Delta {\bf L}^{'}_t$ and ${\bf L}^{''}_t$, will be unique in each replicate although the deterministic part is shared. If recombination rates are constant in time $r_{i_t, j_t}=r_{i, j}$ then $\zeta_{i_{0},j_{0}}/z_{i_{0},j_{0}} = r_{i,j}/(1-r_{i,j})$ and $\prod_{k=0}^{t-1}z_{i_{k},j_{k}} =(1-r_{i,j})^{t}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_k}})$. When population sizes are also constant then $\prod_{k=0}^{t-1}z_{i_{k},j_{k}} =(1-r_{i,j})^{t}(1-\frac{1}{2N_e})^t$. 


\section{Appendix 2: Derivation for the mean, within-replicate (co)variances, and between replicate (co)variances of allele frequency changes.}
%\addcontentsline{toc}{subsection}{Appendix 4: Derivation for the mean, within-replicate (co)variances and between replicate (co)variances allele frequency changes.}
\label{App:dist}

Both $\underset{D}\Delta {\bf p}$ and $\underset{U}\Delta {\bf p}$ have expectation zero such that the conditional mean is

\begin{equation}
\begin{array}{rl}
E\left[\Delta {\bf p}_m\right] =& \sum_{t=t_m}^{\tau_m-1}E\left[({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}\right]\\
=& \left(\sum_{t=t_m}^{\tau_m-1}({\bf N}_{t,m}\circ\tilde{\bf L}_0)\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\


=& \left(\tilde{\bf L}_0\circ\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\
=& \left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)E\left[\bar{\boldsymbol{\alpha}}\right]\\
\end{array}
\end{equation}

where ${\bf N}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf N}_{t,m}$ which is null if $t_m=0$ and $\tau_m=1$. Under the same assumptions, the conditional between-replicate covariance has a similar form 

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_m, \Delta {\bf p}_n^{\top})
=&\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)VAR(\bar{\boldsymbol{\alpha}})\left(\tilde{\bf L}_0\circ{\bf N}^{(n)}\right)\\
\end{array}
\end{equation}

where $m$ and $n$ are a pair of replicates. The within-replicate (co)variances are more challenging to derive as they not only include the predictable response to selection, but also the effects of drift and the unpredictable response to selection. In what follows, we assume $E\left[\Delta\boldsymbol{\alpha}\right]=0$ and $COV(\Delta{\bf L}^{'}+{\bf L}^{''}, \bar{\boldsymbol{\alpha}})=0$ such that the predictable and unpredictable response to selection are independent. In addition, we will assume $COV(\Delta{\bf L}^{'}+{\bf L}^{''}, \Delta\boldsymbol{\alpha})=0$ and that all $\Delta\boldsymbol{\alpha}$ are independent of each other. Since $\Delta {\bf L}^{'}_t$ is the sum of stochastic changes from generation $1$ to $t$, $COV(\Delta {\bf L}^{'}_{t_1, m}, \Delta {\bf L}^{'}_{t_2, m})=VAR(\Delta {\bf L}^{'}_{t_1, m})$ when $t_1\leq t_2$. Note $COV({\bf L}^{''}_{t_1, m}, {\bf L}^{''}_{t_2, m})=0$. These assumptions allow the simplification:

\begin{tiny}
\begin{equation}
\begin{array}{rl}
VAR\left(\Delta {\bf p}_m\right) =& VAR\left(\sum_{t=t_m}^{\tau_m-1}\left(({\bf N}_{t,m}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t, m}+\underset{D}\Delta {\bf p}_{t, m}\right)\right)\\

VAR\left(\Delta {\bf p}_m\right) =& \sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left((({\bf N}_{t_1}\circ\tilde{\bf L}_0)\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_1, m}+\underset{D}\Delta {\bf p}_{t_1, m}, (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_2, m}+\underset{D}\Delta {\bf p}_{t_2, m}\right)\\

VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)+\sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left((({\bf N}_{t_1}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_1, m},  (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\bar{\boldsymbol{\alpha}}+\underset{U}\Delta {\bf p}_{t_2, m}\right)\\


VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)+\left(\sum_{t_1=t_m}^{\tau_m-1} (({\bf N}_{t_1}\circ\tilde{\bf L}_0))\right)VAR(\bar{\boldsymbol{\alpha}})\left(\sum_{t_2=t_m}^{\tau_m-1} (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\right)\\
&+\sum_{t_1=t_m}^{\tau_m-1}\sum_{t_2=t_m}^{\tau_m-1}COV\left(\underset{U}\Delta {\bf p}_{t_1, m},\underset{U}\Delta {\bf p}_{t_2, m}\right)\\

VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)+\left(\sum_{t_1=t_m}^{\tau_m-1} (({\bf N}_{t_1}\circ\tilde{\bf L}_0))\right)VAR(\bar{\boldsymbol{\alpha}})\left(\sum_{t_2=t_m}^{\tau_m-1} (({\bf N}_{t_2}\circ\tilde{\bf L}_0))\right)\\
&+\sum_{t=t_m}^{\tau_m-1}(2(\tau^m-t)+1)VAR\left(\underset{U}\Delta {\bf p}_{t,m}\right)\\

VAR\left(\Delta {\bf p}_m\right) =& \sum_{t=t_m}^{\tau_m-1}VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)+\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)VAR(\bar{\boldsymbol{\alpha}})\left(\tilde{\bf L}_0\circ{\bf N}^{(m)}\right)\\
&+\sum_{t=t_m}^{\tau_m-1}(2(\tau^m-t)+1)VAR\left(\underset{U}\Delta {\bf p}_{t,m}\right)\\


\end{array}
\end{equation}
\end{tiny}

which requires an expressions for $VAR\left(\underset{U}\Delta {\bf p}_{t, m}\right)$ and $VAR\left(\underset{D}\Delta {\bf p}_{t, m}\right)$. The variance due to unpredictable selection is:


\begin{tiny}
\begin{equation}
\begin{array}{rl}
VAR\left(\underset{U}\Delta {\bf p}_{t, m}\right)=&VAR\left((\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}+(({\bf N}_{t, m}\circ\tilde{\bf L}_0))\Delta\boldsymbol{\alpha}_{t,m}+(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m})\Delta\boldsymbol{\alpha}_{t, m}\right)\\
=&VAR\left(
(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t, m})\bar{\boldsymbol{\alpha}}\right)+VAR\left((({\bf N}_{t, m}\circ\tilde{\bf L}_0)\Delta\boldsymbol{\alpha}_{t,m}\right)+VAR\left((\Delta{\bf L}^{'}_{t, m}+{\bf L}^{''}_{t, m})\Delta\boldsymbol{\alpha}_{t,m}\right)\\

=&VAR\left(
\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}\right)VAR\left(\bar{\boldsymbol{\alpha}}\right)\\
&+(({\bf N}_{t, m}\circ\tilde{\bf L}_0)VAR\left(\Delta\boldsymbol{\alpha}_{t,m}\right)(({\bf N}_{t, m}\circ\tilde{\bf L}_0)VAR\left(\Delta{\bf L}^{'}_{t,m}+{\bf L}^{''}_{t,m}\right)VAR\left(\Delta\boldsymbol{\alpha}_{t,m}\right)\\
\end{array}
\end{equation}
\end{tiny}

and cannot be simplified.\\

For the drift covariances, note that under random mating, haplotypes are drawn from a multinomial with $2N$ trials. Using AB, Ab, AB and aB to denote the \emph{number} of each haplotypes in the gamete pool, the number of $mn$ haplotypes has variance $2Np_{mn}(1-p_{mn})$ and the covariance in the numbers of $mn$ and $op$ haplotypes is $-2Np_{mn}p_{op}$ where $p_{mn}$ is the frequency of the $mn$ halpotype in the gamete pool (i.e the parental haplotype frequencies modified by recombination). The covariance in the number of A and B alleles sampled, is therefore 


\begin{equation}
\begin{array}{rl}
COV(AB+Ab, AB+aB) =& COV(AB, AB)+COV(AB, aB)\\
&+COV(Ab, AB)+COV(Ab, aB)\\
=& 2N\left[p_{AB}(1-p_{AB})-p_{AB}p_{aB}-p_{Ab}p_{AB}-p_{Ab}p_{aB}\right]\\
=& 2N\left[p_{AB}(1-p_{AB}-p_{aB})-p_{Ab}(p_{AB}+p_{aB})\right]\\
=& 2N\left[p_{AB}(1-p_{B})-p_{Ab}p_{B}\right]\\
=& 2N\left[p_{AB}-(p_{Ab}+p_{AB})p_{B}\right]\\
=& 2N\left[p_{AB}-p_{A}p_{B}\right]\\
=& 4N\bar{L}^{'}_{i,j}\\
\end{array}
\end{equation}

where $\bar{L}^{'}_{i,j}$ is the gametic-phase linkage disequilibria that would be achieved in an infinite population. We can divide through by $(1/2N)^2$ to obtain the drift covariance in frequency (rather than counts) as $\bar{L}^{'}_{i,j}/N$ (i.e the drift (co)variances in a allele frequency from generation $t$ to $t+1$ are proportional to the gametic-phase disequilibria in generation $t+1$ that would be achieved in an infinite population conditional on the genotypic composition of the population in generation $t$). This recovers the well known result for the drift variance in allele frequency: $\bar{L}^{'}_{i,i}/N = p_i(1-p_i)/2N$. We can replace the census population size, $N$, with the effective population size $N_E$, since this approximates the sampling of genotypes in non-idealised populations well \citep{ethier1980diffusion}. However, note that $N_E$ differs from $N_e$ in that it does include the impact of linked selection since this is conditioned on in the expectation, $E[{\bf p}]$. In matrix terms (since $\bar{L}^{'}_{i_{t+1},j_{t+1}}=L^{'}_{i_t,j_t}r_{i,j}+L^{''}_{i_t,j}(1-r_{i,j})$):

\begin{equation}
\begin{array}{rl}
VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}} \bar{\bf L}^{'}_{t+1,m}\\
VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[{\bf R}_{-}\circ{\bf L}^{'}_{t,m}+{\bf R}_{+}\circ{\bf L}^{''}_{t, m}\right]\\

VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right) =& \frac{1}{N_{E_{t,m}}}\left[\left({\bf R}_{-}\circ\left({\bf N}_{t, m}\circ\tilde{\bf L}_{0}+\Delta {\bf L}^{'}_{t, m}\right)+{\bf R}_{+}\circ{\bf L}^{''}_{t, m}\right) \right]\\
\end{array}
\end{equation}

where ${\bf R}_{+}$ and ${\bf R}_{\_}$ are matrices with the $ij_{th}$ being $r_{i,j}$ and $1-r_{i,j}$ respectively. The expected drift terms (conditional on ${\bf L}_0$) are therefore:

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right] =& \frac{1}{N_{E_{t,m}}}\left({\bf R}_{-}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\right)\\
\end{array}
\end{equation}

We define a new matrix ${\bf M}_{t,m}$ with the $ij^{th}$ element being $(1-r_{i,j})/N_{E_{t,m}}$ (${\bf M}_{t,m}=\frac{1}{N_{E_{t,m}}}{\bf R}_{-}$) to give

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right] 
=& {\bf M}_{t,m}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\\
\end{array}
\end{equation}


Since the drift terms are independent, this gives:

\begin{equation}
\begin{array}{rl}
E\left[VAR\left(\underset{D}\Delta {\bf p}_{m}\right)\right]=&\sum_{t=t_m}^{\tau_m-1}E\left[VAR\left(\underset{D}\Delta {\bf p}_{t,m}\right)\right]\\
=& \sum_{t=t_m}^{\tau_m-1}\frac{1}{N_{E_{t,m}}}\left({\bf R}_{-}\circ{\bf N}_{t,m}\circ\tilde{\bf L}_{0}\right)\\\\
=& \tilde{\bf L}_{0}\circ\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}\\
=& \tilde{\bf L}_{0}\circ{\bf M}^{(m)}\\
\end{array}
\end{equation}

where ${\bf M}^{(m)}=\sum_{t=t_m}^{\tau_m-1}{\bf M}_{t,m}\circ{\bf N}_{t,m}$ and is null when $t_m=0$ and $\tau_m=1$.  Note the $ij^{th}$ element of ${\bf M}_{t,m}\circ{\bf N}_{t,m}=(1-r_{i,j})^{t+1}\frac{1}{N_{E_t}}\prod_{k=0}^{t-1}(1-\frac{1}{2N_{e_{k,m}}})$ which reduces to $(1-r_{i,j})^{t+1}\frac{1}{N_{e_m}}(1-\frac{1}{2N_{e_m}})^{t}$ with constant population size and $N_e=N_E$. It is not clear how large the evolutionary variance in $VAR\left(\underset{D}\Delta {\bf p}_{m}\right)$ is, and whether this would need to be accommodated.

\section{Appendix 3: Treating $\boldsymbol{\alpha}$ as random}
\label{App:alpha_random}

%\addcontentsline{toc}{subsection}{Appendix 1: Treating $\boldsymbol{\alpha}$ as random}

Before we consider $\boldsymbol{\alpha}$ as random rather than fixed, it is important to understand that quantities such as $V_A$ and genomic best linear unbiased predictors (gBLUP) are insensitive to which allele at a locus we consider the reference allele and which allele we consider the alternate allele. To make this explicit, consider the diagonal `assignment' matrix ${\bf A}$ for which the diagonal elements are either 1 (the fittest allele is the reference allele) or -1 (the fittest allele is the alternate allele). Under a particular assignment, $\boldsymbol{\alpha}={\bf A}\boldsymbol{\alpha}_{+}$ and ${\bf L}={\bf A}{\bf L}_{+}{\bf A}$, where the subscript $+$ indicates the quantity had the fitter of the two alleles been the reference allele at all loci. If we consider $V_A$ conditional on a particular assignment we get (since ${\bf A}{\bf A}={\bf I}$):


\begin{equation}
\begin{array}{rl}
V_A =& \boldsymbol{\alpha}^{\top}{\bf L}\boldsymbol{\alpha}\\
    =& ({\bf A}\boldsymbol{\alpha}_{+})^{\top}{\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& \boldsymbol{\alpha}_{+}^{\top}{\bf A}{\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& \boldsymbol{\alpha}_{+}^{\top}{\bf L}_{+}\boldsymbol{\alpha}_{+}\\
\end{array}
\end{equation}
showing we get the same value of $V_A$ irrespective of the assignment we choose.  In contrast, quantities such as $E[{\bf L}\boldsymbol{\alpha}]$ are sensitive to the assignment, since they undergo a sign reversal under a different choice: 

\begin{equation}
\begin{array}{rl}
{\bf L}\boldsymbol{\alpha} =& {\bf A}{\bf L}_{+}{\bf A}{\bf A}\boldsymbol{\alpha}_{+}\\
    =& {\bf A}{\bf L}_{+}\boldsymbol{\alpha}_{+}\\
\end{array}
\label{Eq:Lalpha}
\end{equation}

It is tempting to use the argument that $E[{\bf L}\boldsymbol{\alpha}]={\bf 0}$ when the reference allele is chosen at random, since $\alpha$ is equally likely to be positive as negative. The logic behind this argument can be expressed mathematically as $E[\boldsymbol{\alpha}]=E[{\bf A}]E[\boldsymbol{\alpha}_{+}]$ since the reference allele is chosen at random and so ${\bf A}$ must be independent of $\boldsymbol{\alpha}_{+}$. Under this same assumption $E[{\bf A}]={\bf 0}$, since any diagonal element has an equal chance of being -1 or 1, such that $E[{\bf L}\boldsymbol{\alpha}]=0$. However, this logic is incorrect. The argument envisages ${\bf A}$ as random, yet for any particular analysis ${\bf A}$ is no longer a random variable but fixed - a choice has been made as to which allele is the reference allele - even if there remains epistemic uncertainty as to whether the reference allele is the fitter of the two alleles.\\

In our inference section we show that

\begin{equation}
\begin{array}{rl}
E_{\textbf{L}_0}({V_A}) &= E_{\textbf{L}_0}[\boldsymbol{\bar \alpha}^{\top}\textbf{L}_0\bar{\boldsymbol{\alpha}}]\\
&= Tr(\textbf{L}_0{\bf V}_{\bar{\alpha}}) + \boldsymbol{\mu}_{\bar{\alpha}}^{\top}\textbf{L}_0\boldsymbol{\mu}_{\bar{\alpha}}\\
\end{array}
\end{equation}

where $\boldsymbol{\mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}}$ are the mean vector and covariance matrix of the expected average effects. When the reference allele is chosen arbitrarily, any sensible distribution for the $\bar{\alpha}$'s must induce the same distribution on the $\bar{\alpha}_{+}$'s regardless of the assignment. If ${\boldsymbol \mu}_{\bar{\alpha}_{+}}$ and ${\bf V}_{\bar{\alpha}_{+}}$ are the means and (co)variances of the expected average effects had all reference alleles been the fitter allele, then the distribution for a particular assignment becomes ${\boldsymbol \mu}_{\bar{\alpha}}={\bf A}{\boldsymbol \mu}_{\bar{\alpha}_{+}}$ and ${\bf V}_{\bar{\alpha}} = {\bf A}{\bf V}_{\bar{\alpha}_{+}}{\bf A}$. Given ${\bf A}^{-1}={\bf A}$ this implies  ${\boldsymbol \mu}_{\bar{\alpha}_{+}}={\bf A}{\boldsymbol \mu}_{\bar{\alpha}}$ and ${\bf V}_{\bar{\alpha}_{+}}={\bf A}{\bf V}_{\bar{\alpha}}{\bf A}$. For, ${\boldsymbol \mu}_{\alpha}$ this implies that suitable models should be (weighted) sums of differences between invariant properties of the alleles such that the difference reverses sign when the reference and alternate allele are switched. This might be their (log) frequency, such that the model is $\beta(p-q)$, with $\beta$ a parameter, or it might be the difference in derived vs ancestral coded as 1 vs -1, such that the model is $2\beta$ or $-2\beta$ depending on whether the reference allele is derived or ancestral, respectively. 

If ${\bf V}_{\bar{\alpha}}$ is assumed to be diagonal, all models are permissible since the square removes any sign. Since the multiplication of diagonal matrices is not affected by order we can see this directly:

\begin{equation}
\begin{array}{rl}
{\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf V}_{\bar{\alpha}}{\bf A}\\
{\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf A}{\bf V}_{\bar{\alpha}}\\
{\bf V}_{\bar{\alpha}_{+}} =& {\bf V}_{\bar{\alpha}}\\
\end{array}
\end{equation}

However, for non-diagonal matrices a suitable distribution must result in a sign reversal of all covariances at a locus when the reference and alternate alleles are switched. The most obvious way to achieve this is to allow ${\bf V}_{\bar{\alpha}}$ to be proportional to ${\bf L}^{p}$ since

\begin{equation}
\begin{array}{rl}
{\bf L}^{p}=&({\bf A}{\bf L}_{+}{\bf A})^{p}\\
         =&{\bf A}{\bf L}_{+}{\bf A}...{\bf A}{\bf L}_{+}{\bf A}\\
         =&{\bf A}{\bf L}_{+}^p{\bf A}\\
\end{array}
\end{equation}

where ${\bf L}_{+}$ is the linkage-disequilibrium matrix had the fittest allele been the reference allele at all loci. Under this assumption

\begin{equation}
\begin{array}{rl}
{\bf V}_{\bar{\alpha}_{+}} =& {\bf A}{\bf V}_{\bar{\alpha}}{\bf A}\\
{\bf V}_{\bar{\alpha}_{+}} \propto& {\bf A}{\bf L}^{p}{\bf A}\\
{\bf V}_{\bar{\alpha}_{+}} \propto& {\bf A}{\bf A}{\bf L}_{+}^p{\bf A}{\bf A}\\
{\bf V}_{\bar{\alpha}_{+}} \propto&{\bf L}_{+}^p\\
\end{array}
\end{equation}

A similar model was proposed by \citet{zeng2018signatures}, although there, ${\bf L}$ was treated as diagonal such that the variance of the average effects are assumed to be proportional to the genetic diversities to some power. 

\section{Appendix 4: Projection matrices}
\label{App:projection}

To show that our chosen projection (${\bf P} = {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$) results in identical and independently distributed residuals, we need to show that the drift covariance matrix is an identity matrix under this projection. First, we note that both ${\bf U}_{\bf L}$ and ${\bf U}_2$ are (semi-)unitary such that ${\bf U}{\bf U}^{\top}={\bf U}^{\top}{\bf U}={\bf I}$. Next we write down the eigendecomposition of ${\bf U}_{\bf L}^{\top}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf U}_{\bf L} = {\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}$, and use the unitary property of ${\bf U}_{\bf L}$ to note that $\tilde{\bf L}_{0}\circ{\bf M}^{(m)}$ can be expressed as ${\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}$. The drift covariance matrix under the projection is then:

\begin{equation} 
\begin{array}{rl}
VAR(\underset{D}\Delta \overrightarrow{\bf p}_m) &= {\bf P}VAR(\underset{D}\Delta {\bf p}_m){\bf P}^{\top}\\
&= {\bf P}(\tilde{\bf L}_{0}\circ{\bf M}^{(m)}){\bf P}^{\top}\\
&= {\bf P}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf P}^{\top}\\
&= {\bf D}_2^{-1}{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2{\bf D}_2{\bf U}_2^{\top}{\bf U}_{\bf L}^{\top}{\bf U}_{\bf L}{\bf U}_2{\bf D}_2^{-1}\\
&= {\bf I}\\
\end{array}
\end{equation}

\section{Appendix 5: Bias correction for $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$}
\label{App:bias_correction}

Using $\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}$ as an estimator of $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$ results in upward bias. To understand this, and correct for it, have
\begin{equation} 
\widehat{{\boldsymbol \beta}_{\bar{\alpha}}} = {\boldsymbol \beta}_{\bar{\alpha}}+{\bf m}_{\bar{\alpha}}
\end{equation}

where  ${\bf m}_{\bar{\alpha}}$ is the vector of deviations of the estimates from their true value.  The expected estimate of $\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}$ is then

\begin{equation}
\begin{array}{rl}
E[\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}]=& {\boldsymbol \beta}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\boldsymbol \beta}_{\bar{\alpha}}+E[{\bf m}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\bf m}_{\bar{\alpha}}]\\
=& \boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}+E[{\bf m}_{\bar{\alpha}}^{\top}{\bf X}^{\top}{\bf L}_0{\bf X}{\bf m}_{\bar{\alpha}}]\\

\end{array}
\end{equation} 

where ${\bf X}$ is the design matrix with the first column all ones, and the second ${\bf p}_{0}-{\bf q}_{0}$. Here, the expectation is taken over the distribution of estimates, and it is assumed the estimates are unbiased (since then, $E[{\bf m}_{\bar{\alpha}}]={\bf 0}$, and so $E[{\bf m}_{\bar{\alpha}}{\boldsymbol \beta}_{\bar{\alpha}}^{\top}]={\bf 0}$). This same assumption implies


\begin{equation}
\begin{array}{rl}
E[\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}]=& \boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}+Tr\left({\bf X}^{\top}{\bf L}_0{\bf X}E[{\bf m}_{\bar{\alpha}}^{\top}{\bf m}_{\bar{\alpha}}]\right)\\
\end{array}
\end{equation} 

Since $E[{\bf m}_{\bar{\alpha}}^{\top}{\bf m}_{\bar{\alpha}}]$ is a matrix of sampling (co)variances for the parameters, to get an improved estimate we can use the inverse Hessian to get an approximate ${\bf S}_{\bar{\alpha}}$ :

\begin{equation} 
\widehat{\boldsymbol{\mu}_{\bar{\alpha}}^{\top}{\bf L}_0\boldsymbol{\mu}_{\bar{\alpha}}}= \widehat{\boldsymbol{\mu}_{\bar{\alpha}}}^{\top}{\bf L}_0\widehat{\boldsymbol{\mu}_{\bar{\alpha}}}-Tr\left({\bf X}^{\top}{\bf L}_0{\bf X}{\bf S}_{\bar{\alpha}}\right)
\end{equation} 

In addition, $Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})$ is most likely an upwardly biased estimator of $Tr({\bf L}_0{\bf V}_{\bar \alpha})$. However, we found no easy way to determine or correct for the degree of bias, and the simulation results suggest that the bias is likely to be small, at least when the number of replicates or generations is moderately large.\\

% We can express the estimate of the trace as

% \begin{equation}
% \begin{array}{rl}
% Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}}) =& Tr({\bf L}_0\widehat{\sigma^2_{\bar \alpha}}{\bf L}_0^{\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}Tr({\bf L}_0^{1+\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}Tr({\bf D}_L^{2+2\widehat{p_{\bar{\alpha}}}})\\
%                                     =& \widehat{\sigma^2_{\bar \alpha}}\left(\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)\\
% \end{array}
% \end{equation}

% such that

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})] =& 
% COV\left(\widehat{\sigma^2_{\bar \alpha}}, \sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)+E[\widehat{\sigma^2_{\bar \alpha}}]E[\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}]\\
% \end{array}
% \label{Eq:ETrLV}
% \end{equation}

% Assuming estimates of $\sigma^2_{\bar \alpha}$ and $p_{\bar{\alpha}}$ are unbiased and their sampling distribution is multivariate normal then

% \begin{equation}
% \begin{array}{rl}
% E[d_i^{2+2\widehat{p_{\bar{\alpha}}}}]=&E[exp(2log(d_i)+2\widehat{p_{\bar{\alpha}}}log(d_i))]\\
% =&exp(2log(d_i)+2p_{\bar{\alpha}} log(d_i)+2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\   =&d_i^{2+2p_{\bar{\alpha}}}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\

% \end{array}
% \end{equation}

% following results for the log-normal distribution. 

% Consequently, the final product in Equation \ref{Eq:ETrLV} is upwardly biased. However, this might be offset by the covariance term which is likely to be negative given the sampling distribution of the two parameters will in general have a negative correlation. The covariance does not have an analytical form but can be approximated using the Delta method:

% \begin{equation}
% \begin{array}{rl}
% COV\left(\widehat{\sigma^2_{\bar \alpha}}, \sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)\approx&
% COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\frac{\partial \left(\sum_i d_i^{2+2\widehat{p_{\bar{\alpha}}}}\right)}{\partial \widehat{p_{\bar{\alpha}}}}\Big|_{p_{\bar{\alpha}}}\\
% \approx&
% COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\sum_i log(2d_i)d_i^{2+2p_{\bar{\alpha}}}\\
% \end{array}
% \end{equation}

% This gives

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})]  =& COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}})\sum_i log(2d_i)d_i^{2+2p_{\bar{\alpha}}}+\sigma^2_{\bar \alpha}\sum_id_i^{2+2p_{\bar{\alpha}}}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\\
% =& \sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}exp(2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}}))\right]\\
% \end{array}
% \end{equation}

% If $VAR(\widehat{p_{\bar{\alpha}}})$ is small then

% \begin{equation}
% \begin{array}{rl}
% E[Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})] 
% =& \sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}+\sigma^2_{\bar \alpha}2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}})\right]\\
% =& Tr({\bf L}_0{\bf V}_{\bar \alpha})+\sum_i d_i^{2+2p_{\bar{\alpha}}}\left[COV(\widehat{\sigma^2_{\bar \alpha}}, \widehat{p_{\bar{\alpha}}}) log(2d_i)+\sigma^2_{\bar \alpha}2log(d_i)^2VAR(\widehat{p_{\bar{\alpha}}})\right]\\ 
% \end{array}
% \end{equation}

% Note that if we model ${\bf V}_{\bar \alpha}$ using only the diagonal elements of ${\bf L}_{0}$ then

% \begin{equation}
% \begin{array}{rl}
% Tr({\bf L}_0\widehat{{\bf V}_{\bar \alpha}})                                      =& \widehat{\sigma^2_{\bar \alpha}}\left(\sum_i l_{0_{ii}}^{1+\widehat{p_{\bar{\alpha}}}}\right)\\
% \end{array}
% \end{equation}

% and so the above equations can be used by replacing $d_i$ with $\sqrt{l_{0_i}}$.



\section{Appendix 6: Comparison with the method of \citet{buffalo2019linked}}
\label{App:BandC}

To make clearer the distinction between the approach of B\&C and our approach, here we explicitly express the expectations and covariances appearing in B\&C as conditional on ${\bf B}$ and $\boldsymbol{\alpha}$. In the sections dealing with our theory and inference, the conditioning (on ${\bf L}_0$) is left implicit. B\&C work with the quantity

\begin{equation}
COV(\Delta {\bf p}_t, \Delta {\bf p}_{\tau}^{\top} | {\bf B}, \boldsymbol{\alpha})
\end{equation}

where $\tau$ is some generation after $t$ (B\&C actually only work with the diagonal elements of this matrix, but we retain the full multi-locus model here for generality). Importantly, when B\&C estimate the additive genetic variance in fitness they assume that both $\Delta {\bf p}_t$ and $\Delta {\bf p}_{\tau}$ both represent allele frequency change over a single generation (Assumption A). As the change due to drift will be independent in different generations, we can rewrite B\&C's covariance: 

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_t, \Delta {\bf p}_{\tau}^\top  | {\bf B}, \boldsymbol{\alpha}) 
=& COV({\bf L}_t\boldsymbol{\alpha}_t,  \boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau}  | {\bf B}, \boldsymbol{\alpha})\\
%=& E\left[{\bf L}_t\boldsymbol{\alpha}_t\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau}  | {\bf B}, \boldsymbol{\alpha}\right]-\left[{\bf L}_t\boldsymbol{\alpha}_t  | {\bf B}, \boldsymbol{\alpha}\right] E\left[\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
=& E\left[{\bf L}_t\boldsymbol{\alpha}_t\boldsymbol{\alpha}_{\tau}^{\top}{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]-E\left[{\bf L}_t | {\bf B}, \boldsymbol{\alpha}\right]\boldsymbol{\alpha}_t \boldsymbol{\alpha}_{\tau}^{\top}E\left[{\bf L}_{\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov1}
\end{equation}

Since the diagonal elements of ${\bf L}$ have to be positive, a sufficient, but not necessary, condition for the final term to be zero is that there is no direct selection on the loci (i.e. $\boldsymbol{\alpha}={\bf 0}$). It is not a necessary condition because the change caused by direct selection at all loci could be exactly balanced by the change caused by indirect selection at other loci, although we ignore this unlikely scenario. The assumption that $\boldsymbol{\alpha}={\bf 0}$ is achieved in B\&C by assuming that sites can be partitioned into neutral and selected sites and that allele frequency change is only tracked at the neutral sites (Assumption B). To understand the consequences of this assumption we consider all loci are being followed, both a selected set (${\mathcal S}$) and a neutral set (${\mathcal N}$). Consequently,

\begin{equation}
\boldsymbol{\alpha}=
\left[
\begin{array}{c}
{\bf 0}\\
\boldsymbol{\alpha}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

and so

\begin{equation}
\boldsymbol{\alpha}\boldsymbol{\alpha}^{\top}=
\left[
\begin{array}{cc}
{\bf 0}&{\bf 0}\\
{\bf 0}&\boldsymbol{\alpha}_{\mathcal S}\boldsymbol{\alpha}^{\top}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

We can also partition ${\bf L}$

\begin{equation}
{\bf L}=
\left[
\begin{array}{cc}
{\bf L}_{\mathcal N}&{\bf L}_{{\mathcal N}, {\mathcal S}}\\
{\bf L}_{{\mathcal S}, {\mathcal N}}&{\bf L}_{\mathcal S}\\
\end{array}
\right]
\end{equation}

and writing ${\bf L}_{{\mathcal N}, {\mathcal S}} = {\bf B}_{{\mathcal N}}{\bf R}_{{\mathcal N}, {\mathcal S}}{\bf B}_{{\mathcal S}}$, Equation \ref{Eq:BCcov1} for neutral sites becomes

\begin{footnotesize}
\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_{{\mathcal N}_t}, \Delta {\bf p}_{{\mathcal N}_{\tau}}^\top  | {\bf B}, \boldsymbol{\alpha}) 
%=& E\left[{\bf L}_{{\mathcal N}_t, {\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf L}_{{\mathcal S}_\tau, {\mathcal N}_\tau} | {\bf B}, \boldsymbol{\alpha}\right]+E\left[{\bf L}_{{\mathcal N}_t, {\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]E\left[\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf L}_{{\mathcal S}_\tau, {\mathcal N}_\tau} | {\bf B}, \boldsymbol{\alpha}\right]\\
%=& E\left[{\bf B}_{{\mathcal N}_t}{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
%&+E\left[{\bf B}_{{\mathcal N}_t}{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]E\left[\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
=& {\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
&+{\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}E\left[{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\ 
\end{array}
\label{Eq:BCcov3}
\end{equation}
\end{footnotesize}
Under the conditioning of B\&C, ${\bf R}_{{\mathcal S}, {\mathcal N}_\tau}$ is a random variable. If we assume that the linkage-disequilibrium between the neutral alleles and the selected alleles has arbitrary sign, then $E[{\bf R}_{{\mathcal S}, {\mathcal N}_\tau} |  {\bf B}, \boldsymbol{\alpha}]={\bf 0}$, which will be met if the reference allele is chosen arbitrarily (e.g. not based on minor allele frequency \citep{good2022linkage}). Under this assumption (Assumption C) the final term in Equation \ref{Eq:BCcov3} disappears to give: 

\begin{equation}
\begin{array}{rl}
COV(\Delta {\bf p}_{{\mathcal N}_t}, \Delta {\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})
=& {\bf B}_{{\mathcal N}_t}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
\end{array}
\label{Eq:BCcov4}
\end{equation}

As in our inference section, the vector of allele frequency changes could be transformed using matrix ${\bf P}$ ($\Delta \overrightarrow{\bf p} = {\bf P}\Delta {\bf p}$) and B\&C use the projection ${\bf P}={\bf B}_{{\mathcal N}_t}^{-1}$ (they actually multiply this by $\sqrt{2}$ - see Equation \ref{Eq:BCcov10}) which results in

\begin{equation}
\begin{array}{rl}
COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) 
=& E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}{\bf B}_{{\mathcal N}_t}^{-1}\\
=& {\bf B}_{{\mathcal N}_t}^{-1}E\left[{\bf R}_{{\mathcal N}_t, {\mathcal S}_t}{\bf B}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_t}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_{\tau}}{\bf R}_{{\mathcal S}_\tau, {\mathcal N}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal N}_{\tau}}\\
\end{array}
\label{Eq:BCcov5}
\end{equation}

Further derivation in B\&C considers the expected value of a diagonal element of this matrix: the average (over neutral loci) covariance in projected allele frequency change. However, it is perhaps easier to note that the trace of this matrix is equal to this average multiplied by the number of neutral loci, $n_{L_\mathcal{N}}$ (see below). Since the trace of an outer product is equal to the inner product we get:

\begin{footnotesize}
\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top  | {\bf B}, \boldsymbol{\alpha})\right)&=
E\left[\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{{\mathcal S}_t}{\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov6}
\end{equation}
\end{footnotesize}

The diagonal element $j$ of ${\bf W}_{t\tau}={\bf R}_{{\mathcal S}_t, {\mathcal N}_t}{\bf B}_{{\mathcal N}_t}^{-1}{\bf B}_{{\mathcal N}_{\tau}}{\bf R}_{{\mathcal N}_\tau, {\mathcal S}_{\tau}}$ is equal to the sum of selected locus $j$'s $R_{j_t,i_t}R_{j_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$ across all neutral loci $i$. The $jk^{th}$ off-diagonal element is the sum of $R_{j_t,i_t}R_{k_{\tau},i_{\tau}}(b_{i_\tau}/b_{i_t})$ for selected loci $j$ and $k$ across all neutral loci $i$. If we write  ${\bf W}_{t\tau} = {\bf H}_{t\tau}+({\bf W}_{t\tau}-{\bf H}_{t\tau})$ where ${\bf H}_{t\tau}$ and ${\bf W}_{t\tau}-{\bf H}_{t\tau}$ are zero but for the diagonal and off-diagonal elements respectively, then Equation \ref{Eq:BCcov6} becomes


\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&\quad+\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf W}_{t\tau}-{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov7}
\end{equation}

If we focus on a system with two selected loci, $j$ and $k$, then the final term in Equation \ref{Eq:BCcov7} is equal to:
\begin{tiny}
\begin{equation}
\sum_j\sum_k\left(\alpha_{j_t}\alpha_{k_{\tau}}b_{j_t,j_t}b_{k_{\tau},k_{\tau}}\sum _i \left(E\left[R_{i_t,j_t}R_{i_{\tau},k_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]b_{i_\tau}/b_{i_t}\right)+\alpha_{j_{\tau}}\alpha_{k_t}b_{j_{\tau},j_{\tau}}b_{k_t,k_t}\sum _i \left(E\left[R_{i_{\tau},j_{\tau}}R_{i_t,k} | {\bf B}, \boldsymbol{\alpha}\right]b_{i_\tau}/b_{i_t}\right)\right).
\label{eq:AssumpE}
\end{equation}
\end{tiny}

Under Hill-Robertson interference, if $\alpha_j$ and $\alpha_k$ have the same sign we expect them to be in negative LD with each other, and as a consequence have opposing patterns of LD with the neutral loci (i.e. if $\alpha_j\alpha_k>0$ then we expect $E[R_{i,j}R_{i,k}]<0$ and vice versa). Although the terms of these products are evaluated at different generations in Equation \ref{eq:AssumpE} ($t$ and $\tau$) we expect the terms to share sign in the same way, generating a negative expectation for the second term in Equation \ref{Eq:BCcov7}.  However, assuming an absence of Hill-Robertson interference, or signed linkage-disequilibrium more generally (Assumption D), then the final term in Equation \ref{Eq:BCcov7} can be dropped:

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top) | {\bf B}, \boldsymbol{\alpha}\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}
\end{array}
\label{Eq:BCcov8}
\end{equation}

Based on a deterministic model for changes in linkage-disequilibrium (Assumption E) and assuming nongametic-phase linkage-disequilibrium is absent (Assumption F), Equations 40-44 in B\&C derive an expression from which $E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]$ can be computed. Under the assumption that drift (or selection) does not alter the dynamics of ${\bf R}$ then (Equation 42 in B\&C):

\begin{equation}
\begin{array}{rl}
L_{j_{\tau},i_{\tau}} =& L_{j_t,i_t}\frac{b_{j_\tau}^2}{b_{j_t}^2}(1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}

which implies

\begin{equation}
\begin{array}{rl}
R_{j_{\tau},i_{\tau}} =&R_{j_t,i_t}\frac{b_{j_\tau}b_{i_t}}{b_{j_t}b_{i_\tau}}(1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}

and so

\begin{equation}
\begin{array}{rl}
E\left[H_{j_t, j_\tau} | {\bf B}, \boldsymbol{\alpha}\right]
&=\sum_i E\left[R_{j_t,i_t}R_{j_{\tau},i_{\tau}} | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{i_\tau}}{b_{i_t}}\\
%&=\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{i_\tau}}{b_{i_t}}\frac{b_{j_\tau}b_{i_t}}{b_{j_t}b_{i_\tau}}(1-r(g_{j,i}))^{\tau-t}\\
%&=\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right]\frac{b_{j_\tau}}{b_{j_t}}(1-r(g_{j,i}))^{\tau-t}\\
&=\frac{b_{j_\tau}}{b_{j_t}}\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}\\
\end{array}
\end{equation}


where $r(g_{j,i})$ is the recombination rate as a function of the distance $g_{i,j}$ between the two loci. Writing ${\bf F}_{t\tau}$ a diagonal matrix with the $j^{th}$ element equal to
$\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}$, then $E\left[{\bf H}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]= E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{\mathcal{S}_t}^{-1}$ and so

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})\right)&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}{\bf B}_{{\mathcal S}_t}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{\mathcal{S}_t}^{-1}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}{\bf B}_{{\mathcal S}_{\tau}}\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
&=
\boldsymbol{\alpha}_{{\mathcal S}_t}^{\top}E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]{\bf B}_{\mathcal{S}_\tau}^2\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}\\
\end{array}
\label{Eq:BCcov9}
\end{equation}

where (under random mating) ${\bf B}_{\mathcal{S}_\tau}^2$ is a diagonal matrix with elements proportional to the genetic diversities in generation $\tau$. However, this is still hard to evaluate since $E\left[{\bf F}_{t\tau} | {\bf B}, \boldsymbol{\alpha}\right]$ will vary over loci in a way that may depend on ${\bf B}$ and hence ${\bf B}_{{\mathcal S}_t}^2$. 
The method of B\&C assumes that the sample correlation between the diagonal elements of $E\left[{\bf F}_{t\tau} | {\bf B},\boldsymbol{\alpha}\right]$ and the elements $\alpha_{j_t}\alpha_{j_\tau}b^2_{j_\tau}$ is zero (Assumption G). Under this assumption:

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)&=\frac{1}{n_{L_\mathcal{S}}}
\boldsymbol{\alpha}_{{\mathcal S}_{t}}^{\top}{\bf B}_{\mathcal{S}_\tau}^2\boldsymbol{\alpha}_{{\mathcal S}_{\tau}}E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
&=
\frac{1}{n_{L_\mathcal{S}}}C_a(t\rightarrow\tau)E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov10}
\end{equation}

where $n_{L_\mathcal{S}}$ is the number of selected loci (note that in B\&C  the leading term is $\frac{1}{2n_{L_\mathcal{S}}}$ not $\frac{1}{n_{L_\mathcal{S}}}$ and this is because our projection matrices are only proportional by a factor $\sqrt{2}$ -  see Equation \ref{Eq:BCcov5}). The method of B\&C further assumes (Assumption H) that the average effects are constant in time such that $\boldsymbol{\alpha}_t=\boldsymbol{\alpha}_\tau$ then this reduces to

\begin{equation}
\begin{array}{rl}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)&=
\frac{V_a(\tau)}{n_{L_\mathcal{S}}}E\left[Tr({\bf F}_{t\tau}) | {\bf B}, \boldsymbol{\alpha}\right]\\
\end{array}
\label{Eq:BCcov11}
\end{equation}

Under Assumption H, Assumption G implies that the additive genic variance contributed by a selected locus is independent of its associations with neutral loci as measured by $R_{i_t,j_t}^2$. 
However, allele frequencies at selected loci enter the expression for the additive genic variance, and they also dictate the range of $R_{i_t,j_t}$ and therefore the magnitude of $R_{i_t,j_t}^2$: when selected allele frequencies are  small compared to frequencies at neutral alleles,  $R_{i_t,j_t}$ cannot cover the full range of -1 to 1 \citep{sved2018one}. 

B\&C approximate ${\bf R}_t$, and therefore ${\bf F}_{t\tau}$ under the assumption of mutation-drift-recombination equilibrium (Assumption I). \citet{Ohta.1971} derived the expectation of $L_{j_t, i_t}L_{j_t, i_t}=L^2_{j_t, i_t}$ under this assumption, although the expectation of $R^2_{j_t, i_t}$ can only be approximated as the expectation of $L^2_{j_t, i_t}$ divided by the expectation of the genetic diversities at the two loci, and is only accurate when the minor allele frequencies are greater than 10\%  \citep{McVean.2002} -- and can be out by orders of magnitude when allele frequencies are extreme \citep{Song.2007}, as can be expected at loci under selection.  Moreover,  \citet{Ohta.1971} derived the expectation $E[L^2_{j_t, i_t}]$ yet the B\&C approach actually requires $E\left[L^2_{j_t, i_t} | {\bf B}, \boldsymbol{\alpha}\right]$ which is considerably more challenging to compute \citep{good2022linkage}. In the Appendix B\&C also relax, to some extent, Assumption I, where $Tr({\bf F}_{t\tau})$ is calculated empirically using all loci, neutral and selected (Equation 55). In both cases - using the neutral expectation (Assumption I) or empirical LD (Assumption I-b) - the expected LD between selected and neutral loci will be overestimated since in reality selected alleles will be rarer than neutral alleles and so their LD, even measured as a correlation, will be reduced compared to that between neutral loci \citep{sved2018one}.

Equation \ref{Eq:BCcov11} allows $V_a(\tau)$ to be estimated, but B\&C aim to estimate $V_a(t)$.  Under Assumption H, and assuming that the proportional change in genetic diversity at selected loci between generation $t$ and $\tau$ is constant across loci (Assumption J: ${\bf B}_{\mathcal{S}_t}^2{\bf B}_{\mathcal{S}_\tau}^{-2} = \phi_{t,\tau}{\bf I}$), $V_a(t)=\phi_{t,\tau} V_a(\tau)$.\\ 

The above derivation assumes that the sites can be partitioned into selected and neutral sites and that the map positions of all sites are known.  In practice, this will often be infeasible and so a number of additional assumptions are required. In the absence of map positions, Haldane's \citeyearpar{haldane1919map} mapping function is assumed for $r(g)$ (Assumption K) but, since the selected loci and their physical position, $g$, are assumed unknown, a model is also required for $g$. B\&C assume that selected and neutral loci are distributed uniformly and independently such that $g_{j,i}$ has a triangular distribution (Assumption L). Also, since the selected sites are unobserved, $\phi_{t,\tau}$ cannot be computed and so it is assumed that that $\phi_{t,\tau}$ is equal to the ratio of genetic diversity at generation $\tau$ to genetic diversity at generation $t$ across all neutral loci (Assumption M). \\ 
 
In addition to the assumptions/approximations made when developing the theory, additional assumptions/approximations are made when making inferences from data.  Rather than taking the average (over loci) covariance (over evolutionary replicates) the covariance over loci is taken. However, from the law of total covariance this is expected to yield the correct result under Assumptions B and C. In addition, rather than calculating the (co)variances in projected allele frequency change, it is assumed (Assumption N) that the (co)variances in actual allele frequency divided through by the average projection is a good approximation: $COV_{L}(\Delta p_{t}, \Delta p_{\tau})/E[b_t^2]$ is a good approximation of $COV_{L}(\Delta p_{t}/b_{t}, \Delta p_{\tau}/b_{t})$ where $ COV_L$ designates a covariance over loci (Equation 16 B\&C). The two quantities are only expected to agree under restrictive conditions \citep{Bohrnstedt.1969}. However, it is not necessary to make Assumption N and relaxing it can reduce the bias in the estimator considerably. Finally, if there is measurement error in allele frequencies and the same allele frequency measurements are used to calculate change over adjacent intervals then this will generate downward bias in the estimated covariances. This is corrected for in B\&C by assuming the sampling error in allele frequencies is binomial around the true value (Assumption O), although in practice non-binomial causes of overdispersion are likely. While we have tested our method assuming allele frequencies are known without error, any error in the allele frequencies will look like drift if allele frequencies are measured independently in each time/replicate. Consequently, the sampling noise will be incorporated into the estimate of the residual variance. \\ 

To connect Equation \ref{Eq:BCcov11} with the derivation in B\&C more clearly, we can write 

\begin{equation}
Tr\left(COV(\Delta \overrightarrow{\bf p}_{{\mathcal N}_t}, \Delta \overrightarrow{\bf p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha}) \right)=n_{L_\mathcal{N}}\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}
\end{equation}

where the overline denotes the sample mean for the $n_{L_\mathcal{N}}$ neutral loci. Similarly, 

\begin{equation}
\begin{array}{rl}
Tr({\bf F}_{t\tau}) =& \sum_j\sum_i E\left[R_{j_t,i_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,i}))^{\tau-t}\\
=&n_{L_\mathcal{N}}\overline{\sum_jE\left[R_{j_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,{\mathcal N}}))^{\tau-t}}\\
\end{array}
\end{equation}

Equation \ref{Eq:BCcov11} can then be written as

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}&=
\frac{V_a(\tau)}{n_{L_\mathcal{S}}}\overline{\sum_jE\left[R_{j_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{j,{\mathcal N}}))^{\tau-t}}\\
\end{array}
\label{Eq:BCcov12}
\end{equation}

which is Equation 8 in B\&C averaged over neutral loci and can be further simplified to

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_t}, \Delta \overrightarrow{p}_{{\mathcal N}_{\tau}}^\top | {\bf B}, \boldsymbol{\alpha})}&=
V_a(\tau)\overline{E\left[R_{{\mathcal S}_t,{\mathcal N}_t}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{{\mathcal S},{\mathcal N}}))^{\tau-t}}\\
\end{array}
\label{Eq:BCcov13}
\end{equation}

where the overline indicates the sample average of all the $n_{L_\mathcal{S}}n_{L_\mathcal{N}}$ pairwise comparisons between selected loci and neutral loci. 

Extending this theory to allele frequency change measured in independent replicates, rather than at different time-points in a single population is straightforward \citep{Buffalo.2020}. If allele frequency change is measured in two populations, $m$ and $n$,  both of which have been derived independently from the base population $t$ generation  in the past, Equation  \ref{Eq:BCcov13} can be expressed as:

\begin{equation}
\begin{array}{rl}
\overline{COV(\Delta \overrightarrow{p}_{{\mathcal N}_m}, \Delta \overrightarrow{p}_{{\mathcal N}_n}^\top | {\bf B}, \boldsymbol{\alpha})}&=
V_a(m,n)\overline{E\left[R_{{\mathcal S}_0,{\mathcal N}_0}^2 | {\bf B}, \boldsymbol{\alpha}\right](1-r(g_{{\mathcal S},{\mathcal N}}))^{2t}}\\
\end{array}
\label{Eq:BCcov14}
\end{equation}

assuming the average effects have stayed constant.


\subsection[Appendix 7]{Appendix 7: $N_E$ and average effects under a log-linear model}
\label{App:loglinear}

In the simulations we simulate for individual $k$

$$y_k={\bf c}^{\top}_k\boldsymbol{\eta}+e_k$$

where the environmental deviations, $e$, have zero mean and standard deviation $\sigma_e$.  We then draw $2N_{t+1}$ parents with replacement from a multinomial with the unnormalised  probability of $k$ being a parent of an offspring equal to  $P_k=exp(y_k)$ and the normalised probability being $p_k=P_k/\sum_{j}^{N_t}P_j$. Absolute fitness is therefore $2N_{t+1}p_k = 2\frac{N_{t+1}}{N_tE[P]}P_k$. Having $m = 2\frac{N_{t+1}}{N_tE[P]}$, then absolute fitness is $P_km=exp(y_k)m$.  Following \citet{Kojima.1959} we can define Fisher's average effect for relative fitness in terms of the partial derivative of each $E[c]=p_0$ with respect to mean fitness and then rescale by mean fitness:

\begin{equation}
\begin{array}{rl}
\alpha_i =& \frac{1}{\bar W}\frac{\partial{\bar W}}{\partial{p_{0_i}}}\\
 =& \frac{1}{E[exp(y)m]}\frac{\partial{E[exp(y)m]}}{\partial{p_{0_i}}}\\
 =&  \frac{1}{E[exp(y)]}\frac{\partial{E[exp(y)]}}{\partial{p_{0_i}}}\\
  =&  \frac{\partial{log(E[exp(y)])}}{\partial{p_{0_i}}}\\
\end{array}
\end{equation}

Assuming that $y$ to be normally distributed with mean ${\mu_y}$ and variance $V_y$ then allows us to use the expression for the expectation of a log-normal distribution to write:

\begin{equation}
\begin{array}{rl}
\alpha_i&= \frac{\partial log(exp(\mu_y + {V_y}/2 ))}{\partial p_i} \\
&= \frac{\partial (\mu_y + {V_y}/2 )}{\partial p_{0_i}}
\end{array}
\end{equation}

It is worth highlighting that, so far, we have made no assumptions about the distribution of the contributions ($c_{i}\eta_{i}$) made by individual loci to $y$. Next, we split up $\mu_y$ and $V_y$ into the contributions of individual loci.

\begin{equation}
\begin{array}{rl}
\mu_y &= \sum_{i=1}^{n_L} E[c_i \eta_i] \\
&= \sum_{i=1}^{n_L} p_{0_i} \eta_i
\end{array}
\end{equation}

\begin{equation}
\begin{array}{rl}
V_y &= {\bf \eta}^{\top}{\bf L}_{0}{\bf \eta} + \sigma^2_e\\
&= \sum_{i=1}^{n_L} l_{0_{ii}}\eta^2_{i} + 2\sum\limits_{j \neq i}^{n_L} l_{0_{ij}} \eta_i \eta_j  + \sigma^2_e\\
\end{array}
\end{equation}

Assuming all additive genetic variance is genic, $V_y$  simplifies to 

\begin{equation}
\begin{array}{rl}
V_y
&= \sum_{i=1}^{n_L} l_{0_{ii}}\eta^2_{i} + \sigma^2_e\\
\end{array}
\end{equation}

and substituting these expressions for $\mu_y$ and $V_y$ yields:

\begin{equation}
\begin{array}{rl}
\alpha_i&=\frac{\partial \left(\sum_{i=1}^{n_L}(p_{0_i} \eta_i+l_{0_{ii}}\eta^2_{i}/2) + \sigma^2_e\right)}{\partial p_{0_i}}\\
\end{array}
\end{equation}


Under Hardy-Weinberg Equilibrium $l_{0_{ii}}=p_i(1 - p_i)/2$ and this simplifies to 

\begin{equation}
\begin{array}{rl}
\alpha_i&=\frac{\partial \left(\sum_{i=1}^{n_L}(p_{0_i} \eta_i+p_{0_i}(1-p_{0_i})\eta^2_{i}/2) + \sigma^2_e\right)}{\partial p_{0_i}}\\
&= \eta_i + \frac{1}{4}(1 - 2p_{0_i} )\eta^2_{i}\\
&= \eta_i - \frac{1}{4}(p_{0_i}-q_{0_i})\eta^2_{i}\\
\end{array} 
\end{equation}

Note $\frac{1}{4}\eta^2$ is the quantitative genetic dominance deviation, often denoted $d$.

In order to calculate $N_E$ under this multinomial log-linear model we need to know the variance in offspring number $V_o$ in the presence of environmental variance in fitness only.  Then $N_E=4N/(2+V_o)$ where $N$ is the census population size \citep{Wright.1938}. The expected number of offspring for parent $k$ is $2N_{t+1}p_k$, as given above, and  the variance in the number offspring is $2N_{t+1}p_k(1-p_k)$. From the the law of total variance $V_o = 4N^2_{t+1}Var(p)+2N_{t+1}E[p(1-p)]$.  Since $E[p(1-p)]=E[p]-E[p^2]$ and $Var(p)=E[p^2]-E[p]^2$ then $E[p(1-p)]=E[p]-Var(p)+E[p]^2$. Since $E[p] = 1/N_{t}$ by definition, 


\begin{equation}
\begin{array}{rl}
V_o =& 4N^2_{t+1}Var(p)+2N_{t+1}E[p(1-p)]\\
       =& 4N^2_{t+1}Var(p)+\frac{2N_{t+1}}{N_t}-2N_{t+1}Var(p)+\frac{2N_{t+1}}{N^2_t}\\
       =& (4N^2_{t+1}-2N_{t+1})Var(p)+\frac{2N_{t+1}}{N_t}+\frac{2N_{t+1}}{N^2_t}\\
\end{array}
\label{Eq:vo}
\end{equation}

From the properties of the log-normal (with zero mean) we know $E[P] = exp(\sigma_e^2/2)$ and $Var(P) = (exp(\sigma_e^2)-1)exp(\sigma_e^2)$. Since $p = P/(N_tE[P])$

\begin{equation}
\begin{array}{rl}
Var(p) =& Var(P)/(N_tE[P])^2\\
=&(exp(\sigma_e^2)-1)exp(\sigma_e^2)/(N_texp((\sigma_e^2)/2))^2\\
       =& (exp(\sigma_e^2)-1)exp(\sigma_e^2)/(N_t^2exp(\sigma_e^2))\\
       =& (exp(\sigma_e^2)-1)/N_t^2\\
\end{array}
\end{equation}

If $N_{t+1}$ and $N_t$ are large then Equation \ref{Eq:vo} simplifies to

\begin{equation}
V_o = 4N^2_{t+1}Var(p)+2N_{t+1}/N_t
\end{equation}

such that 

\begin{equation}
V_o = (4N^2_{t+1}/N^2_t)(exp(\sigma^2_e)-1)+2N_{t+1}/N_t
\end{equation}

If the population size is constant then this simplifies to $V_o = 4exp(\sigma^2_e)-2$ and the variance effective population size, $N_{E_t}$, is $4N_t/(2+V_o)=N_t/exp(\sigma^2_e)$. 

\section{Supplementary Figures}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/FigS1.jpg}
\caption{Results of full simulations with a burn-in phase of 25000 generations (map length in the history phase = 2 morgans, number of replicate populations = 10, population size = 1000, number of generations = 3, $\eta_{scale} = 0.045$) at different levels of the map length in the history phase (0.5 morgans: pink, 5 morgans: blue, and 50 morgans: grey). The coloured solid lines represent regression lines for estimates of $V_A$ vs true values of $V_A$.}
  \label{fig:Figure S1}
\end{figure}


\begin{figure}[p]
\begin{center}
\includegraphics[scale = 0.11]{Figures/FigS2.jpg}
\end{center}
\caption{(A) Fraction of the total additive genic variance ($V_a(0)$) lost during the experiment (averaged over all the replicate populations) plotted as a function of $\eta_{scale}$. Each boxplot represents 100 independent simulations shown (for the corresponding level of $\eta_{scale}$) in Figure \ref{fig:Figure 4}D. (B) The error on our estimates of $V_A$ plotted versus the total additive genic variance ($V_a$) lost during the experiment (averaged over all the replicate populations) for simulations where the non-neutral $\eta_{scale}$ was either 0.033 (green), 0.045 (blue), or 0.1 (grey). The solid line has an intercept of 0 and a slope of -1. (C) The contribution of each non-neutral locus (averaged over all the replicate populations) to $V_a$ lost during the experiment plotted versus $|\alpha|$ for that locus for a simulation with $\eta_{scale} = 0.1$ that had the maximum $V_a$ loss (grey) and a simulation with $\eta_{scale} = 0.033$ that had a comparable true initial $V_A$ but  the minimum $V_a$ loss (green) in the experiment. The solid curve represents the additive genic variance lost when a singleton goes extinct. (D) The total $V_a$ lost at groups of loci classified by dividing $|\alpha|$ into intervals of 0.01 for the simulation with the maximum $V_a$ loss (grey) and the simulation with the minimum $V_a$ loss (green) in the experiment. In the simulation with the maximum $V_A$ loss -- in which the mean $|\alpha|$ for non-neutral loci was 0.0410 -- more than 50\% of the total loss in $V_a$ was driven by just 0.96\% loci whose $|\alpha|$ was greater than 0.3.}
  \label{fig:Figure S2}
\end{figure}

% max_va_loss_sim = "Set_15_a_bigwig_2025-03-25_16-11-05.569303_1.52828282828283e-07_0.5_2_1000_10_4_0_0"

% min_va_loss_sim = "Set_9_bigbird_2024-12-26_09-31-27.103756_5.10509090909091e-07_0.5_2_1000_10_4_0_0"

\newpage
\begin{figure}[H]
\centering
\includegraphics[scale = 0.15]{Figures/FigS3.jpg}
\caption{Residual variance in the models analysing the results of full simulations shown in Figure \ref{fig:Figure 3} using either the number of individuals (1000) instead of the $N_E$ or the true $N_E$.}
  \label{fig:Figure S3}
\end{figure}

\putbib
\end{bibunit}




%\printbibliography

\end{document}
